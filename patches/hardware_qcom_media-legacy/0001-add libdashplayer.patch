From: ChepKun <ProgrammerKun@gmail.com>
Subject: [PATCH] hardware/qcom/media-legacy (0001): add libdashplayer

diff --git a/dashplayer/Android.mk b/dashplayer/Android.mk
new file mode 100644
index 0000000..988084f
--- /dev/null
+++ b/dashplayer/Android.mk
@@ -0,0 +1,56 @@
+#ifneq ($(TARGET_BOARD_PLATFORM),msm8960
+LOCAL_PATH:= $(call my-dir)
+include $(CLEAR_VARS)
+# ---------------------------------------------------------------------------------
+#            Common definitons
+# ---------------------------------------------------------------------------------
+LOCAL_SRC_FILES:=                       \
+        DashPlayer.cpp                  \
+        DashPlayerDriver.cpp            \
+        DashPlayerRenderer.cpp          \
+        DashPlayerStats.cpp             \
+        DashPlayerDecoder.cpp           \
+        DashPacketSource.cpp            \
+        DashFactory.cpp                 \
+        DashCodec.cpp
+
+LOCAL_SHARED_LIBRARIES :=       \
+    libbinder                   \
+    libcamera_client            \
+    libcutils                   \
+    libdl                       \
+    libgui                      \
+    libmedia                    \
+    libstagefright              \
+    libstagefright_foundation   \
+    libstagefright_omx          \
+    libutils                    \
+    libui                       \
+
+LOCAL_STATIC_LIBRARIES :=       \
+    libstagefright_nuplayer     \
+    libstagefright_rtsp         \
+
+LOCAL_C_INCLUDES := \
+    $(TOP)/frameworks/av/media/libstagefright/timedtext           \
+	$(TOP)/frameworks/native/include/media/hardware               \
+	$(TOP)/frameworks/native/include/media/openmax                \
+	$(TOP)/frameworks/av/media/libstagefright/httplive            \
+	$(TOP)/frameworks/av/media/libmediaplayerservice/nuplayer     \
+	$(TOP)/frameworks/av/media/libmediaplayerservice              \
+	$(TOP)/frameworks/av/media/libstagefright/include             \
+	$(TOP)/frameworks/av/media/libstagefright/mpeg2ts             \
+	$(TOP)/frameworks/av/media/libstagefright/rtsp                \
+	$(TOP)/hardware/qcom/media-legacy/mm-core/inc                        \
+
+#ifeq ($(PLATFORM_SDK_VERSION), 18)
+ifeq (1,$(filter 1,$(shell echo "$$(( $(PLATFORM_SDK_VERSION) >= 18 ))" )))
+  LOCAL_CFLAGS += -DANDROID_JB_MR2
+endif
+
+LOCAL_MODULE:= libdashplayer
+
+LOCAL_MODULE_TAGS := eng
+
+include $(BUILD_SHARED_LIBRARY)
+#endif
diff --git a/dashplayer/DashCodec.cpp b/dashplayer/DashCodec.cpp
new file mode 100644
index 0000000..51e5865
--- /dev/null
+++ b/dashplayer/DashCodec.cpp
@@ -0,0 +1,4229 @@
+/*
+ * Copyright (c) 2013, The Linux Foundation. All rights reserved.
+ * Not a Contribution.
+ *
+ * Copyright (C) 2010 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+//#define LOG_NDEBUG 0
+#define LOG_TAG "DashCodec"
+
+#include "DashCodec.h"
+
+#include <binder/MemoryDealer.h>
+
+#include <media/stagefright/foundation/hexdump.h>
+#include <media/stagefright/foundation/ABuffer.h>
+#include <media/stagefright/foundation/ADebug.h>
+#include <media/stagefright/foundation/AMessage.h>
+
+#include <media/stagefright/MediaCodecList.h>
+#include <media/stagefright/MediaDefs.h>
+#include <media/stagefright/NativeWindowWrapper.h>
+#include <media/stagefright/OMXClient.h>
+#include <media/stagefright/OMXCodec.h>
+
+#include <media/hardware/HardwareAPI.h>
+#include <OMX_QCOMExtns.h>
+#include <OMX_Component.h>
+#include <cutils/properties.h>
+#include "avc_utils.h"
+
+//Smmoth streaming settings
+//Max resolution 1080p
+#define MAX_WIDTH 1920;
+#define MAX_HEIGHT 1080;
+
+//Min resolution QVGA
+#define MIN_WIDTH 480;
+#define MIN_HEIGHT 320;
+
+namespace android {
+
+template<class T>
+static void InitOMXParams(T *params) {
+    params->nSize = sizeof(T);
+    params->nVersion.s.nVersionMajor = 1;
+    params->nVersion.s.nVersionMinor = 0;
+    params->nVersion.s.nRevision = 0;
+    params->nVersion.s.nStep = 0;
+}
+
+struct CodecObserver : public BnOMXObserver {
+    CodecObserver() {}
+
+    void setNotificationMessage(const sp<AMessage> &msg) {
+        mNotify = msg;
+    }
+
+    // from IOMXObserver
+    virtual void onMessage(const omx_message &omx_msg) {
+        sp<AMessage> msg = mNotify->dup();
+
+        msg->setInt32("type", omx_msg.type);
+        msg->setPointer("node", omx_msg.node);
+
+        switch (omx_msg.type) {
+            case omx_message::EVENT:
+            {
+                msg->setInt32("event", omx_msg.u.event_data.event);
+                msg->setInt32("data1", omx_msg.u.event_data.data1);
+                msg->setInt32("data2", omx_msg.u.event_data.data2);
+                break;
+            }
+
+            case omx_message::EMPTY_BUFFER_DONE:
+            {
+                msg->setPointer("buffer", omx_msg.u.buffer_data.buffer);
+                break;
+            }
+
+            case omx_message::FILL_BUFFER_DONE:
+            {
+                msg->setPointer(
+                        "buffer", omx_msg.u.extended_buffer_data.buffer);
+                msg->setInt32(
+                        "range_offset",
+                        omx_msg.u.extended_buffer_data.range_offset);
+                msg->setInt32(
+                        "range_length",
+                        omx_msg.u.extended_buffer_data.range_length);
+                msg->setInt32(
+                        "flags",
+                        omx_msg.u.extended_buffer_data.flags);
+                msg->setInt64(
+                        "timestamp",
+                        omx_msg.u.extended_buffer_data.timestamp);
+                msg->setPointer(
+                        "platform_private",
+                        omx_msg.u.extended_buffer_data.platform_private);
+                msg->setPointer(
+                        "data_ptr",
+                        omx_msg.u.extended_buffer_data.data_ptr);
+                break;
+            }
+
+            default:
+                TRESPASS();
+                break;
+        }
+
+        msg->post();
+    }
+
+protected:
+    virtual ~CodecObserver() {}
+
+private:
+    sp<AMessage> mNotify;
+
+    DISALLOW_EVIL_CONSTRUCTORS(CodecObserver);
+};
+
+////////////////////////////////////////////////////////////////////////////////
+
+struct DashCodec::BaseState : public AState {
+    BaseState(DashCodec *codec, const sp<AState> &parentState = NULL);
+
+protected:
+    enum PortMode {
+        KEEP_BUFFERS,
+        RESUBMIT_BUFFERS,
+        FREE_BUFFERS,
+    };
+
+    DashCodec *mCodec;
+
+    virtual PortMode getPortMode(OMX_U32 portIndex);
+
+    virtual bool onMessageReceived(const sp<AMessage> &msg);
+
+    virtual bool onOMXEvent(OMX_EVENTTYPE event, OMX_U32 data1, OMX_U32 data2);
+
+    virtual void onOutputBufferDrained(const sp<AMessage> &msg);
+    virtual void onInputBufferFilled(const sp<AMessage> &msg);
+
+    void postFillThisBuffer(BufferInfo *info);
+
+private:
+    bool onOMXMessage(const sp<AMessage> &msg);
+
+    bool onOMXEmptyBufferDone(IOMX::buffer_id bufferID);
+
+    bool onOMXFillBufferDone(
+            IOMX::buffer_id bufferID,
+            size_t rangeOffset, size_t rangeLength,
+            OMX_U32 flags,
+            int64_t timeUs,
+            void *platformPrivate,
+            void *dataPtr);
+
+    void getMoreInputDataIfPossible();
+
+    DISALLOW_EVIL_CONSTRUCTORS(BaseState);
+};
+
+////////////////////////////////////////////////////////////////////////////////
+
+struct DashCodec::UninitializedState : public DashCodec::BaseState {
+    UninitializedState(DashCodec *codec);
+
+protected:
+    virtual bool onMessageReceived(const sp<AMessage> &msg);
+    virtual void stateEntered();
+
+private:
+    void onSetup(const sp<AMessage> &msg);
+    bool onAllocateComponent(const sp<AMessage> &msg);
+
+    DISALLOW_EVIL_CONSTRUCTORS(UninitializedState);
+};
+
+////////////////////////////////////////////////////////////////////////////////
+
+struct DashCodec::LoadedState : public DashCodec::BaseState {
+    LoadedState(DashCodec *codec);
+
+protected:
+    virtual bool onMessageReceived(const sp<AMessage> &msg);
+    virtual void stateEntered();
+
+private:
+    friend struct DashCodec::UninitializedState;
+
+    bool onConfigureComponent(const sp<AMessage> &msg);
+    void onStart();
+    void onShutdown(bool keepComponentAllocated);
+
+    DISALLOW_EVIL_CONSTRUCTORS(LoadedState);
+};
+
+////////////////////////////////////////////////////////////////////////////////
+
+struct DashCodec::LoadedToIdleState : public DashCodec::BaseState {
+    LoadedToIdleState(DashCodec *codec);
+
+protected:
+    virtual bool onMessageReceived(const sp<AMessage> &msg);
+    virtual bool onOMXEvent(OMX_EVENTTYPE event, OMX_U32 data1, OMX_U32 data2);
+    virtual void stateEntered();
+
+private:
+    status_t allocateBuffers();
+
+    DISALLOW_EVIL_CONSTRUCTORS(LoadedToIdleState);
+};
+
+////////////////////////////////////////////////////////////////////////////////
+
+struct DashCodec::IdleToExecutingState : public DashCodec::BaseState {
+    IdleToExecutingState(DashCodec *codec);
+
+protected:
+    virtual bool onMessageReceived(const sp<AMessage> &msg);
+    virtual bool onOMXEvent(OMX_EVENTTYPE event, OMX_U32 data1, OMX_U32 data2);
+    virtual void stateEntered();
+
+private:
+    DISALLOW_EVIL_CONSTRUCTORS(IdleToExecutingState);
+};
+
+////////////////////////////////////////////////////////////////////////////////
+
+struct DashCodec::ExecutingState : public DashCodec::BaseState {
+    ExecutingState(DashCodec *codec);
+
+    void submitOutputBuffers();
+
+    // Submit output buffers to the decoder, submit input buffers to client
+    // to fill with data.
+    void resume();
+
+    // Returns true iff input and output buffers are in play.
+    bool active() const { return mActive; }
+
+protected:
+    virtual PortMode getPortMode(OMX_U32 portIndex);
+    virtual bool onMessageReceived(const sp<AMessage> &msg);
+    virtual void stateEntered();
+
+    virtual bool onOMXEvent(OMX_EVENTTYPE event, OMX_U32 data1, OMX_U32 data2);
+
+private:
+    bool mActive;
+
+    DISALLOW_EVIL_CONSTRUCTORS(ExecutingState);
+};
+
+////////////////////////////////////////////////////////////////////////////////
+
+struct DashCodec::OutputPortSettingsChangedState : public DashCodec::BaseState {
+    OutputPortSettingsChangedState(DashCodec *codec);
+
+protected:
+    virtual PortMode getPortMode(OMX_U32 portIndex);
+    virtual bool onMessageReceived(const sp<AMessage> &msg);
+    virtual void stateEntered();
+
+    virtual bool onOMXEvent(OMX_EVENTTYPE event, OMX_U32 data1, OMX_U32 data2);
+
+private:
+    DISALLOW_EVIL_CONSTRUCTORS(OutputPortSettingsChangedState);
+};
+
+////////////////////////////////////////////////////////////////////////////////
+
+struct DashCodec::ExecutingToIdleState : public DashCodec::BaseState {
+    ExecutingToIdleState(DashCodec *codec);
+
+protected:
+    virtual bool onMessageReceived(const sp<AMessage> &msg);
+    virtual void stateEntered();
+
+    virtual bool onOMXEvent(OMX_EVENTTYPE event, OMX_U32 data1, OMX_U32 data2);
+
+    virtual void onOutputBufferDrained(const sp<AMessage> &msg);
+    virtual void onInputBufferFilled(const sp<AMessage> &msg);
+
+private:
+    void changeStateIfWeOwnAllBuffers();
+
+    bool mComponentNowIdle;
+
+    DISALLOW_EVIL_CONSTRUCTORS(ExecutingToIdleState);
+};
+
+////////////////////////////////////////////////////////////////////////////////
+
+struct DashCodec::IdleToLoadedState : public DashCodec::BaseState {
+    IdleToLoadedState(DashCodec *codec);
+
+protected:
+    virtual bool onMessageReceived(const sp<AMessage> &msg);
+    virtual void stateEntered();
+
+    virtual bool onOMXEvent(OMX_EVENTTYPE event, OMX_U32 data1, OMX_U32 data2);
+
+private:
+    DISALLOW_EVIL_CONSTRUCTORS(IdleToLoadedState);
+};
+
+////////////////////////////////////////////////////////////////////////////////
+
+struct DashCodec::FlushingState : public DashCodec::BaseState {
+    FlushingState(DashCodec *codec);
+
+protected:
+    virtual bool onMessageReceived(const sp<AMessage> &msg);
+    virtual void stateEntered();
+
+    virtual bool onOMXEvent(OMX_EVENTTYPE event, OMX_U32 data1, OMX_U32 data2);
+
+    virtual void onOutputBufferDrained(const sp<AMessage> &msg);
+    virtual void onInputBufferFilled(const sp<AMessage> &msg);
+
+private:
+    bool mFlushComplete[2];
+
+    void changeStateIfWeOwnAllBuffers();
+
+    DISALLOW_EVIL_CONSTRUCTORS(FlushingState);
+};
+
+////////////////////////////////////////////////////////////////////////////////
+
+struct DashCodec::FlushingOutputState : public DashCodec::BaseState {
+    FlushingOutputState(DashCodec *codec);
+
+protected:
+    virtual PortMode getPortMode(OMX_U32 portIndex);
+    virtual bool onMessageReceived(const sp<AMessage> &msg);
+    virtual void stateEntered();
+
+    virtual bool onOMXEvent(OMX_EVENTTYPE event, OMX_U32 data1, OMX_U32 data2);
+
+    virtual void onOutputBufferDrained(const sp<AMessage> &msg);
+    virtual void onInputBufferFilled(const sp<AMessage> &msg);
+
+private:
+    bool mFlushComplete;
+
+    void changeStateIfWeOwnAllBuffers();
+
+    DISALLOW_EVIL_CONSTRUCTORS(FlushingOutputState);
+};
+
+////////////////////////////////////////////////////////////////////////////////
+
+DashCodec::DashCodec()
+    : mQuirks(0),
+      mNode(NULL),
+      mSentFormat(false),
+      mPostFormat(false),
+      mIsEncoder(false),
+      mShutdownInProgress(false),
+      mEncoderDelay(0),
+      mEncoderPadding(0),
+      mChannelMaskPresent(false),
+      mChannelMask(0),
+      mAdaptivePlayback(false){
+    mUninitializedState = new UninitializedState(this);
+    mLoadedState = new LoadedState(this);
+    mLoadedToIdleState = new LoadedToIdleState(this);
+    mIdleToExecutingState = new IdleToExecutingState(this);
+    mExecutingState = new ExecutingState(this);
+
+    mOutputPortSettingsChangedState =
+        new OutputPortSettingsChangedState(this);
+
+    mExecutingToIdleState = new ExecutingToIdleState(this);
+    mIdleToLoadedState = new IdleToLoadedState(this);
+    mFlushingState = new FlushingState(this);
+    mFlushingOutputState = new FlushingOutputState(this);
+
+    mPortEOS[kPortIndexInput] = mPortEOS[kPortIndexOutput] = false;
+    mInputEOSResult = OK;
+
+    changeState(mUninitializedState);
+}
+
+DashCodec::~DashCodec() {
+  clearCachedFormats();
+}
+
+void DashCodec::setNotificationMessage(const sp<AMessage> &msg) {
+    mNotify = msg;
+}
+
+void DashCodec::initiateSetup(const sp<AMessage> &msg) {
+    msg->setWhat(kWhatSetup);
+    msg->setTarget(id());
+    msg->post();
+}
+
+void DashCodec::initiateAllocateComponent(const sp<AMessage> &msg) {
+    msg->setWhat(kWhatAllocateComponent);
+    msg->setTarget(id());
+    msg->post();
+}
+
+void DashCodec::initiateConfigureComponent(const sp<AMessage> &msg) {
+    msg->setWhat(kWhatConfigureComponent);
+    msg->setTarget(id());
+    msg->post();
+}
+
+void DashCodec::initiateStart() {
+    (new AMessage(kWhatStart, id()))->post();
+}
+
+void DashCodec::signalFlush() {
+    ALOGV("[%s] signalFlush", mComponentName.c_str());
+    (new AMessage(kWhatFlush, id()))->post();
+}
+
+void DashCodec::signalResume() {
+    (new AMessage(kWhatResume, id()))->post();
+}
+
+void DashCodec::initiateShutdown(bool keepComponentAllocated) {
+    sp<AMessage> msg = new AMessage(kWhatShutdown, id());
+    msg->setInt32("keepComponentAllocated", keepComponentAllocated);
+    msg->post();
+}
+
+void DashCodec::signalRequestIDRFrame() {
+    (new AMessage(kWhatRequestIDRFrame, id()))->post();
+}
+
+status_t DashCodec::allocateBuffersOnPort(OMX_U32 portIndex) {
+    CHECK(portIndex == kPortIndexInput || portIndex == kPortIndexOutput);
+
+    CHECK(mDealer[portIndex] == NULL);
+    CHECK(mBuffers[portIndex].isEmpty());
+
+    status_t err;
+    if (mNativeWindow != NULL && portIndex == kPortIndexOutput) {
+        err = allocateOutputBuffersFromNativeWindow();
+    } else {
+        OMX_PARAM_PORTDEFINITIONTYPE def;
+        InitOMXParams(&def);
+        def.nPortIndex = portIndex;
+
+        err = mOMX->getParameter(
+                mNode, OMX_IndexParamPortDefinition, &def, sizeof(def));
+
+        if (err == OK) {
+            ALOGV("[%s] Allocating %lu buffers of size %lu on %s port",
+                    mComponentName.c_str(),
+                    def.nBufferCountActual, def.nBufferSize,
+                    portIndex == kPortIndexInput ? "input" : "output");
+
+            size_t totalSize = def.nBufferCountActual * def.nBufferSize;
+            mDealer[portIndex] = new MemoryDealer(totalSize, "DashCodec");
+
+            for (OMX_U32 i = 0; i < def.nBufferCountActual; ++i) {
+                sp<IMemory> mem = mDealer[portIndex]->allocate(def.nBufferSize);
+                CHECK(mem.get() != NULL);
+
+                BufferInfo info;
+                info.mStatus = BufferInfo::OWNED_BY_US;
+
+                uint32_t requiresAllocateBufferBit =
+                    (portIndex == kPortIndexInput)
+                        ? OMXCodec::kRequiresAllocateBufferOnInputPorts
+                        : OMXCodec::kRequiresAllocateBufferOnOutputPorts;
+
+                if (portIndex == kPortIndexInput && (mFlags & kFlagIsSecure)) {
+                    mem.clear();
+
+                    void *ptr;
+                    err = mOMX->allocateBuffer(
+                            mNode, portIndex, def.nBufferSize, &info.mBufferID,
+                            &ptr);
+
+                    info.mData = new ABuffer(ptr, def.nBufferSize);
+                } else if (mQuirks & requiresAllocateBufferBit) {
+                    err = mOMX->allocateBufferWithBackup(
+                            mNode, portIndex, mem, &info.mBufferID);
+                } else {
+                    err = mOMX->useBuffer(mNode, portIndex, mem, &info.mBufferID);
+                }
+
+                if (mem != NULL) {
+                    info.mData = new ABuffer(mem->pointer(), def.nBufferSize);
+                }
+
+                mBuffers[portIndex].push(info);
+            }
+        }
+    }
+
+    if (err != OK) {
+        return err;
+    }
+
+    sp<AMessage> notify = mNotify->dup();
+    notify->setInt32("what", DashCodec::kWhatBuffersAllocated);
+
+    notify->setInt32("portIndex", portIndex);
+
+    sp<PortDescription> desc = new PortDescription;
+
+    for (size_t i = 0; i < mBuffers[portIndex].size(); ++i) {
+        const BufferInfo &info = mBuffers[portIndex][i];
+
+        desc->addBuffer(info.mBufferID, info.mData);
+    }
+
+    notify->setObject("portDesc", desc);
+    notify->post();
+
+    return OK;
+}
+
+status_t DashCodec::allocateOutputBuffersFromNativeWindow() {
+    OMX_PARAM_PORTDEFINITIONTYPE def;
+    InitOMXParams(&def);
+    def.nPortIndex = kPortIndexOutput;
+
+    status_t err = mOMX->getParameter(
+            mNode, OMX_IndexParamPortDefinition, &def, sizeof(def));
+
+    if (err != OK) {
+        return err;
+    }
+
+    err = native_window_set_buffers_geometry(
+            mNativeWindow.get(),
+            def.format.video.nFrameWidth,
+            def.format.video.nFrameHeight,
+            def.format.video.eColorFormat);
+
+    if (err != 0) {
+        ALOGE("native_window_set_buffers_geometry failed: %s (%d)",
+                strerror(-err), -err);
+        return err;
+    }
+
+    // Set up the native window.
+    OMX_U32 usage = 0;
+    err = mOMX->getGraphicBufferUsage(mNode, kPortIndexOutput, &usage);
+    if (err != 0) {
+        ALOGW("querying usage flags from OMX IL component failed: %d", err);
+        // XXX: Currently this error is logged, but not fatal.
+        usage = 0;
+    }
+
+    if (mFlags & kFlagIsSecure || mFlags & kFlagIsSecureOPOnly) {
+        usage |= GRALLOC_USAGE_PROTECTED;
+    }
+
+    // Make sure to check whether either Stagefright or the video decoder
+    // requested protected buffers.
+    if (usage & GRALLOC_USAGE_PROTECTED) {
+        // Verify that the ANativeWindow sends images directly to
+        // SurfaceFlinger.
+        int queuesToNativeWindow = 0;
+        err = mNativeWindow->query(
+                mNativeWindow.get(), NATIVE_WINDOW_QUEUES_TO_WINDOW_COMPOSER,
+                &queuesToNativeWindow);
+        if (err != 0) {
+            ALOGE("error authenticating native window: %d", err);
+            return err;
+        }
+        if (queuesToNativeWindow != 1) {
+            ALOGE("native window could not be authenticated");
+            return PERMISSION_DENIED;
+        }
+    }
+
+    err = native_window_set_usage(
+            mNativeWindow.get(),
+            usage | GRALLOC_USAGE_HW_TEXTURE | GRALLOC_USAGE_EXTERNAL_DISP);
+
+    if (err != 0) {
+        ALOGE("native_window_set_usage failed: %s (%d)", strerror(-err), -err);
+        return err;
+    }
+
+    int minUndequeuedBufs = 0;
+    err = mNativeWindow->query(
+            mNativeWindow.get(), NATIVE_WINDOW_MIN_UNDEQUEUED_BUFFERS,
+            &minUndequeuedBufs);
+
+    if (err != 0) {
+        ALOGE("NATIVE_WINDOW_MIN_UNDEQUEUED_BUFFERS query failed: %s (%d)",
+                strerror(-err), -err);
+        return err;
+    }
+
+    // XXX: Is this the right logic to use?  It's not clear to me what the OMX
+    // buffer counts refer to - how do they account for the renderer holding on
+    // to buffers?
+    if (def.nBufferCountActual < def.nBufferCountMin + minUndequeuedBufs) {
+        OMX_U32 newBufferCount = def.nBufferCountMin + minUndequeuedBufs;
+        def.nBufferCountActual = newBufferCount;
+
+        //Keep an extra buffer for smooth streaming
+        if (mAdaptivePlayback) {
+            def.nBufferCountActual += 1;
+        }
+
+        err = mOMX->setParameter(
+                mNode, OMX_IndexParamPortDefinition, &def, sizeof(def));
+
+        if (err != OK) {
+            ALOGE("[%s] setting nBufferCountActual to %lu failed: %d",
+                    mComponentName.c_str(), newBufferCount, err);
+            return err;
+        }
+    }
+
+
+    err = native_window_set_buffer_count(
+            mNativeWindow.get(), def.nBufferCountActual);
+
+    if (err != 0) {
+        ALOGE("native_window_set_buffer_count failed: %s (%d)", strerror(-err),
+                -err);
+        return err;
+    }
+
+    ALOGV("[%s] Allocating %lu buffers from a native window of size %lu on "
+         "output port",
+         mComponentName.c_str(), def.nBufferCountActual, def.nBufferSize);
+
+    // Dequeue buffers and send them to OMX
+    for (OMX_U32 i = 0; i < def.nBufferCountActual; i++) {
+        ANativeWindowBuffer *buf;
+        err = native_window_dequeue_buffer_and_wait(mNativeWindow.get(), &buf);
+        if (err != 0) {
+            ALOGE("dequeueBuffer failed: %s (%d)", strerror(-err), -err);
+            break;
+        }
+
+        sp<GraphicBuffer> graphicBuffer(new GraphicBuffer(buf, false));
+        BufferInfo info;
+        info.mStatus = BufferInfo::OWNED_BY_US;
+        info.mData = new ABuffer(0);
+        info.mGraphicBuffer = graphicBuffer;
+        mBuffers[kPortIndexOutput].push(info);
+
+        IOMX::buffer_id bufferId;
+        err = mOMX->useGraphicBuffer(mNode, kPortIndexOutput, graphicBuffer,
+                &bufferId);
+        if (err != 0) {
+            ALOGE("registering GraphicBuffer %lu with OMX IL component failed: "
+                 "%d", i, err);
+            break;
+        }
+
+        mBuffers[kPortIndexOutput].editItemAt(i).mBufferID = bufferId;
+
+        ALOGV("[%s] Registered graphic buffer with ID %p (pointer = %p)",
+             mComponentName.c_str(),
+             bufferId, graphicBuffer.get());
+    }
+
+    OMX_U32 cancelStart;
+    OMX_U32 cancelEnd;
+
+    if (err != 0) {
+        // If an error occurred while dequeuing we need to cancel any buffers
+        // that were dequeued.
+        cancelStart = 0;
+        cancelEnd = mBuffers[kPortIndexOutput].size();
+    } else {
+        // Return the last two buffers to the native window.
+        cancelStart = def.nBufferCountActual - minUndequeuedBufs;
+        cancelEnd = def.nBufferCountActual;
+    }
+
+    for (OMX_U32 i = cancelStart; i < cancelEnd; i++) {
+        BufferInfo *info = &mBuffers[kPortIndexOutput].editItemAt(i);
+        cancelBufferToNativeWindow(info);
+    }
+
+    return err;
+}
+
+status_t DashCodec::cancelBufferToNativeWindow(BufferInfo *info) {
+    CHECK_EQ((int)info->mStatus, (int)BufferInfo::OWNED_BY_US);
+
+    ALOGV("[%s] Calling cancelBuffer on buffer %p",
+         mComponentName.c_str(), info->mBufferID);
+
+    int err = mNativeWindow->cancelBuffer(
+        mNativeWindow.get(), info->mGraphicBuffer.get(), -1);
+
+    CHECK_EQ(err, 0);
+
+    info->mStatus = BufferInfo::OWNED_BY_NATIVE_WINDOW;
+
+    return OK;
+}
+
+DashCodec::BufferInfo *DashCodec::dequeueBufferFromNativeWindow() {
+    ANativeWindowBuffer *buf;
+    int fenceFd = -1;
+    if (native_window_dequeue_buffer_and_wait(mNativeWindow.get(), &buf) != 0) {
+        ALOGE("dequeueBuffer failed.");
+        return NULL;
+    }
+
+    for (size_t i = mBuffers[kPortIndexOutput].size(); i-- > 0;) {
+        BufferInfo *info =
+            &mBuffers[kPortIndexOutput].editItemAt(i);
+
+        if (info->mGraphicBuffer->handle == buf->handle) {
+            CHECK_EQ((int)info->mStatus,
+                     (int)BufferInfo::OWNED_BY_NATIVE_WINDOW);
+
+            info->mStatus = BufferInfo::OWNED_BY_US;
+
+            return info;
+        }
+    }
+
+    TRESPASS();
+
+    return NULL;
+}
+
+status_t DashCodec::freeBuffersOnPort(OMX_U32 portIndex) {
+    for (size_t i = mBuffers[portIndex].size(); i-- > 0;) {
+        CHECK_EQ((status_t)OK, freeBuffer(portIndex, i));
+    }
+
+    mDealer[portIndex].clear();
+
+    return OK;
+}
+
+status_t DashCodec::freeOutputBuffersNotOwnedByComponent() {
+    for (size_t i = mBuffers[kPortIndexOutput].size(); i-- > 0;) {
+        BufferInfo *info =
+            &mBuffers[kPortIndexOutput].editItemAt(i);
+
+        if (info->mStatus !=
+                BufferInfo::OWNED_BY_COMPONENT) {
+            // We shouldn't have sent out any buffers to the client at this
+            // point.
+            CHECK_NE((int)info->mStatus, (int)BufferInfo::OWNED_BY_DOWNSTREAM);
+
+            CHECK_EQ((status_t)OK, freeBuffer(kPortIndexOutput, i));
+        }
+    }
+
+    return OK;
+}
+
+status_t DashCodec::freeBuffer(OMX_U32 portIndex, size_t i) {
+    BufferInfo *info = &mBuffers[portIndex].editItemAt(i);
+
+    CHECK(info->mStatus == BufferInfo::OWNED_BY_US
+            || info->mStatus == BufferInfo::OWNED_BY_NATIVE_WINDOW);
+
+    if (portIndex == kPortIndexOutput && mNativeWindow != NULL
+            && info->mStatus == BufferInfo::OWNED_BY_US) {
+        CHECK_EQ((status_t)OK, cancelBufferToNativeWindow(info));
+    }
+
+    CHECK_EQ(mOMX->freeBuffer(
+                mNode, portIndex, info->mBufferID),
+             (status_t)OK);
+
+    mBuffers[portIndex].removeAt(i);
+
+    return OK;
+}
+
+DashCodec::BufferInfo *DashCodec::findBufferByID(
+        uint32_t portIndex, IOMX::buffer_id bufferID,
+        ssize_t *index) {
+    for (size_t i = 0; i < mBuffers[portIndex].size(); ++i) {
+        BufferInfo *info = &mBuffers[portIndex].editItemAt(i);
+
+        if (info->mBufferID == bufferID) {
+            if (index != NULL) {
+                *index = i;
+            }
+            return info;
+        }
+    }
+
+    TRESPASS();
+
+    return NULL;
+}
+
+status_t DashCodec::setComponentRole(
+        bool isEncoder, const char *mime) {
+    struct MimeToRole {
+        const char *mime;
+        const char *decoderRole;
+        const char *encoderRole;
+    };
+
+    static const MimeToRole kMimeToRole[] = {
+        { MEDIA_MIMETYPE_AUDIO_MPEG,
+            "audio_decoder.mp3", "audio_encoder.mp3" },
+        { MEDIA_MIMETYPE_AUDIO_MPEG_LAYER_I,
+            "audio_decoder.mp1", "audio_encoder.mp1" },
+        { MEDIA_MIMETYPE_AUDIO_MPEG_LAYER_II,
+            "audio_decoder.mp2", "audio_encoder.mp2" },
+        { MEDIA_MIMETYPE_AUDIO_AMR_NB,
+            "audio_decoder.amrnb", "audio_encoder.amrnb" },
+        { MEDIA_MIMETYPE_AUDIO_AMR_WB,
+            "audio_decoder.amrwb", "audio_encoder.amrwb" },
+        // commenting out AMR_WM_PLUS for bringing up dash on MR2
+        /* { MEDIA_MIMETYPE_AUDIO_AMR_WB_PLUS,
+            "audio_decoder.amrwbplus", "audio_encoder.amrwbplus" },*/
+        { MEDIA_MIMETYPE_AUDIO_AAC,
+            "audio_decoder.aac", "audio_encoder.aac" },
+        { MEDIA_MIMETYPE_AUDIO_VORBIS,
+            "audio_decoder.vorbis", "audio_encoder.vorbis" },
+        { MEDIA_MIMETYPE_AUDIO_G711_MLAW,
+            "audio_decoder.g711mlaw", "audio_encoder.g711mlaw" },
+        { MEDIA_MIMETYPE_AUDIO_G711_ALAW,
+            "audio_decoder.g711alaw", "audio_encoder.g711alaw" },
+        { MEDIA_MIMETYPE_VIDEO_AVC,
+            "video_decoder.avc", "video_encoder.avc" },
+        { MEDIA_MIMETYPE_VIDEO_MPEG4,
+            "video_decoder.mpeg4", "video_encoder.mpeg4" },
+        { MEDIA_MIMETYPE_VIDEO_H263,
+            "video_decoder.h263", "video_encoder.h263" },
+        { MEDIA_MIMETYPE_VIDEO_VP8,
+            "video_decoder.vpx", "video_encoder.vpx" },
+        { MEDIA_MIMETYPE_AUDIO_RAW,
+            "audio_decoder.raw", "audio_encoder.raw" },
+        { MEDIA_MIMETYPE_AUDIO_FLAC,
+            "audio_decoder.flac", "audio_encoder.flac" },
+    };
+
+    static const size_t kNumMimeToRole =
+        sizeof(kMimeToRole) / sizeof(kMimeToRole[0]);
+
+    size_t i;
+    for (i = 0; i < kNumMimeToRole; ++i) {
+        if (!strcasecmp(mime, kMimeToRole[i].mime)) {
+            break;
+        }
+    }
+
+    if (i == kNumMimeToRole) {
+        return ERROR_UNSUPPORTED;
+    }
+
+    const char *role =
+        isEncoder ? kMimeToRole[i].encoderRole
+                  : kMimeToRole[i].decoderRole;
+
+    if (role != NULL) {
+        OMX_PARAM_COMPONENTROLETYPE roleParams;
+        InitOMXParams(&roleParams);
+
+        strncpy((char *)roleParams.cRole,
+                role, OMX_MAX_STRINGNAME_SIZE - 1);
+
+        roleParams.cRole[OMX_MAX_STRINGNAME_SIZE - 1] = '\0';
+
+        status_t err = mOMX->setParameter(
+                mNode, OMX_IndexParamStandardComponentRole,
+                &roleParams, sizeof(roleParams));
+
+        if (err != OK) {
+            ALOGW("[%s] Failed to set standard component role '%s'.",
+                 mComponentName.c_str(), role);
+
+            return err;
+        }
+    }
+
+    return OK;
+}
+
+status_t DashCodec::configureCodec(
+        const char *mime, const sp<AMessage> &msg) {
+    int32_t encoder;
+    if (!msg->findInt32("encoder", &encoder)) {
+        encoder = false;
+    }
+
+    mIsEncoder = encoder;
+
+    status_t err = setComponentRole(encoder /* isEncoder */, mime);
+
+    if (err != OK) {
+        return err;
+    }
+
+    int32_t bitRate = 0;
+    // FLAC encoder doesn't need a bitrate, other encoders do
+    if (encoder && strcasecmp(mime, MEDIA_MIMETYPE_AUDIO_FLAC)
+            && !msg->findInt32("bitrate", &bitRate)) {
+        return INVALID_OPERATION;
+    }
+
+    int32_t storeMeta;
+    if (encoder
+            && msg->findInt32("store-metadata-in-buffers", &storeMeta)
+            && storeMeta != 0) {
+        err = mOMX->storeMetaDataInBuffers(mNode, kPortIndexInput, OMX_TRUE);
+
+        if (err != OK) {
+            ALOGE("[%s] storeMetaDataInBuffers failed w/ err %d",
+                  mComponentName.c_str(), err);
+
+            return err;
+        }
+    }
+
+    int32_t prependSPSPPS;
+    if (encoder
+            && msg->findInt32("prepend-sps-pps-to-idr-frames", &prependSPSPPS)
+            && prependSPSPPS != 0) {
+        OMX_INDEXTYPE index;
+        err = mOMX->getExtensionIndex(
+                mNode,
+                "OMX.google.android.index.prependSPSPPSToIDRFrames",
+                &index);
+
+        if (err == OK) {
+            PrependSPSPPSToIDRFramesParams params;
+            InitOMXParams(&params);
+            params.bEnable = OMX_TRUE;
+
+            err = mOMX->setParameter(
+                    mNode, index, &params, sizeof(params));
+        }
+
+        if (err != OK) {
+            ALOGE("Encoder could not be configured to emit SPS/PPS before "
+                  "IDR frames. (err %d)", err);
+
+            return err;
+        }
+    }
+
+    // Always try to enable dynamic output buffers on native surface
+    int32_t video = !strncasecmp(mime, "video/", 6);
+    sp<RefBase> obj;
+    int32_t haveNativeWindow = msg->findObject("native-window", &obj) &&
+            obj != NULL;
+    if (!encoder && video && haveNativeWindow) {
+        err = mOMX->storeMetaDataInBuffers(mNode, kPortIndexOutput, OMX_TRUE);
+        if (err != OK) {
+
+            ALOGE("[%s] storeMetaDataInBuffers failed w/ err %d",
+                  mComponentName.c_str(), err);
+
+            // if adaptive playback has been requested, try JB fallback
+            // NOTE: THIS FALLBACK MECHANISM WILL BE REMOVED DUE TO ITS
+            // LARGE MEMORY REQUIREMENT
+
+            // we will not do adaptive playback on software accessed
+            // surfaces as they never had to respond to changes in the
+            // crop window, and we don't trust that they will be able to.
+            int usageBits = 0;
+
+            sp<NativeWindowWrapper> windowWrapper(
+                    static_cast<NativeWindowWrapper *>(obj.get()));
+            sp<ANativeWindow> nativeWindow = windowWrapper->getNativeWindow();
+
+            if (nativeWindow->query(
+                    nativeWindow.get(),
+                    NATIVE_WINDOW_CONSUMER_USAGE_BITS,
+                    &usageBits) != OK) {
+            } else {
+                mAdaptivePlayback =
+                    (usageBits &
+                            (GRALLOC_USAGE_SW_READ_MASK |
+                             GRALLOC_USAGE_SW_WRITE_MASK)) == 0;
+            }
+            int32_t maxWidth = MAX_WIDTH;
+            int32_t maxHeight = MAX_HEIGHT;
+            if (mAdaptivePlayback) {
+                ALOGV("[%s] prepareForAdaptivePlayback(%ldx%ld)",
+                      mComponentName.c_str(), maxWidth, maxHeight);
+
+                err = mOMX->prepareForAdaptivePlayback(
+                        mNode, kPortIndexOutput, OMX_TRUE, maxWidth, maxHeight);
+                if (err != OK)
+                {
+                  ALOGE("[%s] prepareForAdaptivePlayback failed w/ err %d",
+                        mComponentName.c_str(), err);
+                }
+                else
+                {
+                  ALOGV("[%s] prepareForAdaptivePlayback : Success",
+                        mComponentName.c_str(), err);
+            }
+          }
+            // allow failure
+            err = OK;
+        } else {
+            ALOGV("[%s] storeMetaDataInBuffers succeeded", mComponentName.c_str());
+        }
+    }
+
+    if (!strncasecmp(mime, "video/", 6)) {
+        if (encoder) {
+            err = setupVideoEncoder(mime, msg);
+        } else {
+            int32_t width, height;
+            if (!msg->findInt32("width", &width)
+                    || !msg->findInt32("height", &height)) {
+                err = INVALID_OPERATION;
+            } else {
+                //override height & width with max for smooth streaming
+                if (mAdaptivePlayback) {
+                    width = MAX_WIDTH;
+                    height = MAX_HEIGHT;
+                }
+                err = setupVideoDecoder(mime, width, height);
+            }
+        }
+    } else if (!strcasecmp(mime, MEDIA_MIMETYPE_AUDIO_AAC)) {
+        int32_t numChannels, sampleRate;
+        if (!msg->findInt32("channel-count", &numChannels)
+                || !msg->findInt32("sample-rate", &sampleRate)) {
+            err = INVALID_OPERATION;
+        } else {
+            int32_t isADTS, aacProfile;
+            if (!msg->findInt32("is-adts", &isADTS)) {
+                isADTS = 0;
+            }
+            if (!msg->findInt32("aac-profile", &aacProfile)) {
+                aacProfile = OMX_AUDIO_AACObjectNull;
+            }
+
+            err = setupAACCodec(
+                    encoder, numChannels, sampleRate, bitRate, aacProfile, isADTS != 0);
+        }
+    } else if (!strcasecmp(mime, MEDIA_MIMETYPE_AUDIO_AMR_NB)) {
+        err = setupAMRCodec(encoder, false /* isWAMR */, bitRate);
+    } else if (!strcasecmp(mime, MEDIA_MIMETYPE_AUDIO_AMR_WB)) {
+        err = setupAMRCodec(encoder, true /* isWAMR */, bitRate);
+    } else if (!strcasecmp(mime, MEDIA_MIMETYPE_AUDIO_G711_ALAW)
+            || !strcasecmp(mime, MEDIA_MIMETYPE_AUDIO_G711_MLAW)) {
+        // These are PCM-like formats with a fixed sample rate but
+        // a variable number of channels.
+
+        int32_t numChannels;
+        if (!msg->findInt32("channel-count", &numChannels)) {
+            err = INVALID_OPERATION;
+        } else {
+            err = setupG711Codec(encoder, numChannels);
+        }
+    } else if (!strcasecmp(mime, MEDIA_MIMETYPE_AUDIO_FLAC)) {
+        int32_t numChannels, sampleRate, compressionLevel = -1;
+        if (encoder &&
+                (!msg->findInt32("channel-count", &numChannels)
+                        || !msg->findInt32("sample-rate", &sampleRate))) {
+            ALOGE("missing channel count or sample rate for FLAC encoder");
+            err = INVALID_OPERATION;
+        } else {
+            if (encoder) {
+                if (!msg->findInt32("flac-compression-level", &compressionLevel)) {
+                    compressionLevel = 5;// default FLAC compression level
+                } else if (compressionLevel < 0) {
+                    ALOGW("compression level %d outside [0..8] range, using 0", compressionLevel);
+                    compressionLevel = 0;
+                } else if (compressionLevel > 8) {
+                    ALOGW("compression level %d outside [0..8] range, using 8", compressionLevel);
+                    compressionLevel = 8;
+                }
+            }
+            err = setupFlacCodec(encoder, numChannels, sampleRate, compressionLevel);
+        }
+    } else if (!strcasecmp(mime, MEDIA_MIMETYPE_AUDIO_RAW)) {
+        int32_t numChannels, sampleRate;
+        if (encoder
+                || !msg->findInt32("channel-count", &numChannels)
+                || !msg->findInt32("sample-rate", &sampleRate)) {
+            err = INVALID_OPERATION;
+        } else {
+            err = setupRawAudioFormat(kPortIndexInput, sampleRate, numChannels);
+        }
+    }
+
+    if (!msg->findInt32("encoder-delay", &mEncoderDelay)) {
+        mEncoderDelay = 0;
+    }
+
+    if (!msg->findInt32("encoder-padding", &mEncoderPadding)) {
+        mEncoderPadding = 0;
+    }
+
+    if (msg->findInt32("channel-mask", &mChannelMask)) {
+        mChannelMaskPresent = true;
+    } else {
+        mChannelMaskPresent = false;
+    }
+
+    int32_t maxInputSize;
+    if (msg->findInt32("max-input-size", &maxInputSize)) {
+        err = setMinBufferSize(kPortIndexInput, (size_t)maxInputSize);
+    } else if (!strcmp("OMX.Nvidia.aac.decoder", mComponentName.c_str())) {
+        err = setMinBufferSize(kPortIndexInput, 8192);  // XXX
+    }
+
+    return err;
+}
+
+status_t DashCodec::setMinBufferSize(OMX_U32 portIndex, size_t size) {
+    OMX_PARAM_PORTDEFINITIONTYPE def;
+    InitOMXParams(&def);
+    def.nPortIndex = portIndex;
+
+    status_t err = mOMX->getParameter(
+            mNode, OMX_IndexParamPortDefinition, &def, sizeof(def));
+
+    if (err != OK) {
+        return err;
+    }
+
+    if (def.nBufferSize >= size) {
+        return OK;
+    }
+
+    def.nBufferSize = size;
+
+    err = mOMX->setParameter(
+            mNode, OMX_IndexParamPortDefinition, &def, sizeof(def));
+
+    if (err != OK) {
+        return err;
+    }
+
+    err = mOMX->getParameter(
+            mNode, OMX_IndexParamPortDefinition, &def, sizeof(def));
+
+    if (err != OK) {
+        return err;
+    }
+
+    CHECK(def.nBufferSize >= size);
+
+    return OK;
+}
+
+status_t DashCodec::selectAudioPortFormat(
+        OMX_U32 portIndex, OMX_AUDIO_CODINGTYPE desiredFormat) {
+    OMX_AUDIO_PARAM_PORTFORMATTYPE format;
+    InitOMXParams(&format);
+
+    format.nPortIndex = portIndex;
+    for (OMX_U32 index = 0;; ++index) {
+        format.nIndex = index;
+
+        status_t err = mOMX->getParameter(
+                mNode, OMX_IndexParamAudioPortFormat,
+                &format, sizeof(format));
+
+        if (err != OK) {
+            return err;
+        }
+
+        if (format.eEncoding == desiredFormat) {
+            break;
+        }
+    }
+
+    return mOMX->setParameter(
+            mNode, OMX_IndexParamAudioPortFormat, &format, sizeof(format));
+}
+
+status_t DashCodec::setupAACCodec(
+        bool encoder, int32_t numChannels, int32_t sampleRate,
+        int32_t bitRate, int32_t aacProfile, bool isADTS) {
+    if (encoder && isADTS) {
+        return -EINVAL;
+    }
+
+    status_t err = setupRawAudioFormat(
+            encoder ? kPortIndexInput : kPortIndexOutput,
+            sampleRate,
+            numChannels);
+
+    if (err != OK) {
+        return err;
+    }
+
+    if (encoder) {
+        err = selectAudioPortFormat(kPortIndexOutput, OMX_AUDIO_CodingAAC);
+
+        if (err != OK) {
+            return err;
+        }
+
+        OMX_PARAM_PORTDEFINITIONTYPE def;
+        InitOMXParams(&def);
+        def.nPortIndex = kPortIndexOutput;
+
+        err = mOMX->getParameter(
+                mNode, OMX_IndexParamPortDefinition, &def, sizeof(def));
+
+        if (err != OK) {
+            return err;
+        }
+
+        def.format.audio.bFlagErrorConcealment = OMX_TRUE;
+        def.format.audio.eEncoding = OMX_AUDIO_CodingAAC;
+
+        err = mOMX->setParameter(
+                mNode, OMX_IndexParamPortDefinition, &def, sizeof(def));
+
+        if (err != OK) {
+            return err;
+        }
+
+        OMX_AUDIO_PARAM_AACPROFILETYPE profile;
+        InitOMXParams(&profile);
+        profile.nPortIndex = kPortIndexOutput;
+
+        err = mOMX->getParameter(
+                mNode, OMX_IndexParamAudioAac, &profile, sizeof(profile));
+
+        if (err != OK) {
+            return err;
+        }
+
+        profile.nChannels = numChannels;
+
+        profile.eChannelMode =
+            (numChannels == 1)
+                ? OMX_AUDIO_ChannelModeMono: OMX_AUDIO_ChannelModeStereo;
+
+        profile.nSampleRate = sampleRate;
+        profile.nBitRate = bitRate;
+        profile.nAudioBandWidth = 0;
+        profile.nFrameLength = 0;
+        profile.nAACtools = OMX_AUDIO_AACToolAll;
+        profile.nAACERtools = OMX_AUDIO_AACERNone;
+        profile.eAACProfile = (OMX_AUDIO_AACPROFILETYPE) aacProfile;
+        profile.eAACStreamFormat = OMX_AUDIO_AACStreamFormatMP4FF;
+
+        err = mOMX->setParameter(
+                mNode, OMX_IndexParamAudioAac, &profile, sizeof(profile));
+
+        if (err != OK) {
+            return err;
+        }
+
+        return err;
+    }
+
+    OMX_AUDIO_PARAM_AACPROFILETYPE profile;
+    InitOMXParams(&profile);
+    profile.nPortIndex = kPortIndexInput;
+
+    err = mOMX->getParameter(
+            mNode, OMX_IndexParamAudioAac, &profile, sizeof(profile));
+
+    if (err != OK) {
+        return err;
+    }
+
+    profile.nChannels = numChannels;
+    profile.nSampleRate = sampleRate;
+
+    profile.eAACStreamFormat =
+        isADTS
+            ? OMX_AUDIO_AACStreamFormatMP4ADTS
+            : OMX_AUDIO_AACStreamFormatMP4FF;
+
+    return mOMX->setParameter(
+            mNode, OMX_IndexParamAudioAac, &profile, sizeof(profile));
+}
+
+static OMX_AUDIO_AMRBANDMODETYPE pickModeFromBitRate(
+        bool isAMRWB, int32_t bps) {
+    if (isAMRWB) {
+        if (bps <= 6600) {
+            return OMX_AUDIO_AMRBandModeWB0;
+        } else if (bps <= 8850) {
+            return OMX_AUDIO_AMRBandModeWB1;
+        } else if (bps <= 12650) {
+            return OMX_AUDIO_AMRBandModeWB2;
+        } else if (bps <= 14250) {
+            return OMX_AUDIO_AMRBandModeWB3;
+        } else if (bps <= 15850) {
+            return OMX_AUDIO_AMRBandModeWB4;
+        } else if (bps <= 18250) {
+            return OMX_AUDIO_AMRBandModeWB5;
+        } else if (bps <= 19850) {
+            return OMX_AUDIO_AMRBandModeWB6;
+        } else if (bps <= 23050) {
+            return OMX_AUDIO_AMRBandModeWB7;
+        }
+
+        // 23850 bps
+        return OMX_AUDIO_AMRBandModeWB8;
+    } else {  // AMRNB
+        if (bps <= 4750) {
+            return OMX_AUDIO_AMRBandModeNB0;
+        } else if (bps <= 5150) {
+            return OMX_AUDIO_AMRBandModeNB1;
+        } else if (bps <= 5900) {
+            return OMX_AUDIO_AMRBandModeNB2;
+        } else if (bps <= 6700) {
+            return OMX_AUDIO_AMRBandModeNB3;
+        } else if (bps <= 7400) {
+            return OMX_AUDIO_AMRBandModeNB4;
+        } else if (bps <= 7950) {
+            return OMX_AUDIO_AMRBandModeNB5;
+        } else if (bps <= 10200) {
+            return OMX_AUDIO_AMRBandModeNB6;
+        }
+
+        // 12200 bps
+        return OMX_AUDIO_AMRBandModeNB7;
+    }
+}
+
+status_t DashCodec::setupAMRCodec(bool encoder, bool isWAMR, int32_t bitrate) {
+    OMX_AUDIO_PARAM_AMRTYPE def;
+    InitOMXParams(&def);
+    def.nPortIndex = encoder ? kPortIndexOutput : kPortIndexInput;
+
+    status_t err =
+        mOMX->getParameter(mNode, OMX_IndexParamAudioAmr, &def, sizeof(def));
+
+    if (err != OK) {
+        return err;
+    }
+
+    def.eAMRFrameFormat = OMX_AUDIO_AMRFrameFormatFSF;
+    def.eAMRBandMode = pickModeFromBitRate(isWAMR, bitrate);
+
+    err = mOMX->setParameter(
+            mNode, OMX_IndexParamAudioAmr, &def, sizeof(def));
+
+    if (err != OK) {
+        return err;
+    }
+
+    return setupRawAudioFormat(
+            encoder ? kPortIndexInput : kPortIndexOutput,
+            isWAMR ? 16000 : 8000 /* sampleRate */,
+            1 /* numChannels */);
+}
+
+status_t DashCodec::setupG711Codec(bool encoder, int32_t numChannels) {
+    CHECK(!encoder);  // XXX TODO
+
+    return setupRawAudioFormat(
+            kPortIndexInput, 8000 /* sampleRate */, numChannels);
+}
+
+status_t DashCodec::setupFlacCodec(
+        bool encoder, int32_t numChannels, int32_t sampleRate, int32_t compressionLevel) {
+
+    if (encoder) {
+        OMX_AUDIO_PARAM_FLACTYPE def;
+        InitOMXParams(&def);
+        def.nPortIndex = kPortIndexOutput;
+
+        // configure compression level
+        status_t err = mOMX->getParameter(mNode, OMX_IndexParamAudioFlac, &def, sizeof(def));
+        if (err != OK) {
+            ALOGE("setupFlacCodec(): Error %d getting OMX_IndexParamAudioFlac parameter", err);
+            return err;
+        }
+        def.nCompressionLevel = compressionLevel;
+        err = mOMX->setParameter(mNode, OMX_IndexParamAudioFlac, &def, sizeof(def));
+        if (err != OK) {
+            ALOGE("setupFlacCodec(): Error %d setting OMX_IndexParamAudioFlac parameter", err);
+            return err;
+        }
+    }
+
+    return setupRawAudioFormat(
+            encoder ? kPortIndexInput : kPortIndexOutput,
+            sampleRate,
+            numChannels);
+}
+
+status_t DashCodec::setupRawAudioFormat(
+        OMX_U32 portIndex, int32_t sampleRate, int32_t numChannels) {
+    OMX_PARAM_PORTDEFINITIONTYPE def;
+    InitOMXParams(&def);
+    def.nPortIndex = portIndex;
+
+    status_t err = mOMX->getParameter(
+            mNode, OMX_IndexParamPortDefinition, &def, sizeof(def));
+
+    if (err != OK) {
+        return err;
+    }
+
+    def.format.audio.eEncoding = OMX_AUDIO_CodingPCM;
+
+    err = mOMX->setParameter(
+            mNode, OMX_IndexParamPortDefinition, &def, sizeof(def));
+
+    if (err != OK) {
+        return err;
+    }
+
+    OMX_AUDIO_PARAM_PCMMODETYPE pcmParams;
+    InitOMXParams(&pcmParams);
+    pcmParams.nPortIndex = portIndex;
+
+    err = mOMX->getParameter(
+            mNode, OMX_IndexParamAudioPcm, &pcmParams, sizeof(pcmParams));
+
+    if (err != OK) {
+        return err;
+    }
+
+    pcmParams.nChannels = numChannels;
+    pcmParams.eNumData = OMX_NumericalDataSigned;
+    pcmParams.bInterleaved = OMX_TRUE;
+    pcmParams.nBitPerSample = 16;
+    pcmParams.nSamplingRate = sampleRate;
+    pcmParams.ePCMMode = OMX_AUDIO_PCMModeLinear;
+
+    if (getOMXChannelMapping(numChannels, pcmParams.eChannelMapping) != OK) {
+        return OMX_ErrorNone;
+    }
+
+    return mOMX->setParameter(
+            mNode, OMX_IndexParamAudioPcm, &pcmParams, sizeof(pcmParams));
+}
+
+status_t DashCodec::setVideoPortFormatType(
+        OMX_U32 portIndex,
+        OMX_VIDEO_CODINGTYPE compressionFormat,
+        OMX_COLOR_FORMATTYPE colorFormat) {
+    OMX_VIDEO_PARAM_PORTFORMATTYPE format;
+    InitOMXParams(&format);
+    format.nPortIndex = portIndex;
+    format.nIndex = 0;
+    bool found = false;
+
+    OMX_U32 index = 0;
+    for (;;) {
+        format.nIndex = index;
+        status_t err = mOMX->getParameter(
+                mNode, OMX_IndexParamVideoPortFormat,
+                &format, sizeof(format));
+
+        if (err != OK) {
+            return err;
+        }
+
+        // The following assertion is violated by TI's video decoder.
+        // CHECK_EQ(format.nIndex, index);
+
+        if (!strcmp("OMX.TI.Video.encoder", mComponentName.c_str())) {
+            if (portIndex == kPortIndexInput
+                    && colorFormat == format.eColorFormat) {
+                // eCompressionFormat does not seem right.
+                found = true;
+                break;
+            }
+            if (portIndex == kPortIndexOutput
+                    && compressionFormat == format.eCompressionFormat) {
+                // eColorFormat does not seem right.
+                found = true;
+                break;
+            }
+        }
+
+        if (format.eCompressionFormat == compressionFormat
+            && format.eColorFormat == colorFormat) {
+            found = true;
+            break;
+        }
+
+        ++index;
+    }
+
+    if (!found) {
+        return UNKNOWN_ERROR;
+    }
+
+    status_t err = mOMX->setParameter(
+            mNode, OMX_IndexParamVideoPortFormat,
+            &format, sizeof(format));
+
+    return err;
+}
+
+status_t DashCodec::setSupportedOutputFormat() {
+    OMX_VIDEO_PARAM_PORTFORMATTYPE format;
+    InitOMXParams(&format);
+    format.nPortIndex = kPortIndexOutput;
+    format.nIndex = 0;
+
+    status_t err = mOMX->getParameter(
+            mNode, OMX_IndexParamVideoPortFormat,
+            &format, sizeof(format));
+    CHECK_EQ(err, (status_t)OK);
+    CHECK_EQ((int)format.eCompressionFormat, (int)OMX_VIDEO_CodingUnused);
+
+    CHECK(format.eColorFormat == OMX_COLOR_FormatYUV420Planar
+           || format.eColorFormat == OMX_COLOR_FormatYUV420SemiPlanar
+           || format.eColorFormat == OMX_COLOR_FormatCbYCrY
+           || format.eColorFormat == OMX_TI_COLOR_FormatYUV420PackedSemiPlanar
+           || format.eColorFormat == OMX_QCOM_COLOR_FormatYVU420SemiPlanar
+           || format.eColorFormat == OMX_QCOM_COLOR_FormatYUV420PackedSemiPlanar64x32Tile2m8ka
+           /* Commenting OMX_QCOM_COLOR_FormatYUV420PackedSemiPlanar32m for bringing up dash on mr2,
+              also looks like this is needed only for B family*/
+           //|| format.eColorFormat == OMX_QCOM_COLOR_FormatYUV420PackedSemiPlanar32m
+          );
+
+    return mOMX->setParameter(
+            mNode, OMX_IndexParamVideoPortFormat,
+            &format, sizeof(format));
+}
+
+static status_t GetVideoCodingTypeFromMime(
+        const char *mime, OMX_VIDEO_CODINGTYPE *codingType) {
+    if (!strcasecmp(MEDIA_MIMETYPE_VIDEO_AVC, mime)) {
+        *codingType = OMX_VIDEO_CodingAVC;
+    } else if (!strcasecmp(MEDIA_MIMETYPE_VIDEO_MPEG4, mime)) {
+        *codingType = OMX_VIDEO_CodingMPEG4;
+    } else if (!strcasecmp(MEDIA_MIMETYPE_VIDEO_H263, mime)) {
+        *codingType = OMX_VIDEO_CodingH263;
+    } else if (!strcasecmp(MEDIA_MIMETYPE_VIDEO_MPEG2, mime)) {
+        *codingType = OMX_VIDEO_CodingMPEG2;
+    } else if (!strcasecmp(MEDIA_MIMETYPE_VIDEO_VP8, mime)) {
+        //*codingType = OMX_VIDEO_CodingVPX;
+        *codingType = OMX_VIDEO_CodingUnused;
+    } else {
+        *codingType = OMX_VIDEO_CodingUnused;
+        return ERROR_UNSUPPORTED;
+    }
+
+    return OK;
+}
+
+status_t DashCodec::setupVideoDecoder(
+        const char *mime, int32_t width, int32_t height) {
+    OMX_VIDEO_CODINGTYPE compressionFormat;
+    status_t err = GetVideoCodingTypeFromMime(mime, &compressionFormat);
+
+    if (err != OK) {
+        return err;
+    }
+
+    err = setVideoPortFormatType(
+            kPortIndexInput, compressionFormat, OMX_COLOR_FormatUnused);
+
+    if (err != OK) {
+        return err;
+    }
+
+    err = setSupportedOutputFormat();
+
+    if (err != OK) {
+        return err;
+    }
+
+    err = setVideoFormatOnPort(
+            kPortIndexInput, width, height, compressionFormat);
+
+    if (err != OK) {
+        return err;
+    }
+
+    err = setVideoFormatOnPort(
+            kPortIndexOutput, width, height, OMX_VIDEO_CodingUnused);
+
+    if (err != OK) {
+        return err;
+    }
+
+    return OK;
+}
+
+status_t DashCodec::setupVideoEncoder(const char *mime, const sp<AMessage> &msg) {
+    int32_t tmp;
+    if (!msg->findInt32("color-format", &tmp)) {
+        return INVALID_OPERATION;
+    }
+
+    OMX_COLOR_FORMATTYPE colorFormat =
+        static_cast<OMX_COLOR_FORMATTYPE>(tmp);
+
+    status_t err = setVideoPortFormatType(
+            kPortIndexInput, OMX_VIDEO_CodingUnused, colorFormat);
+
+    if (err != OK) {
+        ALOGE("[%s] does not support color format %d",
+              mComponentName.c_str(), colorFormat);
+
+        return err;
+    }
+
+    /* Input port configuration */
+
+    OMX_PARAM_PORTDEFINITIONTYPE def;
+    InitOMXParams(&def);
+
+    OMX_VIDEO_PORTDEFINITIONTYPE *video_def = &def.format.video;
+
+    def.nPortIndex = kPortIndexInput;
+
+    err = mOMX->getParameter(
+            mNode, OMX_IndexParamPortDefinition, &def, sizeof(def));
+
+    if (err != OK) {
+        return err;
+    }
+
+    int32_t width, height, bitrate;
+    if (!msg->findInt32("width", &width)
+            || !msg->findInt32("height", &height)
+            || !msg->findInt32("bitrate", &bitrate)) {
+        return INVALID_OPERATION;
+    }
+
+    video_def->nFrameWidth = width;
+    video_def->nFrameHeight = height;
+
+    int32_t stride;
+    if (!msg->findInt32("stride", &stride)) {
+        stride = width;
+    }
+
+    video_def->nStride = stride;
+
+    int32_t sliceHeight;
+    if (!msg->findInt32("slice-height", &sliceHeight)) {
+        sliceHeight = height;
+    }
+
+    video_def->nSliceHeight = sliceHeight;
+
+    def.nBufferSize = (video_def->nStride * video_def->nSliceHeight * 3) / 2;
+
+    float frameRate;
+    if (!msg->findFloat("frame-rate", &frameRate)) {
+        int32_t tmp;
+        if (!msg->findInt32("frame-rate", &tmp)) {
+            return INVALID_OPERATION;
+        }
+        frameRate = (float)tmp;
+    }
+
+    video_def->xFramerate = (OMX_U32)(frameRate * 65536.0f);
+    video_def->eCompressionFormat = OMX_VIDEO_CodingUnused;
+    video_def->eColorFormat = colorFormat;
+
+    err = mOMX->setParameter(
+            mNode, OMX_IndexParamPortDefinition, &def, sizeof(def));
+
+    if (err != OK) {
+        ALOGE("[%s] failed to set input port definition parameters.",
+              mComponentName.c_str());
+
+        return err;
+    }
+
+    /* Output port configuration */
+
+    OMX_VIDEO_CODINGTYPE compressionFormat;
+    err = GetVideoCodingTypeFromMime(mime, &compressionFormat);
+
+    if (err != OK) {
+        return err;
+    }
+
+    err = setVideoPortFormatType(
+            kPortIndexOutput, compressionFormat, OMX_COLOR_FormatUnused);
+
+    if (err != OK) {
+        ALOGE("[%s] does not support compression format %d",
+             mComponentName.c_str(), compressionFormat);
+
+        return err;
+    }
+
+    def.nPortIndex = kPortIndexOutput;
+
+    err = mOMX->getParameter(
+            mNode, OMX_IndexParamPortDefinition, &def, sizeof(def));
+
+    if (err != OK) {
+        return err;
+    }
+
+    video_def->nFrameWidth = width;
+    video_def->nFrameHeight = height;
+    video_def->xFramerate = 0;
+    video_def->nBitrate = bitrate;
+    video_def->eCompressionFormat = compressionFormat;
+    video_def->eColorFormat = OMX_COLOR_FormatUnused;
+
+    err = mOMX->setParameter(
+            mNode, OMX_IndexParamPortDefinition, &def, sizeof(def));
+
+    if (err != OK) {
+        ALOGE("[%s] failed to set output port definition parameters.",
+              mComponentName.c_str());
+
+        return err;
+    }
+
+    switch (compressionFormat) {
+        case OMX_VIDEO_CodingMPEG4:
+            err = setupMPEG4EncoderParameters(msg);
+            break;
+
+        case OMX_VIDEO_CodingH263:
+            err = setupH263EncoderParameters(msg);
+            break;
+
+        case OMX_VIDEO_CodingAVC:
+            err = setupAVCEncoderParameters(msg);
+            break;
+
+        default:
+            break;
+    }
+
+    ALOGI("setupVideoEncoder succeeded");
+
+    return err;
+}
+
+static OMX_U32 setPFramesSpacing(int32_t iFramesInterval, int32_t frameRate) {
+    if (iFramesInterval < 0) {
+        return 0xFFFFFFFF;
+    } else if (iFramesInterval == 0) {
+        return 0;
+    }
+    OMX_U32 ret = frameRate * iFramesInterval;
+    CHECK(ret > 1);
+    return ret;
+}
+
+static OMX_VIDEO_CONTROLRATETYPE getBitrateMode(const sp<AMessage> &msg) {
+    int32_t tmp;
+    if (!msg->findInt32("bitrate-mode", &tmp)) {
+        return OMX_Video_ControlRateVariable;
+    }
+
+    return static_cast<OMX_VIDEO_CONTROLRATETYPE>(tmp);
+}
+
+status_t DashCodec::setupMPEG4EncoderParameters(const sp<AMessage> &msg) {
+    int32_t bitrate, iFrameInterval;
+    if (!msg->findInt32("bitrate", &bitrate)
+            || !msg->findInt32("i-frame-interval", &iFrameInterval)) {
+        return INVALID_OPERATION;
+    }
+
+    OMX_VIDEO_CONTROLRATETYPE bitrateMode = getBitrateMode(msg);
+
+    float frameRate;
+    if (!msg->findFloat("frame-rate", &frameRate)) {
+        int32_t tmp;
+        if (!msg->findInt32("frame-rate", &tmp)) {
+            return INVALID_OPERATION;
+        }
+        frameRate = (float)tmp;
+    }
+
+    OMX_VIDEO_PARAM_MPEG4TYPE mpeg4type;
+    InitOMXParams(&mpeg4type);
+    mpeg4type.nPortIndex = kPortIndexOutput;
+
+    status_t err = mOMX->getParameter(
+            mNode, OMX_IndexParamVideoMpeg4, &mpeg4type, sizeof(mpeg4type));
+
+    if (err != OK) {
+        return err;
+    }
+
+    mpeg4type.nSliceHeaderSpacing = 0;
+    mpeg4type.bSVH = OMX_FALSE;
+    mpeg4type.bGov = OMX_FALSE;
+
+    mpeg4type.nAllowedPictureTypes =
+        OMX_VIDEO_PictureTypeI | OMX_VIDEO_PictureTypeP;
+
+    mpeg4type.nPFrames = setPFramesSpacing(iFrameInterval, frameRate);
+    if (mpeg4type.nPFrames == 0) {
+        mpeg4type.nAllowedPictureTypes = OMX_VIDEO_PictureTypeI;
+    }
+    mpeg4type.nBFrames = 0;
+    mpeg4type.nIDCVLCThreshold = 0;
+    mpeg4type.bACPred = OMX_TRUE;
+    mpeg4type.nMaxPacketSize = 256;
+    mpeg4type.nTimeIncRes = 1000;
+    mpeg4type.nHeaderExtension = 0;
+    mpeg4type.bReversibleVLC = OMX_FALSE;
+
+    int32_t profile;
+    if (msg->findInt32("profile", &profile)) {
+        int32_t level;
+        if (!msg->findInt32("level", &level)) {
+            return INVALID_OPERATION;
+        }
+
+        err = verifySupportForProfileAndLevel(profile, level);
+
+        if (err != OK) {
+            return err;
+        }
+
+        mpeg4type.eProfile = static_cast<OMX_VIDEO_MPEG4PROFILETYPE>(profile);
+        mpeg4type.eLevel = static_cast<OMX_VIDEO_MPEG4LEVELTYPE>(level);
+    }
+
+    err = mOMX->setParameter(
+            mNode, OMX_IndexParamVideoMpeg4, &mpeg4type, sizeof(mpeg4type));
+
+    if (err != OK) {
+        return err;
+    }
+
+    err = configureBitrate(bitrate, bitrateMode);
+
+    if (err != OK) {
+        return err;
+    }
+
+    return setupErrorCorrectionParameters();
+}
+
+status_t DashCodec::setupH263EncoderParameters(const sp<AMessage> &msg) {
+    int32_t bitrate, iFrameInterval;
+    if (!msg->findInt32("bitrate", &bitrate)
+            || !msg->findInt32("i-frame-interval", &iFrameInterval)) {
+        return INVALID_OPERATION;
+    }
+
+    OMX_VIDEO_CONTROLRATETYPE bitrateMode = getBitrateMode(msg);
+
+    float frameRate;
+    if (!msg->findFloat("frame-rate", &frameRate)) {
+        int32_t tmp;
+        if (!msg->findInt32("frame-rate", &tmp)) {
+            return INVALID_OPERATION;
+        }
+        frameRate = (float)tmp;
+    }
+
+    OMX_VIDEO_PARAM_H263TYPE h263type;
+    InitOMXParams(&h263type);
+    h263type.nPortIndex = kPortIndexOutput;
+
+    status_t err = mOMX->getParameter(
+            mNode, OMX_IndexParamVideoH263, &h263type, sizeof(h263type));
+
+    if (err != OK) {
+        return err;
+    }
+
+    h263type.nAllowedPictureTypes =
+        OMX_VIDEO_PictureTypeI | OMX_VIDEO_PictureTypeP;
+
+    h263type.nPFrames = setPFramesSpacing(iFrameInterval, frameRate);
+    if (h263type.nPFrames == 0) {
+        h263type.nAllowedPictureTypes = OMX_VIDEO_PictureTypeI;
+    }
+    h263type.nBFrames = 0;
+
+    int32_t profile;
+    if (msg->findInt32("profile", &profile)) {
+        int32_t level;
+        if (!msg->findInt32("level", &level)) {
+            return INVALID_OPERATION;
+        }
+
+        err = verifySupportForProfileAndLevel(profile, level);
+
+        if (err != OK) {
+            return err;
+        }
+
+        h263type.eProfile = static_cast<OMX_VIDEO_H263PROFILETYPE>(profile);
+        h263type.eLevel = static_cast<OMX_VIDEO_H263LEVELTYPE>(level);
+    }
+
+    h263type.bPLUSPTYPEAllowed = OMX_FALSE;
+    h263type.bForceRoundingTypeToZero = OMX_FALSE;
+    h263type.nPictureHeaderRepetition = 0;
+    h263type.nGOBHeaderInterval = 0;
+
+    err = mOMX->setParameter(
+            mNode, OMX_IndexParamVideoH263, &h263type, sizeof(h263type));
+
+    if (err != OK) {
+        return err;
+    }
+
+    err = configureBitrate(bitrate, bitrateMode);
+
+    if (err != OK) {
+        return err;
+    }
+
+    return setupErrorCorrectionParameters();
+}
+
+status_t DashCodec::setupAVCEncoderParameters(const sp<AMessage> &msg) {
+    int32_t bitrate, iFrameInterval;
+    if (!msg->findInt32("bitrate", &bitrate)
+            || !msg->findInt32("i-frame-interval", &iFrameInterval)) {
+        return INVALID_OPERATION;
+    }
+
+    OMX_VIDEO_CONTROLRATETYPE bitrateMode = getBitrateMode(msg);
+
+    float frameRate;
+    if (!msg->findFloat("frame-rate", &frameRate)) {
+        int32_t tmp;
+        if (!msg->findInt32("frame-rate", &tmp)) {
+            return INVALID_OPERATION;
+        }
+        frameRate = (float)tmp;
+    }
+
+    OMX_VIDEO_PARAM_AVCTYPE h264type;
+    InitOMXParams(&h264type);
+    h264type.nPortIndex = kPortIndexOutput;
+
+    status_t err = mOMX->getParameter(
+            mNode, OMX_IndexParamVideoAvc, &h264type, sizeof(h264type));
+
+    if (err != OK) {
+        return err;
+    }
+
+    h264type.nAllowedPictureTypes =
+        OMX_VIDEO_PictureTypeI | OMX_VIDEO_PictureTypeP;
+
+    int32_t profile;
+    if (msg->findInt32("profile", &profile)) {
+        int32_t level;
+        if (!msg->findInt32("level", &level)) {
+            return INVALID_OPERATION;
+        }
+
+        err = verifySupportForProfileAndLevel(profile, level);
+
+        if (err != OK) {
+            return err;
+        }
+
+        h264type.eProfile = static_cast<OMX_VIDEO_AVCPROFILETYPE>(profile);
+        h264type.eLevel = static_cast<OMX_VIDEO_AVCLEVELTYPE>(level);
+    }
+
+    // XXX
+    if (h264type.eProfile != OMX_VIDEO_AVCProfileBaseline) {
+        ALOGW("Use baseline profile instead of %d for AVC recording",
+            h264type.eProfile);
+        h264type.eProfile = OMX_VIDEO_AVCProfileBaseline;
+    }
+
+    if (h264type.eProfile == OMX_VIDEO_AVCProfileBaseline) {
+        h264type.nSliceHeaderSpacing = 0;
+        h264type.bUseHadamard = OMX_TRUE;
+        h264type.nRefFrames = 1;
+        h264type.nBFrames = 0;
+        h264type.nPFrames = setPFramesSpacing(iFrameInterval, frameRate);
+        if (h264type.nPFrames == 0) {
+            h264type.nAllowedPictureTypes = OMX_VIDEO_PictureTypeI;
+        }
+        h264type.nRefIdx10ActiveMinus1 = 0;
+        h264type.nRefIdx11ActiveMinus1 = 0;
+        h264type.bEntropyCodingCABAC = OMX_FALSE;
+        h264type.bWeightedPPrediction = OMX_FALSE;
+        h264type.bconstIpred = OMX_FALSE;
+        h264type.bDirect8x8Inference = OMX_FALSE;
+        h264type.bDirectSpatialTemporal = OMX_FALSE;
+        h264type.nCabacInitIdc = 0;
+    }
+
+    if (h264type.nBFrames != 0) {
+        h264type.nAllowedPictureTypes |= OMX_VIDEO_PictureTypeB;
+    }
+
+    h264type.bEnableUEP = OMX_FALSE;
+    h264type.bEnableFMO = OMX_FALSE;
+    h264type.bEnableASO = OMX_FALSE;
+    h264type.bEnableRS = OMX_FALSE;
+    h264type.bFrameMBsOnly = OMX_TRUE;
+    h264type.bMBAFF = OMX_FALSE;
+    h264type.eLoopFilterMode = OMX_VIDEO_AVCLoopFilterEnable;
+
+    err = mOMX->setParameter(
+            mNode, OMX_IndexParamVideoAvc, &h264type, sizeof(h264type));
+
+    if (err != OK) {
+        return err;
+    }
+
+    return configureBitrate(bitrate, bitrateMode);
+}
+
+status_t DashCodec::verifySupportForProfileAndLevel(
+        int32_t profile, int32_t level) {
+    OMX_VIDEO_PARAM_PROFILELEVELTYPE params;
+    InitOMXParams(&params);
+    params.nPortIndex = kPortIndexOutput;
+
+    for (params.nProfileIndex = 0;; ++params.nProfileIndex) {
+        status_t err = mOMX->getParameter(
+                mNode,
+                OMX_IndexParamVideoProfileLevelQuerySupported,
+                &params,
+                sizeof(params));
+
+        if (err != OK) {
+            return err;
+        }
+
+        int32_t supportedProfile = static_cast<int32_t>(params.eProfile);
+        int32_t supportedLevel = static_cast<int32_t>(params.eLevel);
+
+        if (profile == supportedProfile && level <= supportedLevel) {
+            return OK;
+        }
+    }
+}
+
+status_t DashCodec::configureBitrate(
+        int32_t bitrate, OMX_VIDEO_CONTROLRATETYPE bitrateMode) {
+    OMX_VIDEO_PARAM_BITRATETYPE bitrateType;
+    InitOMXParams(&bitrateType);
+    bitrateType.nPortIndex = kPortIndexOutput;
+
+    status_t err = mOMX->getParameter(
+            mNode, OMX_IndexParamVideoBitrate,
+            &bitrateType, sizeof(bitrateType));
+
+    if (err != OK) {
+        return err;
+    }
+
+    bitrateType.eControlRate = bitrateMode;
+    bitrateType.nTargetBitrate = bitrate;
+
+    return mOMX->setParameter(
+            mNode, OMX_IndexParamVideoBitrate,
+            &bitrateType, sizeof(bitrateType));
+}
+
+status_t DashCodec::setupErrorCorrectionParameters() {
+    OMX_VIDEO_PARAM_ERRORCORRECTIONTYPE errorCorrectionType;
+    InitOMXParams(&errorCorrectionType);
+    errorCorrectionType.nPortIndex = kPortIndexOutput;
+
+    status_t err = mOMX->getParameter(
+            mNode, OMX_IndexParamVideoErrorCorrection,
+            &errorCorrectionType, sizeof(errorCorrectionType));
+
+    if (err != OK) {
+        return OK;  // Optional feature. Ignore this failure
+    }
+
+    errorCorrectionType.bEnableHEC = OMX_FALSE;
+    errorCorrectionType.bEnableResync = OMX_TRUE;
+    errorCorrectionType.nResynchMarkerSpacing = 256;
+    errorCorrectionType.bEnableDataPartitioning = OMX_FALSE;
+    errorCorrectionType.bEnableRVLC = OMX_FALSE;
+
+    return mOMX->setParameter(
+            mNode, OMX_IndexParamVideoErrorCorrection,
+            &errorCorrectionType, sizeof(errorCorrectionType));
+}
+
+status_t DashCodec::setVideoFormatOnPort(
+        OMX_U32 portIndex,
+        int32_t width, int32_t height, OMX_VIDEO_CODINGTYPE compressionFormat) {
+    OMX_PARAM_PORTDEFINITIONTYPE def;
+    InitOMXParams(&def);
+    def.nPortIndex = portIndex;
+
+    OMX_VIDEO_PORTDEFINITIONTYPE *video_def = &def.format.video;
+
+    status_t err = mOMX->getParameter(
+            mNode, OMX_IndexParamPortDefinition, &def, sizeof(def));
+
+    CHECK_EQ(err, (status_t)OK);
+
+    if (portIndex == kPortIndexInput) {
+        // XXX Need a (much) better heuristic to compute input buffer sizes.
+        const size_t X = 64 * 1024;
+        if (def.nBufferSize < X) {
+            def.nBufferSize = X;
+        }
+    }
+
+    CHECK_EQ((int)def.eDomain, (int)OMX_PortDomainVideo);
+
+    video_def->nFrameWidth = width;
+    video_def->nFrameHeight = height;
+
+    if (portIndex == kPortIndexInput) {
+        video_def->eCompressionFormat = compressionFormat;
+        video_def->eColorFormat = OMX_COLOR_FormatUnused;
+    }
+
+    err = mOMX->setParameter(
+            mNode, OMX_IndexParamPortDefinition, &def, sizeof(def));
+
+    return err;
+}
+
+status_t DashCodec::initNativeWindow() {
+    if (mNativeWindow != NULL) {
+        return mOMX->enableGraphicBuffers(mNode, kPortIndexOutput, OMX_TRUE);
+    }
+
+    mOMX->enableGraphicBuffers(mNode, kPortIndexOutput, OMX_FALSE);
+    return OK;
+}
+
+size_t DashCodec::countBuffersOwnedByComponent(OMX_U32 portIndex) const {
+    size_t n = 0;
+
+    for (size_t i = 0; i < mBuffers[portIndex].size(); ++i) {
+        const BufferInfo &info = mBuffers[portIndex].itemAt(i);
+
+        if (info.mStatus == BufferInfo::OWNED_BY_COMPONENT) {
+            ++n;
+        }
+    }
+
+    return n;
+}
+
+bool DashCodec::allYourBuffersAreBelongToUs(
+        OMX_U32 portIndex) {
+    for (size_t i = 0; i < mBuffers[portIndex].size(); ++i) {
+        BufferInfo *info = &mBuffers[portIndex].editItemAt(i);
+
+        if (info->mStatus != BufferInfo::OWNED_BY_US
+                && info->mStatus != BufferInfo::OWNED_BY_NATIVE_WINDOW) {
+            ALOGV("[%s] Buffer %p on port %ld still has status %d",
+                    mComponentName.c_str(),
+                    info->mBufferID, portIndex, info->mStatus);
+            return false;
+        }
+    }
+
+    return true;
+}
+
+bool DashCodec::allYourBuffersAreBelongToUs() {
+    return allYourBuffersAreBelongToUs(kPortIndexInput)
+        && allYourBuffersAreBelongToUs(kPortIndexOutput);
+}
+
+void DashCodec::deferMessage(const sp<AMessage> &msg) {
+    bool wasEmptyBefore = mDeferredQueue.empty();
+    mDeferredQueue.push_back(msg);
+}
+
+void DashCodec::processDeferredMessages() {
+    List<sp<AMessage> > queue = mDeferredQueue;
+    mDeferredQueue.clear();
+
+    List<sp<AMessage> >::iterator it = queue.begin();
+    while (it != queue.end()) {
+        onMessageReceived(*it++);
+    }
+}
+
+void DashCodec::queueNextFormat() {
+    OMX_PARAM_PORTDEFINITIONTYPE* def = new OMX_PARAM_PORTDEFINITIONTYPE();
+    InitOMXParams(def);
+    def->nPortIndex = kPortIndexOutput;
+
+    CHECK_EQ(mOMX->getParameter(
+                mNode, OMX_IndexParamPortDefinition, def, sizeof(*def)),
+             (status_t)OK);
+
+    CHECK_EQ((int)def->eDir, (int)OMX_DirOutput);
+    mFormats.push_back(def);
+
+    OMX_CONFIG_RECTTYPE* rect = new OMX_CONFIG_RECTTYPE();
+    InitOMXParams(rect);
+    rect->nPortIndex = kPortIndexOutput;
+    if (mOMX->getConfig(mNode, OMX_IndexConfigCommonOutputCrop, rect, sizeof(*rect)) != OK) {
+        mOutputCrops.push_back(NULL);
+    } else {
+        mOutputCrops.push_back(rect);
+    }
+}
+
+void DashCodec::clearCachedFormats() {
+    for (size_t i = 0 ; i < mOutputCrops.size(); i++)
+    {
+      if (mOutputCrops[i])
+      {
+        delete mOutputCrops[i];
+      }
+    }
+    for (size_t i = 0 ; i < mFormats.size(); i++)
+    {
+      if (mFormats[i])
+      {
+        delete mFormats[i];
+      }
+    }
+    mOutputCrops.clear();
+    mFormats.clear();
+}
+
+void DashCodec::sendFormatChange() {
+    sp<AMessage> notify = mNotify->dup();
+    notify->setInt32("what", kWhatOutputFormatChanged);
+    bool useCachedConfig = false;
+    OMX_PARAM_PORTDEFINITIONTYPE* def;
+    if (mFormats.size() > 0) {
+        useCachedConfig = true;
+        def = mFormats[0];
+        mFormats.removeAt(0);
+    } else {
+        def = new OMX_PARAM_PORTDEFINITIONTYPE();
+        InitOMXParams(def);
+        def->nPortIndex = kPortIndexOutput;
+
+        CHECK_EQ(mOMX->getParameter(
+                    mNode, OMX_IndexParamPortDefinition, def, sizeof(*def)),
+                 (status_t)OK);
+
+        CHECK_EQ((int)def->eDir, (int)OMX_DirOutput);
+    }
+    switch (def->eDomain) {
+        case OMX_PortDomainVideo:
+        {
+            OMX_VIDEO_PORTDEFINITIONTYPE *videoDef = &def->format.video;
+
+            notify->setString("mime", MEDIA_MIMETYPE_VIDEO_RAW);
+            notify->setInt32("width", videoDef->nFrameWidth);
+            notify->setInt32("height", videoDef->nFrameHeight);
+            notify->setInt32("stride", videoDef->nStride);
+            notify->setInt32("slice-height", videoDef->nSliceHeight);
+            notify->setInt32("color-format", videoDef->eColorFormat);
+            ALOGE("sendformatchange: %d %d", videoDef->nFrameWidth, videoDef->nFrameHeight);
+            OMX_CONFIG_RECTTYPE* rect;
+            bool hasValidCrop = true;
+            if (useCachedConfig) {
+                rect = mOutputCrops[0];
+                mOutputCrops.removeAt(0);
+                if (rect == NULL) {
+                    rect = new OMX_CONFIG_RECTTYPE();
+                    hasValidCrop = false;
+                }
+            } else {
+                rect = new OMX_CONFIG_RECTTYPE();
+                InitOMXParams(rect);
+                rect->nPortIndex = kPortIndexOutput;
+                hasValidCrop = (mOMX->getConfig(
+                    mNode, OMX_IndexConfigCommonOutputCrop,
+                    rect, sizeof(*rect)) == OK);
+            }
+
+            if (!hasValidCrop) {
+                rect->nLeft = 0;
+                rect->nTop = 0;
+                rect->nWidth = videoDef->nFrameWidth;
+                rect->nHeight = videoDef->nFrameHeight;
+            }
+
+            CHECK_GE(rect->nLeft, 0);
+            CHECK_GE(rect->nTop, 0);
+            CHECK_GE(rect->nWidth, 0u);
+            CHECK_GE(rect->nHeight, 0u);
+            CHECK_LE(rect->nLeft + rect->nWidth - 1, videoDef->nFrameWidth);
+            CHECK_LE(rect->nTop + rect->nHeight - 1, videoDef->nFrameHeight);
+
+            notify->setRect(
+                    "crop",
+                    rect->nLeft,
+                    rect->nTop,
+                    rect->nLeft + rect->nWidth - 1,
+                    rect->nTop + rect->nHeight - 1);
+
+            if (mNativeWindow != NULL) {
+                android_native_rect_t crop;
+                crop.left = rect->nLeft;
+                crop.top = rect->nTop;
+                crop.right = rect->nLeft + rect->nWidth;
+                crop.bottom = rect->nTop + rect->nHeight;
+
+                CHECK_EQ(0, native_window_set_crop(
+                            mNativeWindow.get(), &crop));
+            }
+            delete rect;
+            break;
+        }
+
+        case OMX_PortDomainAudio:
+        {
+            OMX_AUDIO_PORTDEFINITIONTYPE *audioDef = &def->format.audio;
+            CHECK_EQ((int)audioDef->eEncoding, (int)OMX_AUDIO_CodingPCM);
+
+            OMX_AUDIO_PARAM_PCMMODETYPE params;
+            InitOMXParams(&params);
+            params.nPortIndex = kPortIndexOutput;
+
+            CHECK_EQ(mOMX->getParameter(
+                        mNode, OMX_IndexParamAudioPcm,
+                        &params, sizeof(params)),
+                     (status_t)OK);
+
+            CHECK(params.nChannels == 1 || params.bInterleaved);
+            CHECK_EQ(params.nBitPerSample, 16u);
+            CHECK_EQ((int)params.eNumData, (int)OMX_NumericalDataSigned);
+            CHECK_EQ((int)params.ePCMMode, (int)OMX_AUDIO_PCMModeLinear);
+
+            notify->setString("mime", MEDIA_MIMETYPE_AUDIO_RAW);
+            notify->setInt32("channel-count", params.nChannels);
+            notify->setInt32("sample-rate", params.nSamplingRate);
+            if (mEncoderDelay + mEncoderPadding) {
+                size_t frameSize = params.nChannels * sizeof(int16_t);
+                if (mSkipCutBuffer != NULL) {
+                    size_t prevbufsize = mSkipCutBuffer->size();
+                    if (prevbufsize != 0) {
+                        ALOGW("Replacing SkipCutBuffer holding %d bytes", prevbufsize);
+                    }
+                }
+                mSkipCutBuffer = new SkipCutBuffer(mEncoderDelay * frameSize,
+                                                   mEncoderPadding * frameSize);
+            }
+
+            if (mChannelMaskPresent) {
+                notify->setInt32("channel-mask", mChannelMask);
+            }
+
+            break;
+        }
+
+        default:
+            TRESPASS();
+    }
+
+    notify->post();
+    delete def;
+    mSentFormat = true;
+}
+
+void DashCodec::signalError(OMX_ERRORTYPE error, status_t internalError) {
+    sp<AMessage> notify = mNotify->dup();
+    notify->setInt32("what", DashCodec::kWhatError);
+    notify->setInt32("omx-error", error);
+    notify->setInt32("err", internalError);
+    notify->post();
+}
+
+status_t DashCodec::pushBlankBuffersToNativeWindow() {
+    status_t err = NO_ERROR;
+    ANativeWindowBuffer* anb = NULL;
+    int numBufs = 0;
+    int minUndequeuedBufs = 0;
+
+    // We need to reconnect to the ANativeWindow as a CPU client to ensure that
+    // no frames get dropped by SurfaceFlinger assuming that these are video
+    // frames.
+    err = native_window_api_disconnect(mNativeWindow.get(),
+            NATIVE_WINDOW_API_MEDIA);
+    if (err != NO_ERROR) {
+        ALOGE("error pushing blank frames: api_disconnect failed: %s (%d)",
+                strerror(-err), -err);
+        return err;
+    }
+
+    err = native_window_api_connect(mNativeWindow.get(),
+            NATIVE_WINDOW_API_CPU);
+    if (err != NO_ERROR) {
+        ALOGE("error pushing blank frames: api_connect failed: %s (%d)",
+                strerror(-err), -err);
+        return err;
+    }
+
+    err = native_window_set_buffers_geometry(mNativeWindow.get(), 1, 1,
+            HAL_PIXEL_FORMAT_RGBX_8888);
+    if (err != NO_ERROR) {
+        ALOGE("error pushing blank frames: set_buffers_geometry failed: %s (%d)",
+                strerror(-err), -err);
+        goto error;
+    }
+
+    err = native_window_set_usage(mNativeWindow.get(),
+            GRALLOC_USAGE_SW_WRITE_OFTEN);
+    if (err != NO_ERROR) {
+        ALOGE("error pushing blank frames: set_usage failed: %s (%d)",
+                strerror(-err), -err);
+        goto error;
+    }
+
+    err = mNativeWindow->query(mNativeWindow.get(),
+            NATIVE_WINDOW_MIN_UNDEQUEUED_BUFFERS, &minUndequeuedBufs);
+    if (err != NO_ERROR) {
+        ALOGE("error pushing blank frames: MIN_UNDEQUEUED_BUFFERS query "
+                "failed: %s (%d)", strerror(-err), -err);
+        goto error;
+    }
+
+    numBufs = minUndequeuedBufs + 1;
+    err = native_window_set_buffer_count(mNativeWindow.get(), numBufs);
+    if (err != NO_ERROR) {
+        ALOGE("error pushing blank frames: set_buffer_count failed: %s (%d)",
+                strerror(-err), -err);
+        goto error;
+    }
+
+    // We  push numBufs + 1 buffers to ensure that we've drawn into the same
+    // buffer twice.  This should guarantee that the buffer has been displayed
+    // on the screen and then been replaced, so an previous video frames are
+    // guaranteed NOT to be currently displayed.
+    for (int i = 0; i < numBufs + 1; i++) {
+        int fenceFd = -1;
+        err = native_window_dequeue_buffer_and_wait(mNativeWindow.get(), &anb);
+        if (err != NO_ERROR) {
+            ALOGE("error pushing blank frames: dequeueBuffer failed: %s (%d)",
+                    strerror(-err), -err);
+            goto error;
+        }
+
+        sp<GraphicBuffer> buf(new GraphicBuffer(anb, false));
+
+        // Fill the buffer with the a 1x1 checkerboard pattern ;)
+        uint32_t* img = NULL;
+        err = buf->lock(GRALLOC_USAGE_SW_WRITE_OFTEN, (void**)(&img));
+        if (err != NO_ERROR) {
+            ALOGE("error pushing blank frames: lock failed: %s (%d)",
+                    strerror(-err), -err);
+            goto error;
+        }
+
+        *img = 0;
+
+        err = buf->unlock();
+        if (err != NO_ERROR) {
+            ALOGE("error pushing blank frames: unlock failed: %s (%d)",
+                    strerror(-err), -err);
+            goto error;
+        }
+
+        err = mNativeWindow->queueBuffer(mNativeWindow.get(),
+                buf->getNativeBuffer(), -1);
+        if (err != NO_ERROR) {
+            ALOGE("error pushing blank frames: queueBuffer failed: %s (%d)",
+                    strerror(-err), -err);
+            goto error;
+        }
+
+        anb = NULL;
+    }
+
+error:
+
+    if (err != NO_ERROR) {
+        // Clean up after an error.
+        if (anb != NULL) {
+            mNativeWindow->cancelBuffer(mNativeWindow.get(), anb, -1);
+        }
+
+        native_window_api_disconnect(mNativeWindow.get(),
+                NATIVE_WINDOW_API_CPU);
+        native_window_api_connect(mNativeWindow.get(),
+                NATIVE_WINDOW_API_MEDIA);
+
+        return err;
+    } else {
+        // Clean up after success.
+        err = native_window_api_disconnect(mNativeWindow.get(),
+                NATIVE_WINDOW_API_CPU);
+        if (err != NO_ERROR) {
+            ALOGE("error pushing blank frames: api_disconnect failed: %s (%d)",
+                    strerror(-err), -err);
+            return err;
+        }
+
+        err = native_window_api_connect(mNativeWindow.get(),
+                NATIVE_WINDOW_API_MEDIA);
+        if (err != NO_ERROR) {
+            ALOGE("error pushing blank frames: api_connect failed: %s (%d)",
+                    strerror(-err), -err);
+            return err;
+        }
+
+        return NO_ERROR;
+    }
+}
+
+////////////////////////////////////////////////////////////////////////////////
+
+DashCodec::PortDescription::PortDescription() {
+}
+
+status_t DashCodec::requestIDRFrame() {
+    if (!mIsEncoder) {
+        return ERROR_UNSUPPORTED;
+    }
+
+    OMX_CONFIG_INTRAREFRESHVOPTYPE params;
+    InitOMXParams(&params);
+
+    params.nPortIndex = kPortIndexOutput;
+    params.IntraRefreshVOP = OMX_TRUE;
+
+    return mOMX->setConfig(
+            mNode,
+            OMX_IndexConfigVideoIntraVOPRefresh,
+            &params,
+            sizeof(params));
+}
+
+void DashCodec::PortDescription::addBuffer(
+        IOMX::buffer_id id, const sp<ABuffer> &buffer) {
+    mBufferIDs.push_back(id);
+    mBuffers.push_back(buffer);
+}
+
+size_t DashCodec::PortDescription::countBuffers() {
+    return mBufferIDs.size();
+}
+
+IOMX::buffer_id DashCodec::PortDescription::bufferIDAt(size_t index) const {
+    return mBufferIDs.itemAt(index);
+}
+
+sp<ABuffer> DashCodec::PortDescription::bufferAt(size_t index) const {
+    return mBuffers.itemAt(index);
+}
+
+////////////////////////////////////////////////////////////////////////////////
+
+DashCodec::BaseState::BaseState(DashCodec *codec, const sp<AState> &parentState)
+    : AState(parentState),
+      mCodec(codec) {
+}
+
+DashCodec::BaseState::PortMode DashCodec::BaseState::getPortMode(OMX_U32 portIndex) {
+    return KEEP_BUFFERS;
+}
+
+bool DashCodec::BaseState::onMessageReceived(const sp<AMessage> &msg) {
+    switch (msg->what()) {
+        case kWhatInputBufferFilled:
+        {
+            onInputBufferFilled(msg);
+            break;
+        }
+
+        case kWhatOutputBufferDrained:
+        {
+            onOutputBufferDrained(msg);
+            break;
+        }
+
+        case DashCodec::kWhatOMXMessage:
+        {
+            return onOMXMessage(msg);
+        }
+
+        case DashCodec::kWhatFlush:
+        {
+            sp<AMessage> notify = mCodec->mNotify->dup();
+            notify->setInt32("what", DashCodec::kWhatFlushCompleted);
+            notify->post();
+            return true;
+        }
+
+        default:
+            return false;
+    }
+
+    return true;
+}
+
+bool DashCodec::BaseState::onOMXMessage(const sp<AMessage> &msg) {
+    int32_t type;
+    CHECK(msg->findInt32("type", &type));
+
+    IOMX::node_id nodeID;
+    CHECK(msg->findPointer("node", &nodeID));
+    CHECK_EQ(nodeID, mCodec->mNode);
+
+    switch (type) {
+        case omx_message::EVENT:
+        {
+            int32_t event, data1, data2;
+            CHECK(msg->findInt32("event", &event));
+            CHECK(msg->findInt32("data1", &data1));
+            CHECK(msg->findInt32("data2", &data2));
+
+            if (event == OMX_EventCmdComplete
+                    && data1 == OMX_CommandFlush
+                    && data2 == (int32_t)OMX_ALL) {
+                // Use of this notification is not consistent across
+                // implementations. We'll drop this notification and rely
+                // on flush-complete notifications on the individual port
+                // indices instead.
+
+                return true;
+            }
+
+            return onOMXEvent(
+                    static_cast<OMX_EVENTTYPE>(event),
+                    static_cast<OMX_U32>(data1),
+                    static_cast<OMX_U32>(data2));
+        }
+
+        case omx_message::EMPTY_BUFFER_DONE:
+        {
+            IOMX::buffer_id bufferID;
+            CHECK(msg->findPointer("buffer", &bufferID));
+
+            return onOMXEmptyBufferDone(bufferID);
+        }
+
+        case omx_message::FILL_BUFFER_DONE:
+        {
+            IOMX::buffer_id bufferID;
+            CHECK(msg->findPointer("buffer", &bufferID));
+
+            int32_t rangeOffset, rangeLength, flags;
+            int64_t timeUs;
+            void *platformPrivate;
+            void *dataPtr;
+
+            CHECK(msg->findInt32("range_offset", &rangeOffset));
+            CHECK(msg->findInt32("range_length", &rangeLength));
+            CHECK(msg->findInt32("flags", &flags));
+            CHECK(msg->findInt64("timestamp", &timeUs));
+            CHECK(msg->findPointer("platform_private", &platformPrivate));
+            CHECK(msg->findPointer("data_ptr", &dataPtr));
+
+            return onOMXFillBufferDone(
+                    bufferID,
+                    (size_t)rangeOffset, (size_t)rangeLength,
+                    (OMX_U32)flags,
+                    timeUs,
+                    platformPrivate,
+                    dataPtr);
+        }
+
+        default:
+            TRESPASS();
+            break;
+    }
+}
+
+bool DashCodec::BaseState::onOMXEvent(
+        OMX_EVENTTYPE event, OMX_U32 data1, OMX_U32 data2) {
+    if (event != OMX_EventError) {
+        ALOGV("[%s] EVENT(%d, 0x%08lx, 0x%08lx)",
+             mCodec->mComponentName.c_str(), event, data1, data2);
+
+        return false;
+    }
+
+    ALOGE("[%s] ERROR(0x%08lx)", mCodec->mComponentName.c_str(), data1);
+
+    mCodec->signalError((OMX_ERRORTYPE)data1);
+
+    return true;
+}
+
+bool DashCodec::BaseState::onOMXEmptyBufferDone(IOMX::buffer_id bufferID) {
+    ALOGV("[%s] onOMXEmptyBufferDone %p",
+         mCodec->mComponentName.c_str(), bufferID);
+
+    BufferInfo *info =
+        mCodec->findBufferByID(kPortIndexInput, bufferID);
+
+    CHECK_EQ((int)info->mStatus, (int)BufferInfo::OWNED_BY_COMPONENT);
+    info->mStatus = BufferInfo::OWNED_BY_US;
+
+    const sp<AMessage> &bufferMeta = info->mData->meta();
+    void *mediaBuffer;
+    if (bufferMeta->findPointer("mediaBuffer", &mediaBuffer)
+            && mediaBuffer != NULL) {
+        // We're in "store-metadata-in-buffers" mode, the underlying
+        // OMX component had access to data that's implicitly refcounted
+        // by this "mediaBuffer" object. Now that the OMX component has
+        // told us that it's done with the input buffer, we can decrement
+        // the mediaBuffer's reference count.
+
+        ALOGV("releasing mbuf %p", mediaBuffer);
+
+        ((MediaBuffer *)mediaBuffer)->release();
+        mediaBuffer = NULL;
+
+        bufferMeta->setPointer("mediaBuffer", NULL);
+    }
+
+    PortMode mode = getPortMode(kPortIndexInput);
+
+    switch (mode) {
+        case KEEP_BUFFERS:
+            break;
+
+        case RESUBMIT_BUFFERS:
+            postFillThisBuffer(info);
+            break;
+
+        default:
+        {
+            CHECK_EQ((int)mode, (int)FREE_BUFFERS);
+            TRESPASS();  // Not currently used
+            break;
+        }
+    }
+
+    return true;
+}
+
+void DashCodec::BaseState::postFillThisBuffer(BufferInfo *info) {
+    if (mCodec->mPortEOS[kPortIndexInput]) {
+        return;
+    }
+
+    CHECK_EQ((int)info->mStatus, (int)BufferInfo::OWNED_BY_US);
+
+    sp<AMessage> notify = mCodec->mNotify->dup();
+    notify->setInt32("what", DashCodec::kWhatFillThisBuffer);
+    notify->setPointer("buffer-id", info->mBufferID);
+
+    info->mData->meta()->clear();
+    notify->setBuffer("buffer", info->mData);
+
+    sp<AMessage> reply = new AMessage(kWhatInputBufferFilled, mCodec->id());
+    reply->setPointer("buffer-id", info->mBufferID);
+
+    notify->setMessage("reply", reply);
+
+    notify->post();
+
+    info->mStatus = BufferInfo::OWNED_BY_UPSTREAM;
+}
+
+void DashCodec::BaseState::onInputBufferFilled(const sp<AMessage> &msg) {
+    IOMX::buffer_id bufferID;
+    CHECK(msg->findPointer("buffer-id", &bufferID));
+
+    sp<ABuffer> buffer;
+    int32_t err = OK;
+    bool eos = false;
+
+    if (!msg->findBuffer("buffer", &buffer)) {
+        CHECK(msg->findInt32("err", &err));
+
+        ALOGV("[%s] saw error %d instead of an input buffer",
+             mCodec->mComponentName.c_str(), err);
+
+        buffer.clear();
+
+        eos = true;
+    }
+
+    int32_t tmp;
+    if (buffer != NULL && buffer->meta()->findInt32("eos", &tmp) && tmp) {
+        eos = true;
+        err = ERROR_END_OF_STREAM;
+    }
+
+    BufferInfo *info = mCodec->findBufferByID(kPortIndexInput, bufferID);
+    CHECK_EQ((int)info->mStatus, (int)BufferInfo::OWNED_BY_UPSTREAM);
+
+    info->mStatus = BufferInfo::OWNED_BY_US;
+
+    PortMode mode = getPortMode(kPortIndexInput);
+
+    switch (mode) {
+        case KEEP_BUFFERS:
+        {
+            if (eos) {
+                if (!mCodec->mPortEOS[kPortIndexInput]) {
+                    mCodec->mPortEOS[kPortIndexInput] = true;
+                    mCodec->mInputEOSResult = err;
+                }
+            }
+            break;
+        }
+
+        case RESUBMIT_BUFFERS:
+        {
+            if (buffer != NULL && !mCodec->mPortEOS[kPortIndexInput]) {
+                int64_t timeUs;
+                CHECK(buffer->meta()->findInt64("timeUs", &timeUs));
+
+                OMX_U32 flags = OMX_BUFFERFLAG_ENDOFFRAME;
+
+                int32_t isCSD;
+                if (buffer->meta()->findInt32("csd", &isCSD) && isCSD != 0) {
+                    flags |= OMX_BUFFERFLAG_CODECCONFIG;
+                }
+
+                if (eos) {
+                    flags |= OMX_BUFFERFLAG_EOS;
+                }
+
+                if (buffer != info->mData) {
+                    ALOGV("[%s] Needs to copy input data for buffer %p. (%p != %p)",
+                         mCodec->mComponentName.c_str(),
+                         bufferID,
+                         buffer.get(), info->mData.get());
+
+                    CHECK_LE(buffer->size(), info->mData->capacity());
+                    memcpy(info->mData->data(), buffer->data(), buffer->size());
+                }
+
+                if (flags & OMX_BUFFERFLAG_CODECCONFIG) {
+                    ALOGV("[%s] calling emptyBuffer %p w/ codec specific data",
+                         mCodec->mComponentName.c_str(), bufferID);
+                } else if (flags & OMX_BUFFERFLAG_EOS) {
+                    ALOGV("[%s] calling emptyBuffer %p w/ EOS",
+                         mCodec->mComponentName.c_str(), bufferID);
+                } else {
+#if TRACK_BUFFER_TIMING
+                    ALOGI("[%s] calling emptyBuffer %p w/ time %lld us",
+                         mCodec->mComponentName.c_str(), bufferID, timeUs);
+#else
+                    ALOGV("[%s] calling emptyBuffer %p w/ time %lld us",
+                         mCodec->mComponentName.c_str(), bufferID, timeUs);
+#endif
+                }
+
+#if TRACK_BUFFER_TIMING
+                DashCodec::BufferStats stats;
+                stats.mEmptyBufferTimeUs = ALooper::GetNowUs();
+                stats.mFillBufferDoneTimeUs = -1ll;
+                mCodec->mBufferStats.add(timeUs, stats);
+#endif
+
+                CHECK_EQ(mCodec->mOMX->emptyBuffer(
+                            mCodec->mNode,
+                            bufferID,
+                            0,
+                            buffer->size(),
+                            flags,
+                            timeUs),
+                         (status_t)OK);
+
+                info->mStatus = BufferInfo::OWNED_BY_COMPONENT;
+
+                if (!eos) {
+                    getMoreInputDataIfPossible();
+                } else {
+                    ALOGV("[%s] Signalled EOS on the input port",
+                         mCodec->mComponentName.c_str());
+
+                    mCodec->mPortEOS[kPortIndexInput] = true;
+                    mCodec->mInputEOSResult = err;
+                }
+            } else if (!mCodec->mPortEOS[kPortIndexInput]) {
+                if (err != ERROR_END_OF_STREAM) {
+                    ALOGV("[%s] Signalling EOS on the input port "
+                         "due to error %d",
+                         mCodec->mComponentName.c_str(), err);
+                } else {
+                    ALOGV("[%s] Signalling EOS on the input port",
+                         mCodec->mComponentName.c_str());
+                }
+
+                ALOGV("[%s] calling emptyBuffer %p signalling EOS",
+                     mCodec->mComponentName.c_str(), bufferID);
+
+                CHECK_EQ(mCodec->mOMX->emptyBuffer(
+                            mCodec->mNode,
+                            bufferID,
+                            0,
+                            0,
+                            OMX_BUFFERFLAG_EOS,
+                            0),
+                         (status_t)OK);
+
+                info->mStatus = BufferInfo::OWNED_BY_COMPONENT;
+
+                mCodec->mPortEOS[kPortIndexInput] = true;
+                mCodec->mInputEOSResult = err;
+            }
+            break;
+
+            default:
+                CHECK_EQ((int)mode, (int)FREE_BUFFERS);
+                break;
+        }
+    }
+}
+
+void DashCodec::BaseState::getMoreInputDataIfPossible() {
+    if (mCodec->mPortEOS[kPortIndexInput]) {
+        return;
+    }
+
+    BufferInfo *eligible = NULL;
+
+    for (size_t i = 0; i < mCodec->mBuffers[kPortIndexInput].size(); ++i) {
+        BufferInfo *info = &mCodec->mBuffers[kPortIndexInput].editItemAt(i);
+
+#if 0
+        if (info->mStatus == BufferInfo::OWNED_BY_UPSTREAM) {
+            // There's already a "read" pending.
+            return;
+        }
+#endif
+
+        if (info->mStatus == BufferInfo::OWNED_BY_US) {
+            eligible = info;
+        }
+    }
+
+    if (eligible == NULL) {
+        return;
+    }
+
+    postFillThisBuffer(eligible);
+}
+
+bool DashCodec::BaseState::onOMXFillBufferDone(
+        IOMX::buffer_id bufferID,
+        size_t rangeOffset, size_t rangeLength,
+        OMX_U32 flags,
+        int64_t timeUs,
+        void *platformPrivate,
+        void *dataPtr) {
+    ALOGV("[%s] onOMXFillBufferDone %p time %lld us, flags = 0x%08lx",
+         mCodec->mComponentName.c_str(), bufferID, timeUs, flags);
+
+    ssize_t index;
+
+#if TRACK_BUFFER_TIMING
+    index = mCodec->mBufferStats.indexOfKey(timeUs);
+    if (index >= 0) {
+        DashCodec::BufferStats *stats = &mCodec->mBufferStats.editValueAt(index);
+        stats->mFillBufferDoneTimeUs = ALooper::GetNowUs();
+
+        ALOGI("frame PTS %lld: %lld",
+                timeUs,
+                stats->mFillBufferDoneTimeUs - stats->mEmptyBufferTimeUs);
+
+        mCodec->mBufferStats.removeItemsAt(index);
+        stats = NULL;
+    }
+#endif
+
+    BufferInfo *info =
+        mCodec->findBufferByID(kPortIndexOutput, bufferID, &index);
+
+    CHECK_EQ((int)info->mStatus, (int)BufferInfo::OWNED_BY_COMPONENT);
+
+    info->mStatus = BufferInfo::OWNED_BY_US;
+
+    PortMode mode = getPortMode(kPortIndexOutput);
+
+    switch (mode) {
+        case KEEP_BUFFERS:
+            break;
+
+        case RESUBMIT_BUFFERS:
+        {
+            if (rangeLength == 0 && !(flags & OMX_BUFFERFLAG_EOS)) {
+                ALOGV("[%s] calling fillBuffer %p",
+                     mCodec->mComponentName.c_str(), info->mBufferID);
+
+                CHECK_EQ(mCodec->mOMX->fillBuffer(
+                            mCodec->mNode, info->mBufferID),
+                         (status_t)OK);
+
+                info->mStatus = BufferInfo::OWNED_BY_COMPONENT;
+                break;
+            }
+
+            if (flags & OMX_BUFFERFLAG_EOS) {
+                ALOGE("[%s] saw output EOS", mCodec->mComponentName.c_str());
+
+                sp<AMessage> notify = mCodec->mNotify->dup();
+                notify->setInt32("what", DashCodec::kWhatEOS);
+                notify->setInt32("err", mCodec->mInputEOSResult);
+                notify->post();
+
+                mCodec->mPortEOS[kPortIndexOutput] = true;
+                break;
+            }
+            if (!mCodec->mIsEncoder && !mCodec->mSentFormat && !mCodec->mAdaptivePlayback) {
+                mCodec->sendFormatChange();
+            }
+
+            if (mCodec->mNativeWindow == NULL) {
+                info->mData->setRange(rangeOffset, rangeLength);
+
+#if 0
+                if (IsIDR(info->mData)) {
+                    ALOGI("IDR frame");
+                }
+#endif
+            }
+
+            if (mCodec->mSkipCutBuffer != NULL) {
+                mCodec->mSkipCutBuffer->submit(info->mData);
+            }
+            info->mData->meta()->setInt64("timeUs", timeUs);
+
+            sp<AMessage> notify = mCodec->mNotify->dup();
+            notify->setInt32("what", DashCodec::kWhatDrainThisBuffer);
+            notify->setPointer("buffer-id", info->mBufferID);
+            notify->setBuffer("buffer", info->mData);
+            notify->setInt32("flags", flags);
+            sp<AMessage> reply =
+                new AMessage(kWhatOutputBufferDrained, mCodec->id());
+
+           if (!mCodec->mPostFormat && mCodec->mAdaptivePlayback){
+                 ALOGV("Resolution will change from this buffer, set a flag");
+                   reply->setInt32("resChange", 1);
+                   mCodec->mPostFormat = true;
+            }
+
+            reply->setPointer("buffer-id", info->mBufferID);
+
+            notify->setMessage("reply", reply);
+
+            notify->post();
+
+            info->mStatus = BufferInfo::OWNED_BY_DOWNSTREAM;
+
+            break;
+        }
+
+        default:
+        {
+            CHECK_EQ((int)mode, (int)FREE_BUFFERS);
+
+            CHECK_EQ((status_t)OK,
+                     mCodec->freeBuffer(kPortIndexOutput, index));
+            break;
+        }
+    }
+
+    return true;
+}
+
+void DashCodec::BaseState::onOutputBufferDrained(const sp<AMessage> &msg) {
+    IOMX::buffer_id bufferID;
+    CHECK(msg->findPointer("buffer-id", &bufferID));
+
+    ssize_t index;
+    BufferInfo *info =
+        mCodec->findBufferByID(kPortIndexOutput, bufferID, &index);
+    CHECK_EQ((int)info->mStatus, (int)BufferInfo::OWNED_BY_DOWNSTREAM);
+    if (mCodec->mAdaptivePlayback) {
+        int32_t resChange = 0;
+       if (msg->findInt32("resChange", &resChange) && resChange == 1) {
+            ALOGV("Resolution change is sent to native window now ");
+            mCodec->sendFormatChange();
+            msg->setInt32("resChange", 0);
+        }
+    }
+    int32_t render;
+    if (mCodec->mNativeWindow != NULL
+            && msg->findInt32("render", &render) && render != 0) {
+        // The client wants this buffer to be rendered.
+
+        status_t err;
+        if ((err = mCodec->mNativeWindow->queueBuffer(
+                    mCodec->mNativeWindow.get(),
+                    info->mGraphicBuffer.get(), -1)) == OK) {
+            info->mStatus = BufferInfo::OWNED_BY_NATIVE_WINDOW;
+        } else {
+            mCodec->signalError(OMX_ErrorUndefined, err);
+            info->mStatus = BufferInfo::OWNED_BY_US;
+        }
+    } else {
+        info->mStatus = BufferInfo::OWNED_BY_US;
+    }
+
+    PortMode mode = getPortMode(kPortIndexOutput);
+
+    switch (mode) {
+        case KEEP_BUFFERS:
+        {
+            // XXX fishy, revisit!!! What about the FREE_BUFFERS case below?
+
+            if (info->mStatus == BufferInfo::OWNED_BY_NATIVE_WINDOW) {
+                // We cannot resubmit the buffer we just rendered, dequeue
+                // the spare instead.
+
+                info = mCodec->dequeueBufferFromNativeWindow();
+            }
+            break;
+        }
+
+        case RESUBMIT_BUFFERS:
+        {
+            if (!mCodec->mPortEOS[kPortIndexOutput]) {
+                if (info->mStatus == BufferInfo::OWNED_BY_NATIVE_WINDOW) {
+                    // We cannot resubmit the buffer we just rendered, dequeue
+                    // the spare instead.
+
+                    info = mCodec->dequeueBufferFromNativeWindow();
+                }
+
+                if (info != NULL) {
+                    ALOGV("[%s] calling fillBuffer %p",
+                         mCodec->mComponentName.c_str(), info->mBufferID);
+
+                    CHECK_EQ(mCodec->mOMX->fillBuffer(mCodec->mNode, info->mBufferID),
+                             (status_t)OK);
+
+                    info->mStatus = BufferInfo::OWNED_BY_COMPONENT;
+                }
+            }
+            break;
+        }
+
+        default:
+        {
+            CHECK_EQ((int)mode, (int)FREE_BUFFERS);
+
+            CHECK_EQ((status_t)OK,
+                     mCodec->freeBuffer(kPortIndexOutput, index));
+            break;
+        }
+    }
+}
+
+////////////////////////////////////////////////////////////////////////////////
+
+DashCodec::UninitializedState::UninitializedState(DashCodec *codec)
+    : BaseState(codec) {
+}
+
+void DashCodec::UninitializedState::stateEntered() {
+    ALOGV("Now uninitialized");
+}
+
+bool DashCodec::UninitializedState::onMessageReceived(const sp<AMessage> &msg) {
+    bool handled = false;
+
+    switch (msg->what()) {
+        case DashCodec::kWhatSetup:
+        {
+            onSetup(msg);
+
+            handled = true;
+            break;
+        }
+
+        case DashCodec::kWhatAllocateComponent:
+        {
+            onAllocateComponent(msg);
+            handled = true;
+            break;
+        }
+
+        case DashCodec::kWhatShutdown:
+        {
+            int32_t keepComponentAllocated;
+            CHECK(msg->findInt32(
+                        "keepComponentAllocated", &keepComponentAllocated));
+            CHECK(!keepComponentAllocated);
+
+            sp<AMessage> notify = mCodec->mNotify->dup();
+            notify->setInt32("what", DashCodec::kWhatShutdownCompleted);
+            notify->post();
+
+            handled = true;
+            break;
+        }
+
+        default:
+            return BaseState::onMessageReceived(msg);
+    }
+
+    return handled;
+}
+
+void DashCodec::UninitializedState::onSetup(
+        const sp<AMessage> &msg) {
+    if (onAllocateComponent(msg)
+            && mCodec->mLoadedState->onConfigureComponent(msg)) {
+        mCodec->mLoadedState->onStart();
+    }
+}
+
+bool DashCodec::UninitializedState::onAllocateComponent(const sp<AMessage> &msg) {
+    ALOGV("onAllocateComponent");
+
+    CHECK(mCodec->mNode == NULL);
+
+    OMXClient client;
+    CHECK_EQ(client.connect(), (status_t)OK);
+
+    sp<IOMX> omx = client.interface();
+
+    Vector<OMXCodec::CodecNameAndQuirks> matchingCodecs;
+
+    AString mime;
+
+    AString componentName;
+    uint32_t quirks = 0;
+    if (msg->findString("componentName", &componentName)) {
+        ssize_t index = matchingCodecs.add();
+        OMXCodec::CodecNameAndQuirks *entry = &matchingCodecs.editItemAt(index);
+        entry->mName = String8(componentName.c_str());
+
+        if (!OMXCodec::findCodecQuirks(
+                    componentName.c_str(), &entry->mQuirks)) {
+            entry->mQuirks = 0;
+        }
+    } else {
+        CHECK(msg->findString("mime", &mime));
+
+        int32_t encoder;
+        if (!msg->findInt32("encoder", &encoder)) {
+            encoder = false;
+        }
+
+        OMXCodec::findMatchingCodecs(
+                mime.c_str(),
+                encoder, // createEncoder
+                NULL,  // matchComponentName
+                0,     // flags
+                &matchingCodecs);
+    }
+
+    sp<CodecObserver> observer = new CodecObserver;
+    IOMX::node_id node = NULL;
+
+    for (size_t matchIndex = 0; matchIndex < matchingCodecs.size();
+            ++matchIndex) {
+        componentName = matchingCodecs.itemAt(matchIndex).mName.string();
+        quirks = matchingCodecs.itemAt(matchIndex).mQuirks;
+
+        pid_t tid = androidGetTid();
+        int prevPriority = androidGetThreadPriority(tid);
+        androidSetThreadPriority(tid, ANDROID_PRIORITY_FOREGROUND);
+        status_t err = omx->allocateNode(componentName.c_str(), observer, &node);
+        androidSetThreadPriority(tid, prevPriority);
+
+        if (err == OK) {
+            break;
+        }
+
+        node = NULL;
+    }
+
+    if (node == NULL) {
+        if (!mime.empty()) {
+            ALOGE("Unable to instantiate a decoder for type '%s'.",
+                 mime.c_str());
+        } else {
+            ALOGE("Unable to instantiate decoder '%s'.", componentName.c_str());
+        }
+
+        mCodec->signalError(OMX_ErrorComponentNotFound);
+        return false;
+    }
+
+    sp<AMessage> notify = new AMessage(kWhatOMXMessage, mCodec->id());
+    observer->setNotificationMessage(notify);
+
+    mCodec->mComponentName = componentName;
+    mCodec->mFlags = 0;
+
+    if (componentName.endsWith(".secure")) {
+        mCodec->mFlags |= kFlagIsSecure;
+    }
+
+    mCodec->mQuirks = quirks;
+    mCodec->mOMX = omx;
+    mCodec->mNode = node;
+
+    mCodec->mPortEOS[kPortIndexInput] =
+        mCodec->mPortEOS[kPortIndexOutput] = false;
+
+    mCodec->mInputEOSResult = OK;
+
+    {
+        sp<AMessage> notify = mCodec->mNotify->dup();
+        notify->setInt32("what", DashCodec::kWhatComponentAllocated);
+        notify->setString("componentName", mCodec->mComponentName.c_str());
+        notify->post();
+    }
+
+    mCodec->changeState(mCodec->mLoadedState);
+
+    return true;
+}
+
+////////////////////////////////////////////////////////////////////////////////
+
+DashCodec::LoadedState::LoadedState(DashCodec *codec)
+    : BaseState(codec) {
+}
+
+void DashCodec::LoadedState::stateEntered() {
+    ALOGV("[%s] Now Loaded", mCodec->mComponentName.c_str());
+
+    if (mCodec->mShutdownInProgress) {
+        bool keepComponentAllocated = mCodec->mKeepComponentAllocated;
+
+        mCodec->mShutdownInProgress = false;
+        mCodec->mKeepComponentAllocated = false;
+
+        onShutdown(keepComponentAllocated);
+    }
+}
+
+void DashCodec::LoadedState::onShutdown(bool keepComponentAllocated) {
+    if (!keepComponentAllocated) {
+        CHECK_EQ(mCodec->mOMX->freeNode(mCodec->mNode), (status_t)OK);
+
+        mCodec->mNativeWindow.clear();
+        mCodec->mNode = NULL;
+        mCodec->mOMX.clear();
+        mCodec->mQuirks = 0;
+        mCodec->mFlags = 0;
+        mCodec->mComponentName.clear();
+
+        mCodec->changeState(mCodec->mUninitializedState);
+    }
+
+    sp<AMessage> notify = mCodec->mNotify->dup();
+    notify->setInt32("what", DashCodec::kWhatShutdownCompleted);
+    notify->post();
+}
+
+bool DashCodec::LoadedState::onMessageReceived(const sp<AMessage> &msg) {
+    bool handled = false;
+
+    switch (msg->what()) {
+        case DashCodec::kWhatConfigureComponent:
+        {
+            onConfigureComponent(msg);
+            handled = true;
+            break;
+        }
+
+        case DashCodec::kWhatStart:
+        {
+            onStart();
+            handled = true;
+            break;
+        }
+
+        case DashCodec::kWhatShutdown:
+        {
+            int32_t keepComponentAllocated;
+            CHECK(msg->findInt32(
+                        "keepComponentAllocated", &keepComponentAllocated));
+
+            onShutdown(keepComponentAllocated);
+
+            handled = true;
+            break;
+        }
+
+        default:
+            return BaseState::onMessageReceived(msg);
+    }
+
+    return handled;
+}
+
+bool DashCodec::LoadedState::onConfigureComponent(
+        const sp<AMessage> &msg) {
+    ALOGV("onConfigureComponent");
+
+    CHECK(mCodec->mNode != NULL);
+
+    int32_t value;
+
+    if (msg->findInt32("secure-op", &value) && (value == 1)) {
+        mCodec->mFlags |= kFlagIsSecureOPOnly;
+    }
+
+    AString mime;
+    CHECK(msg->findString("mime", &mime));
+
+    status_t err = mCodec->configureCodec(mime.c_str(), msg);
+
+    if (err != OK) {
+        ALOGE("[%s] configureCodec returning error %d",
+              mCodec->mComponentName.c_str(), err);
+
+        mCodec->signalError(OMX_ErrorUndefined, err);
+        return false;
+    }
+
+    sp<RefBase> obj;
+    if (msg->findObject("native-window", &obj)
+            && strncmp("OMX.google.", mCodec->mComponentName.c_str(), 11)) {
+        sp<NativeWindowWrapper> nativeWindow(
+                static_cast<NativeWindowWrapper *>(obj.get()));
+        CHECK(nativeWindow != NULL);
+        mCodec->mNativeWindow = nativeWindow->getNativeWindow();
+
+        native_window_set_scaling_mode(
+                mCodec->mNativeWindow.get(),
+                NATIVE_WINDOW_SCALING_MODE_SCALE_TO_WINDOW);
+    }
+    CHECK_EQ((status_t)OK, mCodec->initNativeWindow());
+
+    {
+        sp<AMessage> notify = mCodec->mNotify->dup();
+        notify->setInt32("what", DashCodec::kWhatComponentConfigured);
+        notify->post();
+    }
+
+    return true;
+}
+
+void DashCodec::LoadedState::onStart() {
+    ALOGV("onStart");
+
+    CHECK_EQ(mCodec->mOMX->sendCommand(
+                mCodec->mNode, OMX_CommandStateSet, OMX_StateIdle),
+             (status_t)OK);
+
+    mCodec->changeState(mCodec->mLoadedToIdleState);
+}
+
+////////////////////////////////////////////////////////////////////////////////
+
+DashCodec::LoadedToIdleState::LoadedToIdleState(DashCodec *codec)
+    : BaseState(codec) {
+}
+
+void DashCodec::LoadedToIdleState::stateEntered() {
+    ALOGV("[%s] Now Loaded->Idle", mCodec->mComponentName.c_str());
+
+    status_t err;
+    if ((err = allocateBuffers()) != OK) {
+        ALOGE("Failed to allocate buffers after transitioning to IDLE state "
+             "(error 0x%08x)",
+             err);
+
+        mCodec->signalError(OMX_ErrorUndefined, err);
+
+        mCodec->changeState(mCodec->mLoadedState);
+    }
+}
+
+status_t DashCodec::LoadedToIdleState::allocateBuffers() {
+    status_t err = mCodec->allocateBuffersOnPort(kPortIndexInput);
+
+    if (err != OK) {
+        return err;
+    }
+
+    return mCodec->allocateBuffersOnPort(kPortIndexOutput);
+}
+
+bool DashCodec::LoadedToIdleState::onMessageReceived(const sp<AMessage> &msg) {
+    switch (msg->what()) {
+        case kWhatShutdown:
+        {
+            mCodec->deferMessage(msg);
+            return true;
+        }
+
+        default:
+            return BaseState::onMessageReceived(msg);
+    }
+}
+
+bool DashCodec::LoadedToIdleState::onOMXEvent(
+        OMX_EVENTTYPE event, OMX_U32 data1, OMX_U32 data2) {
+    switch (event) {
+        case OMX_EventCmdComplete:
+        {
+            CHECK_EQ(data1, (OMX_U32)OMX_CommandStateSet);
+            CHECK_EQ(data2, (OMX_U32)OMX_StateIdle);
+
+            CHECK_EQ(mCodec->mOMX->sendCommand(
+                        mCodec->mNode, OMX_CommandStateSet, OMX_StateExecuting),
+                     (status_t)OK);
+
+            mCodec->changeState(mCodec->mIdleToExecutingState);
+
+            return true;
+        }
+
+        default:
+            return BaseState::onOMXEvent(event, data1, data2);
+    }
+}
+
+////////////////////////////////////////////////////////////////////////////////
+
+DashCodec::IdleToExecutingState::IdleToExecutingState(DashCodec *codec)
+    : BaseState(codec) {
+}
+
+void DashCodec::IdleToExecutingState::stateEntered() {
+    ALOGV("[%s] Now Idle->Executing", mCodec->mComponentName.c_str());
+}
+
+bool DashCodec::IdleToExecutingState::onMessageReceived(const sp<AMessage> &msg) {
+    switch (msg->what()) {
+        case kWhatShutdown:
+        {
+            mCodec->deferMessage(msg);
+            return true;
+        }
+
+        default:
+            return BaseState::onMessageReceived(msg);
+    }
+}
+
+bool DashCodec::IdleToExecutingState::onOMXEvent(
+        OMX_EVENTTYPE event, OMX_U32 data1, OMX_U32 data2) {
+    switch (event) {
+        case OMX_EventCmdComplete:
+        {
+            CHECK_EQ(data1, (OMX_U32)OMX_CommandStateSet);
+            CHECK_EQ(data2, (OMX_U32)OMX_StateExecuting);
+
+            mCodec->mExecutingState->resume();
+            mCodec->changeState(mCodec->mExecutingState);
+
+            return true;
+        }
+
+        default:
+            return BaseState::onOMXEvent(event, data1, data2);
+    }
+}
+
+////////////////////////////////////////////////////////////////////////////////
+
+DashCodec::ExecutingState::ExecutingState(DashCodec *codec)
+    : BaseState(codec),
+      mActive(false) {
+}
+
+DashCodec::BaseState::PortMode DashCodec::ExecutingState::getPortMode(
+        OMX_U32 portIndex) {
+    return RESUBMIT_BUFFERS;
+}
+
+void DashCodec::ExecutingState::submitOutputBuffers() {
+    for (size_t i = 0; i < mCodec->mBuffers[kPortIndexOutput].size(); ++i) {
+        BufferInfo *info = &mCodec->mBuffers[kPortIndexOutput].editItemAt(i);
+
+        if (mCodec->mNativeWindow != NULL) {
+            CHECK(info->mStatus == BufferInfo::OWNED_BY_US
+                    || info->mStatus == BufferInfo::OWNED_BY_NATIVE_WINDOW);
+
+            if (info->mStatus == BufferInfo::OWNED_BY_NATIVE_WINDOW) {
+                continue;
+            }
+        } else {
+            CHECK_EQ((int)info->mStatus, (int)BufferInfo::OWNED_BY_US);
+        }
+
+        ALOGV("[%s] calling fillBuffer %p",
+             mCodec->mComponentName.c_str(), info->mBufferID);
+
+        CHECK_EQ(mCodec->mOMX->fillBuffer(mCodec->mNode, info->mBufferID),
+                 (status_t)OK);
+
+        info->mStatus = BufferInfo::OWNED_BY_COMPONENT;
+    }
+}
+
+void DashCodec::ExecutingState::resume() {
+    if (mActive) {
+        ALOGV("[%s] We're already active, no need to resume.",
+             mCodec->mComponentName.c_str());
+
+        return;
+    }
+
+    submitOutputBuffers();
+
+    // Post the first input buffer.
+    CHECK_GT(mCodec->mBuffers[kPortIndexInput].size(), 0u);
+    BufferInfo *info = &mCodec->mBuffers[kPortIndexInput].editItemAt(0);
+
+    postFillThisBuffer(info);
+
+    mActive = true;
+}
+
+void DashCodec::ExecutingState::stateEntered() {
+    ALOGV("[%s] Now Executing", mCodec->mComponentName.c_str());
+
+    mCodec->processDeferredMessages();
+}
+
+bool DashCodec::ExecutingState::onMessageReceived(const sp<AMessage> &msg) {
+    bool handled = false;
+
+    switch (msg->what()) {
+        case kWhatShutdown:
+        {
+            int32_t keepComponentAllocated;
+            CHECK(msg->findInt32(
+                        "keepComponentAllocated", &keepComponentAllocated));
+
+            mCodec->mShutdownInProgress = true;
+            mCodec->mKeepComponentAllocated = keepComponentAllocated;
+
+            mActive = false;
+
+            CHECK_EQ(mCodec->mOMX->sendCommand(
+                        mCodec->mNode, OMX_CommandStateSet, OMX_StateIdle),
+                     (status_t)OK);
+
+            mCodec->changeState(mCodec->mExecutingToIdleState);
+
+            handled = true;
+            break;
+        }
+
+        case kWhatFlush:
+        {
+            ALOGV("[%s] ExecutingState flushing now "
+                 "(codec owns %d/%d input, %d/%d output).",
+                    mCodec->mComponentName.c_str(),
+                    mCodec->countBuffersOwnedByComponent(kPortIndexInput),
+                    mCodec->mBuffers[kPortIndexInput].size(),
+                    mCodec->countBuffersOwnedByComponent(kPortIndexOutput),
+                    mCodec->mBuffers[kPortIndexOutput].size());
+
+            mActive = false;
+
+            CHECK_EQ(mCodec->mOMX->sendCommand(
+                        mCodec->mNode, OMX_CommandFlush, OMX_ALL),
+                     (status_t)OK);
+
+            mCodec->changeState(mCodec->mFlushingState);
+            mCodec->clearCachedFormats();
+            handled = true;
+            break;
+        }
+
+        case kWhatResume:
+        {
+            resume();
+
+            handled = true;
+            break;
+        }
+
+        case kWhatRequestIDRFrame:
+        {
+            status_t err = mCodec->requestIDRFrame();
+            if (err != OK) {
+                ALOGW("Requesting an IDR frame failed.");
+            }
+
+            handled = true;
+            break;
+        }
+
+        default:
+            handled = BaseState::onMessageReceived(msg);
+            break;
+    }
+
+    return handled;
+}
+
+bool DashCodec::ExecutingState::onOMXEvent(
+        OMX_EVENTTYPE event, OMX_U32 data1, OMX_U32 data2) {
+    switch (event) {
+        case OMX_EventPortSettingsChanged:
+        {
+            CHECK_EQ(data1, (OMX_U32)kPortIndexOutput);
+
+            if (data2 == 0 || data2 == OMX_IndexParamPortDefinition) {
+                ALOGV("Flush output port before disable");
+                CHECK_EQ(mCodec->mOMX->sendCommand(
+                        mCodec->mNode, OMX_CommandFlush, kPortIndexOutput),
+                     (status_t)OK);
+
+                mCodec->changeState(mCodec->mFlushingOutputState);
+
+            } else if (data2 == OMX_IndexConfigCommonOutputCrop) {
+                mCodec->mSentFormat = false;
+                mCodec->mPostFormat = false;
+                mCodec->queueNextFormat();
+            } else {
+                ALOGV("[%s] OMX_EventPortSettingsChanged 0x%08lx",
+                     mCodec->mComponentName.c_str(), data2);
+            }
+
+            return true;
+        }
+        case OMX_EventIndexsettingChanged:
+        {
+            ALOGW("[%s] Received OMX_EventIndexsettingChanged event ", mCodec->mComponentName.c_str());
+            mCodec->mSentFormat = false;
+            return true;
+        }
+        case OMX_EventBufferFlag:
+        {
+            return true;
+        }
+
+        default:
+            return BaseState::onOMXEvent(event, data1, data2);
+    }
+}
+
+////////////////////////////////////////////////////////////////////////////////
+
+DashCodec::OutputPortSettingsChangedState::OutputPortSettingsChangedState(
+        DashCodec *codec)
+    : BaseState(codec) {
+}
+
+DashCodec::BaseState::PortMode DashCodec::OutputPortSettingsChangedState::getPortMode(
+        OMX_U32 portIndex) {
+    if (portIndex == kPortIndexOutput) {
+        return FREE_BUFFERS;
+    }
+
+    CHECK_EQ(portIndex, (OMX_U32)kPortIndexInput);
+
+    return RESUBMIT_BUFFERS;
+}
+
+bool DashCodec::OutputPortSettingsChangedState::onMessageReceived(
+        const sp<AMessage> &msg) {
+    bool handled = false;
+
+    switch (msg->what()) {
+        case kWhatFlush:
+        case kWhatShutdown:
+        case kWhatResume:
+        {
+            if (msg->what() == kWhatResume) {
+                ALOGV("[%s] Deferring resume", mCodec->mComponentName.c_str());
+            }
+
+            mCodec->deferMessage(msg);
+            handled = true;
+            break;
+        }
+
+        default:
+            handled = BaseState::onMessageReceived(msg);
+            break;
+    }
+
+    return handled;
+}
+
+void DashCodec::OutputPortSettingsChangedState::stateEntered() {
+    ALOGV("[%s] Now handling output port settings change",
+         mCodec->mComponentName.c_str());
+}
+
+bool DashCodec::OutputPortSettingsChangedState::onOMXEvent(
+        OMX_EVENTTYPE event, OMX_U32 data1, OMX_U32 data2) {
+    switch (event) {
+        case OMX_EventCmdComplete:
+        {
+            if (data1 == (OMX_U32)OMX_CommandPortDisable) {
+                CHECK_EQ(data2, (OMX_U32)kPortIndexOutput);
+
+                ALOGV("[%s] Output port now disabled.",
+                        mCodec->mComponentName.c_str());
+
+                CHECK(mCodec->mBuffers[kPortIndexOutput].isEmpty());
+                mCodec->mDealer[kPortIndexOutput].clear();
+
+                CHECK_EQ(mCodec->mOMX->sendCommand(
+                            mCodec->mNode, OMX_CommandPortEnable, kPortIndexOutput),
+                         (status_t)OK);
+
+                status_t err;
+                if ((err = mCodec->allocateBuffersOnPort(
+                                kPortIndexOutput)) != OK) {
+                    ALOGE("Failed to allocate output port buffers after "
+                         "port reconfiguration (error 0x%08x)",
+                         err);
+
+                    mCodec->signalError(OMX_ErrorUndefined, err);
+
+                    // This is technically not correct, but appears to be
+                    // the only way to free the component instance.
+                    // Controlled transitioning from excecuting->idle
+                    // and idle->loaded seem impossible probably because
+                    // the output port never finishes re-enabling.
+                    mCodec->mShutdownInProgress = true;
+                    mCodec->mKeepComponentAllocated = false;
+                    mCodec->changeState(mCodec->mLoadedState);
+                }
+
+                return true;
+            } else if (data1 == (OMX_U32)OMX_CommandPortEnable) {
+                CHECK_EQ(data2, (OMX_U32)kPortIndexOutput);
+
+                mCodec->mSentFormat = false;
+
+                ALOGV("[%s] Output port now reenabled.",
+                        mCodec->mComponentName.c_str());
+
+                if (mCodec->mExecutingState->active()) {
+                    mCodec->mExecutingState->submitOutputBuffers();
+                }
+
+                mCodec->changeState(mCodec->mExecutingState);
+
+                return true;
+            }
+
+            return false;
+        }
+
+        default:
+            return false;
+    }
+}
+
+////////////////////////////////////////////////////////////////////////////////
+
+DashCodec::ExecutingToIdleState::ExecutingToIdleState(DashCodec *codec)
+    : BaseState(codec),
+      mComponentNowIdle(false) {
+}
+
+bool DashCodec::ExecutingToIdleState::onMessageReceived(const sp<AMessage> &msg) {
+    bool handled = false;
+
+    switch (msg->what()) {
+        case kWhatShutdown:
+        {
+            // We're already doing that...
+
+            handled = true;
+            break;
+        }
+
+        default:
+            handled = BaseState::onMessageReceived(msg);
+            break;
+    }
+
+    return handled;
+}
+
+void DashCodec::ExecutingToIdleState::stateEntered() {
+    ALOGV("[%s] Now Executing->Idle", mCodec->mComponentName.c_str());
+
+    mComponentNowIdle = false;
+    mCodec->mSentFormat = false;
+}
+
+bool DashCodec::ExecutingToIdleState::onOMXEvent(
+        OMX_EVENTTYPE event, OMX_U32 data1, OMX_U32 data2) {
+    switch (event) {
+        case OMX_EventCmdComplete:
+        {
+            CHECK_EQ(data1, (OMX_U32)OMX_CommandStateSet);
+            CHECK_EQ(data2, (OMX_U32)OMX_StateIdle);
+
+            mComponentNowIdle = true;
+
+            changeStateIfWeOwnAllBuffers();
+
+            return true;
+        }
+
+        case OMX_EventPortSettingsChanged:
+        case OMX_EventBufferFlag:
+        {
+            // We're shutting down and don't care about this anymore.
+            return true;
+        }
+
+        default:
+            return BaseState::onOMXEvent(event, data1, data2);
+    }
+}
+
+void DashCodec::ExecutingToIdleState::changeStateIfWeOwnAllBuffers() {
+    if (mComponentNowIdle && mCodec->allYourBuffersAreBelongToUs()) {
+        CHECK_EQ(mCodec->mOMX->sendCommand(
+                    mCodec->mNode, OMX_CommandStateSet, OMX_StateLoaded),
+                 (status_t)OK);
+
+        CHECK_EQ(mCodec->freeBuffersOnPort(kPortIndexInput), (status_t)OK);
+        CHECK_EQ(mCodec->freeBuffersOnPort(kPortIndexOutput), (status_t)OK);
+
+        if (mCodec->mFlags & kFlagIsSecure && mCodec->mNativeWindow != NULL) {
+            // We push enough 1x1 blank buffers to ensure that one of
+            // them has made it to the display.  This allows the OMX
+            // component teardown to zero out any protected buffers
+            // without the risk of scanning out one of those buffers.
+            mCodec->pushBlankBuffersToNativeWindow();
+        }
+
+        mCodec->changeState(mCodec->mIdleToLoadedState);
+    }
+}
+
+void DashCodec::ExecutingToIdleState::onInputBufferFilled(
+        const sp<AMessage> &msg) {
+    BaseState::onInputBufferFilled(msg);
+
+    changeStateIfWeOwnAllBuffers();
+}
+
+void DashCodec::ExecutingToIdleState::onOutputBufferDrained(
+        const sp<AMessage> &msg) {
+    BaseState::onOutputBufferDrained(msg);
+
+    changeStateIfWeOwnAllBuffers();
+}
+
+////////////////////////////////////////////////////////////////////////////////
+
+DashCodec::IdleToLoadedState::IdleToLoadedState(DashCodec *codec)
+    : BaseState(codec) {
+}
+
+bool DashCodec::IdleToLoadedState::onMessageReceived(const sp<AMessage> &msg) {
+    bool handled = false;
+
+    switch (msg->what()) {
+        case kWhatShutdown:
+        {
+            // We're already doing that...
+
+            handled = true;
+            break;
+        }
+
+        default:
+            handled = BaseState::onMessageReceived(msg);
+            break;
+    }
+
+    return handled;
+}
+
+void DashCodec::IdleToLoadedState::stateEntered() {
+    ALOGV("[%s] Now Idle->Loaded", mCodec->mComponentName.c_str());
+}
+
+bool DashCodec::IdleToLoadedState::onOMXEvent(
+        OMX_EVENTTYPE event, OMX_U32 data1, OMX_U32 data2) {
+    switch (event) {
+        case OMX_EventCmdComplete:
+        {
+            CHECK_EQ(data1, (OMX_U32)OMX_CommandStateSet);
+            CHECK_EQ(data2, (OMX_U32)OMX_StateLoaded);
+
+            mCodec->changeState(mCodec->mLoadedState);
+
+            return true;
+        }
+
+        default:
+            return BaseState::onOMXEvent(event, data1, data2);
+    }
+}
+
+////////////////////////////////////////////////////////////////////////////////
+
+DashCodec::FlushingState::FlushingState(DashCodec *codec)
+    : BaseState(codec) {
+}
+
+void DashCodec::FlushingState::stateEntered() {
+    ALOGV("[%s] Now Flushing", mCodec->mComponentName.c_str());
+
+    mFlushComplete[kPortIndexInput] = mFlushComplete[kPortIndexOutput] = false;
+}
+
+bool DashCodec::FlushingState::onMessageReceived(const sp<AMessage> &msg) {
+    bool handled = false;
+
+    switch (msg->what()) {
+        case kWhatShutdown:
+        {
+            mCodec->deferMessage(msg);
+            break;
+        }
+
+        case kWhatFlush:
+        {
+            // We're already doing this right now.
+            handled = true;
+            break;
+        }
+
+        default:
+            handled = BaseState::onMessageReceived(msg);
+            break;
+    }
+
+    return handled;
+}
+
+bool DashCodec::FlushingState::onOMXEvent(
+        OMX_EVENTTYPE event, OMX_U32 data1, OMX_U32 data2) {
+    ALOGV("[%s] FlushingState onOMXEvent(%d,%ld)",
+            mCodec->mComponentName.c_str(), event, data1);
+
+    switch (event) {
+        case OMX_EventCmdComplete:
+        {
+            CHECK_EQ(data1, (OMX_U32)OMX_CommandFlush);
+
+            if (data2 == kPortIndexInput || data2 == kPortIndexOutput) {
+                CHECK(!mFlushComplete[data2]);
+                mFlushComplete[data2] = true;
+
+                if (mFlushComplete[kPortIndexInput]
+                        && mFlushComplete[kPortIndexOutput]) {
+                    changeStateIfWeOwnAllBuffers();
+                }
+            } else {
+                CHECK_EQ(data2, OMX_ALL);
+                CHECK(mFlushComplete[kPortIndexInput]);
+                CHECK(mFlushComplete[kPortIndexOutput]);
+
+                changeStateIfWeOwnAllBuffers();
+            }
+
+            return true;
+        }
+
+        case OMX_EventPortSettingsChanged:
+        {
+            sp<AMessage> msg = new AMessage(kWhatOMXMessage, mCodec->id());
+            msg->setInt32("type", omx_message::EVENT);
+            msg->setPointer("node", mCodec->mNode);
+            msg->setInt32("event", event);
+            msg->setInt32("data1", data1);
+            msg->setInt32("data2", data2);
+
+            ALOGV("[%s] Deferring OMX_EventPortSettingsChanged",
+                 mCodec->mComponentName.c_str());
+
+            mCodec->deferMessage(msg);
+
+            return true;
+        }
+
+        default:
+            return BaseState::onOMXEvent(event, data1, data2);
+    }
+
+    return true;
+}
+
+void DashCodec::FlushingState::onOutputBufferDrained(const sp<AMessage> &msg) {
+    BaseState::onOutputBufferDrained(msg);
+
+    changeStateIfWeOwnAllBuffers();
+}
+
+void DashCodec::FlushingState::onInputBufferFilled(const sp<AMessage> &msg) {
+    BaseState::onInputBufferFilled(msg);
+
+    changeStateIfWeOwnAllBuffers();
+}
+
+void DashCodec::FlushingState::changeStateIfWeOwnAllBuffers() {
+    if (mFlushComplete[kPortIndexInput]
+            && mFlushComplete[kPortIndexOutput]
+            && mCodec->allYourBuffersAreBelongToUs()) {
+        sp<AMessage> notify = mCodec->mNotify->dup();
+        notify->setInt32("what", DashCodec::kWhatFlushCompleted);
+        notify->post();
+
+        mCodec->mPortEOS[kPortIndexInput] =
+            mCodec->mPortEOS[kPortIndexOutput] = false;
+
+        mCodec->mInputEOSResult = OK;
+
+        mCodec->changeState(mCodec->mExecutingState);
+    }
+}
+
+////////////////////////////////////////////////////////////////////////////////
+
+DashCodec::FlushingOutputState::FlushingOutputState(DashCodec *codec)
+    : BaseState(codec) {
+}
+
+DashCodec::BaseState::PortMode DashCodec::FlushingOutputState::getPortMode(OMX_U32 portIndex) {
+    if (portIndex == kPortIndexOutput)
+    {
+        return KEEP_BUFFERS;
+    }
+    return RESUBMIT_BUFFERS;
+}
+
+void DashCodec::FlushingOutputState::stateEntered() {
+    ALOGV("[%s] Now Flushing Output Port", mCodec->mComponentName.c_str());
+
+    mFlushComplete = false;
+}
+
+bool DashCodec::FlushingOutputState::onMessageReceived(const sp<AMessage> &msg) {
+    bool handled = false;
+
+    switch (msg->what()) {
+        case kWhatShutdown:
+        {
+            mCodec->deferMessage(msg);
+            handled = true;
+            break;
+        }
+
+        case kWhatFlush:
+        {
+            ALOGV("Flush received during port reconfig, deferring it");
+            mCodec->deferMessage(msg);
+            handled = true;
+            break;
+        }
+
+        case kWhatInputBufferFilled:
+        {
+            mCodec->deferMessage(msg);
+            changeStateIfWeOwnAllBuffers();
+            handled = true;
+            break;
+        }
+
+        default:
+            handled = BaseState::onMessageReceived(msg);
+            break;
+    }
+
+    return handled;
+}
+
+bool DashCodec::FlushingOutputState::onOMXEvent(
+        OMX_EVENTTYPE event, OMX_U32 data1, OMX_U32 data2) {
+    switch (event) {
+        case OMX_EventCmdComplete:
+        {
+            CHECK_EQ(data1, (OMX_U32)OMX_CommandFlush);
+            CHECK_EQ(data2,(OMX_U32)kPortIndexOutput);
+            ALOGV("FlushingOutputState::onOMXEvent Output port flush complete");
+            mFlushComplete = true;
+            changeStateIfWeOwnAllBuffers();
+            return true;
+        }
+
+        case OMX_EventPortSettingsChanged:
+        {
+            sp<AMessage> msg = new AMessage(kWhatOMXMessage, mCodec->id());
+            msg->setInt32("type", omx_message::EVENT);
+            msg->setPointer("node", mCodec->mNode);
+            msg->setInt32("event", event);
+            msg->setInt32("data1", data1);
+            msg->setInt32("data2", data2);
+
+            ALOGV("[%s] Deferring OMX_EventPortSettingsChanged",
+                 mCodec->mComponentName.c_str());
+
+            mCodec->deferMessage(msg);
+
+            return true;
+        }
+
+        default:
+            return BaseState::onOMXEvent(event, data1, data2);
+    }
+
+    return true;
+}
+
+void DashCodec::FlushingOutputState::onOutputBufferDrained(const sp<AMessage> &msg) {
+    BaseState::onOutputBufferDrained(msg);
+
+    changeStateIfWeOwnAllBuffers();
+}
+
+void DashCodec::FlushingOutputState::onInputBufferFilled(const sp<AMessage> &msg) {
+    BaseState::onInputBufferFilled(msg);
+
+    changeStateIfWeOwnAllBuffers();
+}
+
+void DashCodec::FlushingOutputState::changeStateIfWeOwnAllBuffers() {
+   ALOGV("FlushingOutputState::ChangeState %d",mFlushComplete);
+
+   if (mFlushComplete && mCodec->allYourBuffersAreBelongToUs( kPortIndexOutput )) {
+        ALOGV("FlushingOutputState Sending port disable ");
+        CHECK_EQ(mCodec->mOMX->sendCommand(
+                            mCodec->mNode,
+                            OMX_CommandPortDisable, kPortIndexOutput),
+                         (status_t)OK);
+
+        mCodec->mPortEOS[kPortIndexInput] = false;
+        mCodec->mPortEOS[kPortIndexOutput] = false;
+
+        ALOGV("FlushingOutputState Calling freeOutputBuffersNotOwnedByComponent");
+        mCodec->freeOutputBuffersNotOwnedByComponent();
+
+        ALOGV("FlushingOutputState Change state to port settings changed");
+        mCodec->changeState(mCodec->mOutputPortSettingsChangedState);
+    }
+}
+
+}  // namespace android
diff --git a/dashplayer/DashCodec.h b/dashplayer/DashCodec.h
new file mode 100644
index 0000000..7848bcb
--- /dev/null
+++ b/dashplayer/DashCodec.h
@@ -0,0 +1,288 @@
+/*
+ * Copyright (c) 2013, The Linux Foundation. All rights reserved.
+ * Not a Contribution.
+ *
+ * Copyright (C) 2010 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef DASH_CODEC_H_
+#define DASH_CODEC_H_
+
+#include <stdint.h>
+#include <android/native_window.h>
+#include <media/IOMX.h>
+#include <media/stagefright/foundation/AHierarchicalStateMachine.h>
+#include <media/stagefright/SkipCutBuffer.h>
+#include <OMX_Audio.h>
+#include <OMX_Component.h>
+
+#define TRACK_BUFFER_TIMING     0
+
+namespace android {
+
+struct ABuffer;
+struct MemoryDealer;
+
+struct DashCodec : public AHierarchicalStateMachine {
+    enum {
+        kWhatFillThisBuffer      = 'fill',
+        kWhatDrainThisBuffer     = 'drai',
+        kWhatEOS                 = 'eos ',
+        kWhatShutdownCompleted   = 'scom',
+        kWhatFlushCompleted      = 'fcom',
+        kWhatOutputFormatChanged = 'outC',
+        kWhatError               = 'erro',
+        kWhatComponentAllocated  = 'cAll',
+        kWhatComponentConfigured = 'cCon',
+        kWhatBuffersAllocated    = 'allc',
+    };
+
+    DashCodec();
+
+    void setNotificationMessage(const sp<AMessage> &msg);
+    void initiateSetup(const sp<AMessage> &msg);
+    void signalFlush();
+    void signalResume();
+    void initiateShutdown(bool keepComponentAllocated = false);
+
+    void initiateAllocateComponent(const sp<AMessage> &msg);
+    void initiateConfigureComponent(const sp<AMessage> &msg);
+    void initiateStart();
+
+    void signalRequestIDRFrame();
+    void queueNextFormat();
+    void clearCachedFormats();
+    struct PortDescription : public RefBase {
+        size_t countBuffers();
+        IOMX::buffer_id bufferIDAt(size_t index) const;
+        sp<ABuffer> bufferAt(size_t index) const;
+
+    private:
+        friend struct DashCodec;
+
+        Vector<IOMX::buffer_id> mBufferIDs;
+        Vector<sp<ABuffer> > mBuffers;
+
+        PortDescription();
+        void addBuffer(IOMX::buffer_id id, const sp<ABuffer> &buffer);
+
+        DISALLOW_EVIL_CONSTRUCTORS(PortDescription);
+    };
+
+protected:
+    virtual ~DashCodec();
+
+private:
+    struct BaseState;
+    struct UninitializedState;
+    struct LoadedState;
+    struct LoadedToIdleState;
+    struct IdleToExecutingState;
+    struct ExecutingState;
+    struct OutputPortSettingsChangedState;
+    struct ExecutingToIdleState;
+    struct IdleToLoadedState;
+    struct FlushingState;
+    struct FlushingOutputState;
+
+    enum {
+        kWhatSetup                   = 'setu',
+        kWhatOMXMessage              = 'omx ',
+        kWhatInputBufferFilled       = 'inpF',
+        kWhatOutputBufferDrained     = 'outD',
+        kWhatShutdown                = 'shut',
+        kWhatFlush                   = 'flus',
+        kWhatResume                  = 'resm',
+        kWhatDrainDeferredMessages   = 'drai',
+        kWhatAllocateComponent       = 'allo',
+        kWhatConfigureComponent      = 'conf',
+        kWhatStart                   = 'star',
+        kWhatRequestIDRFrame         = 'ridr',
+    };
+
+    enum {
+        kPortIndexInput  = 0,
+        kPortIndexOutput = 1
+    };
+
+    enum {
+        kFlagIsSecure   = 1,
+        kFlagIsSecureOPOnly = 2
+    };
+
+    struct BufferInfo {
+        enum Status {
+            OWNED_BY_US,
+            OWNED_BY_COMPONENT,
+            OWNED_BY_UPSTREAM,
+            OWNED_BY_DOWNSTREAM,
+            OWNED_BY_NATIVE_WINDOW,
+        };
+
+        IOMX::buffer_id mBufferID;
+        Status mStatus;
+
+        sp<ABuffer> mData;
+        sp<GraphicBuffer> mGraphicBuffer;
+    };
+
+#if TRACK_BUFFER_TIMING
+    struct BufferStats {
+        int64_t mEmptyBufferTimeUs;
+        int64_t mFillBufferDoneTimeUs;
+    };
+
+    KeyedVector<int64_t, BufferStats> mBufferStats;
+#endif
+
+    sp<AMessage> mNotify;
+
+    sp<UninitializedState> mUninitializedState;
+    sp<LoadedState> mLoadedState;
+    sp<LoadedToIdleState> mLoadedToIdleState;
+    sp<IdleToExecutingState> mIdleToExecutingState;
+    sp<ExecutingState> mExecutingState;
+    sp<OutputPortSettingsChangedState> mOutputPortSettingsChangedState;
+    sp<ExecutingToIdleState> mExecutingToIdleState;
+    sp<IdleToLoadedState> mIdleToLoadedState;
+    sp<FlushingState> mFlushingState;
+    sp<FlushingOutputState> mFlushingOutputState;
+    sp<SkipCutBuffer> mSkipCutBuffer;
+
+    AString mComponentName;
+    uint32_t mFlags;
+    uint32_t mQuirks;
+    sp<IOMX> mOMX;
+    IOMX::node_id mNode;
+    sp<MemoryDealer> mDealer[2];
+
+    sp<ANativeWindow> mNativeWindow;
+
+    Vector<BufferInfo> mBuffers[2];
+    bool mPortEOS[2];
+    status_t mInputEOSResult;
+
+    List<sp<AMessage> > mDeferredQueue;
+
+    bool mSentFormat;
+    bool mPostFormat;
+    bool mIsEncoder;
+
+    bool mShutdownInProgress;
+
+    // If "mKeepComponentAllocated" we only transition back to Loaded state
+    // and do not release the component instance.
+    bool mKeepComponentAllocated;
+
+    int32_t mEncoderDelay;
+    int32_t mEncoderPadding;
+
+    bool mChannelMaskPresent;
+    int32_t mChannelMask;
+
+    status_t allocateBuffersOnPort(OMX_U32 portIndex);
+    status_t freeBuffersOnPort(OMX_U32 portIndex);
+    status_t freeBuffer(OMX_U32 portIndex, size_t i);
+
+    status_t allocateOutputBuffersFromNativeWindow();
+    status_t cancelBufferToNativeWindow(BufferInfo *info);
+    status_t freeOutputBuffersNotOwnedByComponent();
+    BufferInfo *dequeueBufferFromNativeWindow();
+
+    BufferInfo *findBufferByID(
+            uint32_t portIndex, IOMX::buffer_id bufferID,
+            ssize_t *index = NULL);
+
+    status_t setComponentRole(bool isEncoder, const char *mime);
+    status_t configureCodec(const char *mime, const sp<AMessage> &msg);
+
+    status_t setVideoPortFormatType(
+            OMX_U32 portIndex,
+            OMX_VIDEO_CODINGTYPE compressionFormat,
+            OMX_COLOR_FORMATTYPE colorFormat);
+
+    status_t setSupportedOutputFormat();
+
+    status_t setupVideoDecoder(
+            const char *mime, int32_t width, int32_t height);
+
+    status_t setupVideoEncoder(
+            const char *mime, const sp<AMessage> &msg);
+
+    status_t setVideoFormatOnPort(
+            OMX_U32 portIndex,
+            int32_t width, int32_t height,
+            OMX_VIDEO_CODINGTYPE compressionFormat);
+
+    status_t setupAACCodec(
+            bool encoder,
+            int32_t numChannels, int32_t sampleRate, int32_t bitRate,
+            int32_t aacProfile, bool isADTS);
+
+    status_t selectAudioPortFormat(
+            OMX_U32 portIndex, OMX_AUDIO_CODINGTYPE desiredFormat);
+
+    status_t setupAMRCodec(bool encoder, bool isWAMR, int32_t bitRate);
+    status_t setupG711Codec(bool encoder, int32_t numChannels);
+
+    status_t setupFlacCodec(
+            bool encoder, int32_t numChannels, int32_t sampleRate, int32_t compressionLevel);
+
+    status_t setupRawAudioFormat(
+            OMX_U32 portIndex, int32_t sampleRate, int32_t numChannels);
+
+    status_t setMinBufferSize(OMX_U32 portIndex, size_t size);
+
+    status_t setupMPEG4EncoderParameters(const sp<AMessage> &msg);
+    status_t setupH263EncoderParameters(const sp<AMessage> &msg);
+    status_t setupAVCEncoderParameters(const sp<AMessage> &msg);
+
+    status_t verifySupportForProfileAndLevel(int32_t profile, int32_t level);
+
+    status_t configureBitrate(
+            int32_t bitrate, OMX_VIDEO_CONTROLRATETYPE bitrateMode);
+
+    status_t setupErrorCorrectionParameters();
+
+    status_t initNativeWindow();
+
+    status_t pushBlankBuffersToNativeWindow();
+
+    // Returns true iff all buffers on the given port have status OWNED_BY_US.
+    bool allYourBuffersAreBelongToUs(OMX_U32 portIndex);
+
+    bool allYourBuffersAreBelongToUs();
+
+    size_t countBuffersOwnedByComponent(OMX_U32 portIndex) const;
+
+    void deferMessage(const sp<AMessage> &msg);
+    void processDeferredMessages();
+
+    void sendFormatChange();
+
+    void signalError(
+            OMX_ERRORTYPE error = OMX_ErrorUndefined,
+            status_t internalError = UNKNOWN_ERROR);
+
+    status_t requestIDRFrame();
+    bool mAdaptivePlayback;
+    Vector<OMX_PARAM_PORTDEFINITIONTYPE*> mFormats;
+    Vector<OMX_CONFIG_RECTTYPE*> mOutputCrops;
+    DISALLOW_EVIL_CONSTRUCTORS(DashCodec);
+};
+
+}  // namespace android
+
+#endif  // DASH_CODEC_H_
diff --git a/dashplayer/DashFactory.cpp b/dashplayer/DashFactory.cpp
new file mode 100644
index 0000000..cb4e9e6
--- /dev/null
+++ b/dashplayer/DashFactory.cpp
@@ -0,0 +1,65 @@
+/*
+ *Copyright (c) 2013, The Linux Foundation. All rights reserved.
+ *Not a Contribution.
+ *
+ * Copyright (C) 2010 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+//#define LOG_NDEBUG 0
+#define LOG_TAG "DASHFactory"
+#include <media/IMediaPlayer.h>
+#include <utils/Log.h>
+#include "DashPlayerDriver.h"
+#include "MediaPlayerFactory.h"
+
+namespace android {
+
+class DashPlayerFactory : public MediaPlayerFactory::IFactory {
+  public:
+    virtual float scoreFactory(const sp<IMediaPlayer>& client,
+                               const char* url,
+                               float curScore) {
+        static const float kOurScore = 0.8;
+
+        if (kOurScore <= curScore)
+            return 0.0;
+
+        if (!strncasecmp("http://", url, 7)) {
+            size_t len = strlen(url);
+            if (len >= 5 && !strcasecmp(".mpd", &url[len - 4])) {
+                return kOurScore;
+            }
+        }
+        return 0.0;
+    }
+
+    virtual float scoreFactory(const sp<IMediaPlayer>& client,
+                               const sp<IStreamSource> &source,
+                               float curScore) {
+        return 0.0;
+    }
+
+    virtual sp<MediaPlayerBase> createPlayer() {
+        ALOGV("DashPlayerFactory::createPlayer");
+        return new DashPlayerDriver;
+    }
+};
+
+extern "C" MediaPlayerFactory::IFactory* CreateDASHFactory()
+{
+  return new DashPlayerFactory();
+}
+
+}  // namespace android
diff --git a/dashplayer/DashPacketSource.cpp b/dashplayer/DashPacketSource.cpp
new file mode 100644
index 0000000..8c6bc94
--- /dev/null
+++ b/dashplayer/DashPacketSource.cpp
@@ -0,0 +1,305 @@
+/*
+ *Copyright (c) 2013, The Linux Foundation. All rights reserved.
+ *Not a Contribution, Apache license notifications and license are retained
+ *for attribution purposes only.
+ *Copyright (C) 2010 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include "DashPacketSource.h"
+
+#include <media/stagefright/foundation/ABuffer.h>
+#include <media/stagefright/foundation/ADebug.h>
+#include <media/stagefright/foundation/AMessage.h>
+#include <media/stagefright/foundation/AString.h>
+#include <media/stagefright/foundation/hexdump.h>
+#include <media/stagefright/MediaBuffer.h>
+#include <media/stagefright/MediaDefs.h>
+#include <media/stagefright/MetaData.h>
+#include <utils/Vector.h>
+
+namespace android {
+
+DashPacketSource::DashPacketSource(const sp<MetaData> &meta)
+    : mIsAudio(false),
+      mFormat(meta),
+      mEOSResult(OK),
+      mStreamPID(0),
+      mProgramPID(0),
+      mFirstPTS(0) {
+    const char *mime;
+    CHECK(meta->findCString(kKeyMIMEType, &mime));
+
+    if (!strncasecmp("audio/", mime, 6)) {
+        mIsAudio = true;
+    }
+}
+
+void DashPacketSource::setFormat(const sp<MetaData> &meta) {
+    Mutex::Autolock autoLock(mLock);
+    CHECK(mFormat == NULL);
+    mFormat = meta;
+}
+
+void DashPacketSource::updateFormat(const sp<MetaData> &meta) {
+    Mutex::Autolock autoLock(mLock);
+    mFormat = meta;
+}
+
+DashPacketSource::~DashPacketSource() {
+}
+
+status_t DashPacketSource::start(MetaData *params) {
+    return OK;
+}
+
+status_t DashPacketSource::stop() {
+    return OK;
+}
+
+void DashPacketSource::setStreamInfo(unsigned streamPID, unsigned programPID, uint64_t firstPTS){
+    mStreamPID = streamPID;
+    mProgramPID = programPID;
+    mFirstPTS = firstPTS;
+}
+
+status_t DashPacketSource::getStreamInfo(unsigned& streamPID, unsigned& programPID, uint64_t& firstPTS){
+    streamPID = mStreamPID;
+    programPID = mProgramPID;
+    firstPTS = mFirstPTS;
+    return OK;
+}
+
+sp<MetaData> DashPacketSource::getFormat() {
+    Mutex::Autolock autoLock(mLock);
+    return mFormat;
+}
+
+status_t DashPacketSource::dequeueAccessUnit(sp<ABuffer> *buffer) {
+    buffer->clear();
+
+    Mutex::Autolock autoLock(mLock);
+    while (mEOSResult == OK && mBuffers.empty()) {
+        mCondition.wait(mLock);
+    }
+
+    if (!mBuffers.empty()) {
+        *buffer = *mBuffers.begin();
+        mBuffers.erase(mBuffers.begin());
+
+        int32_t discontinuity;
+        if ((*buffer)->meta()->findInt32("discontinuity", &discontinuity)) {
+            if (wasFormatChange(discontinuity)) {
+                mFormat.clear();
+            }
+
+            return INFO_DISCONTINUITY;
+        }
+
+        return OK;
+    }
+
+    return mEOSResult;
+}
+
+status_t DashPacketSource::read(
+        MediaBuffer **out, const ReadOptions *) {
+    *out = NULL;
+
+    Mutex::Autolock autoLock(mLock);
+    while (mEOSResult == OK && mBuffers.empty()) {
+        mCondition.wait(mLock);
+    }
+
+    if (!mBuffers.empty()) {
+        const sp<ABuffer> buffer = *mBuffers.begin();
+        mBuffers.erase(mBuffers.begin());
+
+        int32_t discontinuity;
+        if (buffer->meta()->findInt32("discontinuity", &discontinuity)) {
+            if (wasFormatChange(discontinuity)) {
+                mFormat.clear();
+            }
+
+            return INFO_DISCONTINUITY;
+        } else {
+            int64_t timeUs;
+            CHECK(buffer->meta()->findInt64("timeUs", &timeUs));
+
+            MediaBuffer *mediaBuffer = new MediaBuffer(buffer);
+
+            mediaBuffer->meta_data()->setInt64(kKeyTime, timeUs);
+
+            *out = mediaBuffer;
+            return OK;
+        }
+    }
+
+    return mEOSResult;
+}
+
+bool DashPacketSource::wasFormatChange(
+        int32_t discontinuityType) const {
+    if (mIsAudio) {
+        return (discontinuityType & ATSParser::DISCONTINUITY_AUDIO_FORMAT) != 0;
+    }
+
+    return (discontinuityType & ATSParser::DISCONTINUITY_VIDEO_FORMAT) != 0;
+}
+
+void DashPacketSource::queueAccessUnit(const sp<ABuffer> &buffer) {
+    int32_t damaged;
+    if (buffer->meta()->findInt32("damaged", &damaged) && damaged) {
+        // LOG(VERBOSE) << "discarding damaged AU";
+        return;
+    }
+
+    int64_t timeUs;
+    CHECK(buffer->meta()->findInt64("timeUs", &timeUs));
+    ALOGV("queueAccessUnit timeUs=%lld us (%.2f secs)", timeUs, timeUs / 1E6);
+
+    Mutex::Autolock autoLock(mLock);
+    mBuffers.push_back(buffer);
+    ALOGV("@@@@:: DashPacketSource --> size is %d ",mBuffers.size() );
+    mCondition.signal();
+}
+
+int DashPacketSource::getQueueSize() {
+    return mBuffers.size();
+}
+
+void DashPacketSource::queueDiscontinuity(
+        ATSParser::DiscontinuityType type,
+        const sp<AMessage> &extra) {
+    Mutex::Autolock autoLock(mLock);
+
+    if (type == ATSParser::DISCONTINUITY_SEEK ||
+        type == ATSParser::DISCONTINUITY_SEEK) {
+        ALOGI("Flushing all Access units for seek");
+        mBuffers.clear();
+        mEOSResult = OK;
+        mCondition.signal();
+        return;
+    }
+
+    // Leave only discontinuities in the queue.
+    List<sp<ABuffer> >::iterator it = mBuffers.begin();
+    while (it != mBuffers.end()) {
+        sp<ABuffer> oldBuffer = *it;
+
+        int32_t oldDiscontinuityType;
+        if (!oldBuffer->meta()->findInt32(
+                    "discontinuity", &oldDiscontinuityType)) {
+            it = mBuffers.erase(it);
+            continue;
+        }
+
+        ++it;
+    }
+
+    mEOSResult = OK;
+
+    sp<ABuffer> buffer = new ABuffer(0);
+    buffer->meta()->setInt32("discontinuity", static_cast<int32_t>(type));
+    buffer->meta()->setMessage("extra", extra);
+
+    mBuffers.push_back(buffer);
+    mCondition.signal();
+}
+
+void DashPacketSource::signalEOS(status_t result) {
+    CHECK(result != OK);
+
+    Mutex::Autolock autoLock(mLock);
+    mEOSResult = result;
+    mCondition.signal();
+}
+
+bool DashPacketSource::hasBufferAvailable(status_t *finalResult) {
+    Mutex::Autolock autoLock(mLock);
+    if (!mBuffers.empty()) {
+        return true;
+    }
+
+    *finalResult = mEOSResult;
+    return false;
+}
+
+int64_t DashPacketSource::getBufferedDurationUs(status_t *finalResult) {
+    Mutex::Autolock autoLock(mLock);
+
+    *finalResult = mEOSResult;
+
+    if (mBuffers.empty()) {
+        return 0;
+    }
+
+    int64_t time1 = -1;
+    int64_t time2 = -1;
+
+    List<sp<ABuffer> >::iterator it = mBuffers.begin();
+    while (it != mBuffers.end()) {
+        const sp<ABuffer> &buffer = *it;
+
+        int64_t timeUs;
+        if (buffer->meta()->findInt64("timeUs", &timeUs)) {
+            if (time1 < 0) {
+                time1 = timeUs;
+            }
+
+            time2 = timeUs;
+        } else {
+            // This is a discontinuity, reset everything.
+            time1 = time2 = -1;
+        }
+
+        ++it;
+    }
+
+    return time2 - time1;
+}
+
+status_t DashPacketSource::nextBufferTime(int64_t *timeUs) {
+    *timeUs = 0;
+
+    Mutex::Autolock autoLock(mLock);
+
+    if (mBuffers.empty()) {
+        return mEOSResult != OK ? mEOSResult : -EWOULDBLOCK;
+    }
+
+    sp<ABuffer> buffer = *mBuffers.begin();
+    CHECK(buffer->meta()->findInt64("timeUs", timeUs));
+    return OK;
+}
+
+status_t DashPacketSource::nextBufferIsSync(bool* isSyncFrame) {
+    Mutex::Autolock autoLock(mLock);
+    CHECK(isSyncFrame != NULL);
+
+    if (mBuffers.empty()) {
+        return mEOSResult != OK ? mEOSResult : -EWOULDBLOCK;
+    }
+
+    sp<ABuffer> buffer = *mBuffers.begin();
+
+    *isSyncFrame = false;
+    int32_t value = 0;
+    if (buffer->meta()->findInt32("isSync", &value) && (value == 1)) {
+       *isSyncFrame = true;
+    }
+    return OK;
+}
+
+}  // namespace android
diff --git a/dashplayer/DashPacketSource.h b/dashplayer/DashPacketSource.h
new file mode 100644
index 0000000..5185f8b
--- /dev/null
+++ b/dashplayer/DashPacketSource.h
@@ -0,0 +1,95 @@
+/*
+ *Copyright (c) 2013, The Linux Foundation. All rights reserved.
+ *Not a Contribution, Apache license notifications and license are retained
+ *for attribution purposes only.
+ *Copyright (C) 2010 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef DASH_PACKET_SOURCE_H_
+
+#define DASH_PACKET_SOURCE_H_
+
+#include <media/stagefright/foundation/ABase.h>
+#include <media/stagefright/MediaSource.h>
+#include <utils/threads.h>
+#include <utils/List.h>
+
+#include "ATSParser.h"
+
+namespace android {
+
+struct ABuffer;
+
+struct DashPacketSource : public MediaSource {
+    DashPacketSource(const sp<MetaData> &meta);
+
+    void setFormat(const sp<MetaData> &meta);
+
+    virtual status_t start(MetaData *params = NULL);
+    virtual status_t stop();
+    virtual sp<MetaData> getFormat();
+
+    virtual status_t read(
+            MediaBuffer **buffer, const ReadOptions *options = NULL);
+
+    bool hasBufferAvailable(status_t *finalResult);
+
+    // Returns the difference between the last and the first queued
+    // presentation timestamps since the last discontinuity (if any).
+    int64_t getBufferedDurationUs(status_t *finalResult);
+
+    status_t nextBufferTime(int64_t *timeUs);
+
+    void queueAccessUnit(const sp<ABuffer> &buffer);
+
+    void queueDiscontinuity(
+            ATSParser::DiscontinuityType type, const sp<AMessage> &extra);
+
+    void signalEOS(status_t result);
+
+    status_t dequeueAccessUnit(sp<ABuffer> *buffer);
+    void updateFormat(const sp<MetaData> &meta);
+    int getQueueSize();
+
+    status_t getStreamInfo(unsigned& streamPID, unsigned& programPID, uint64_t& firstPTS);
+
+    void setStreamInfo(unsigned streamPID, unsigned programPID, uint64_t firstPTS);
+
+    status_t nextBufferIsSync(bool* isSyncFrame);
+
+protected:
+    virtual ~DashPacketSource();
+
+private:
+    Mutex mLock;
+    Condition mCondition;
+
+    bool mIsAudio;
+    sp<MetaData> mFormat;
+    List<sp<ABuffer> > mBuffers;
+    status_t mEOSResult;
+    unsigned mStreamPID;
+    unsigned mProgramPID;
+    uint64_t mFirstPTS;
+
+    bool wasFormatChange(int32_t discontinuityType) const;
+
+    DISALLOW_EVIL_CONSTRUCTORS(DashPacketSource);
+};
+
+
+}  // namespace android
+
+#endif  // DASH_PACKET_SOURCE_H_
diff --git a/dashplayer/DashPlayer.cpp b/dashplayer/DashPlayer.cpp
new file mode 100644
index 0000000..0f3e4c0
--- /dev/null
+++ b/dashplayer/DashPlayer.cpp
@@ -0,0 +1,1751 @@
+/*
+ *Copyright (c) 2013, The Linux Foundation. All rights reserved.
+ *Not a Contribution.
+ *
+ * Copyright (C) 2010 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+//#define LOG_NDEBUG 0
+
+#define LOG_TAG "DashPlayer"
+#define SRMax 30
+#include <utils/Log.h>
+#include <dlfcn.h>  // for dlopen/dlclose
+#include "DashPlayer.h"
+#ifdef QCOM_WFD_SINK
+#include "WFDRenderer.h"
+#endif //QCOM_WFD_SINK
+//#include "HTTPLiveSource.h"
+#include "DashPlayerDecoder.h"
+#include "DashPlayerDriver.h"
+#include "DashPlayerRenderer.h"
+#include "DashPlayerSource.h"
+#include "DashCodec.h"
+//#include "RTSPSource.h"
+//#include "StreamingSource.h"
+//#include "GenericSource.h"
+
+#include "ATSParser.h"
+#include <media/stagefright/foundation/hexdump.h>
+#include <media/stagefright/foundation/ABuffer.h>
+#include <media/stagefright/foundation/ADebug.h>
+#include <media/stagefright/foundation/AMessage.h>
+#include <media/stagefright/foundation/AString.h>
+#include <media/stagefright/MediaDefs.h>
+#include <media/stagefright/MediaErrors.h>
+#include <media/stagefright/MetaData.h>
+#include <TextDescriptions.h>
+
+#ifdef ANDROID_JB_MR2
+#include <gui/IGraphicBufferProducer.h>
+#else
+#include <gui/ISurfaceTexture.h>
+#endif
+
+#include <cutils/properties.h>
+#include "avc_utils.h"
+
+namespace android {
+
+////////////////////////////////////////////////////////////////////////////////
+
+DashPlayer::DashPlayer()
+    : mUIDValid(false),
+      mVideoIsAVC(false),
+      mAudioEOS(false),
+      mVideoEOS(false),
+      mScanSourcesPending(false),
+      mScanSourcesGeneration(0),
+      mTimeDiscontinuityPending(false),
+      mFlushingAudio(NONE),
+      mFlushingVideo(NONE),
+      mResetInProgress(false),
+      mResetPostponed(false),
+      mSetVideoSize(true),
+      mSkipRenderingAudioUntilMediaTimeUs(-1ll),
+      mSkipRenderingVideoUntilMediaTimeUs(-1ll),
+      mVideoLateByUs(0ll),
+      mNumFramesTotal(0ll),
+      mNumFramesDropped(0ll),
+      mPauseIndication(false),
+      mSourceType(kDefaultSource),
+      mRenderer(NULL),
+      mIsSecureInputBuffers(false),
+      mStats(NULL),
+      mBufferingNotification(false),
+      mSRid(0) {
+      mTrackName = new char[6];
+}
+
+DashPlayer::~DashPlayer() {
+    if (mRenderer != NULL) {
+        looper()->unregisterHandler(mRenderer->id());
+    }
+    if (mAudioDecoder != NULL) {
+      looper()->unregisterHandler(mAudioDecoder->id());
+    }
+    if (mVideoDecoder != NULL) {
+      looper()->unregisterHandler(mVideoDecoder->id());
+    }
+    if (mTextDecoder != NULL) {
+      looper()->unregisterHandler(mTextDecoder->id());
+    }
+    if(mStats != NULL) {
+        mStats->logFpsSummary();
+        mStats = NULL;
+    }
+    if (mTrackName != NULL) {
+       delete[] mTrackName;
+       mTrackName = NULL;
+    }
+}
+
+void DashPlayer::setUID(uid_t uid) {
+    mUIDValid = true;
+    mUID = uid;
+}
+
+void DashPlayer::setDriver(const wp<DashPlayerDriver> &driver) {
+    mDriver = driver;
+}
+
+void DashPlayer::setDataSource(const sp<IStreamSource> &source) {
+    ALOGE("DashPlayer::setDataSource not Implemented...");
+}
+
+status_t DashPlayer::setDataSource(
+        const char *url, const KeyedVector<String8, String8> *headers) {
+    sp<AMessage> msg = new AMessage(kWhatSetDataSource, id());
+
+    sp<Source> source;
+    if (!strncasecmp(url, "http://", 7) &&
+          (strlen(url) >= 4 && !strcasecmp(".mpd", &url[strlen(url) - 4]))) {
+           /* Load the DASH HTTP Live source librery here */
+           ALOGV("DashPlayer setDataSource url sting %s",url);
+           source = LoadCreateSource(url, headers, mUIDValid, mUID,kHttpDashSource);
+           if (source != NULL) {
+              mSourceType = kHttpDashSource;
+              msg->setObject("source", source);
+              msg->post();
+              return OK;
+           } else {
+             ALOGE("Error creating DASH source");
+             return UNKNOWN_ERROR;
+           }
+    }
+    else
+    {
+      ALOGE("Unsupported URL");
+      return UNKNOWN_ERROR;
+    }
+}
+
+void DashPlayer::setDataSource(int fd, int64_t offset, int64_t length) {
+   ALOGE("DashPlayer::setDataSource not Implemented...");
+}
+
+#ifdef ANDROID_JB_MR2
+void DashPlayer::setVideoSurfaceTexture(const sp<IGraphicBufferProducer> &bufferProducer) {
+    sp<AMessage> msg = new AMessage(kWhatSetVideoNativeWindow, id());
+    sp<Surface> surface(bufferProducer != NULL ?
+                new Surface(bufferProducer) : NULL);
+    msg->setObject("native-window", new NativeWindowWrapper(surface));
+    msg->post();
+}
+#else
+void DashPlayer::setVideoSurfaceTexture(const sp<ISurfaceTexture> &surfaceTexture) {
+    mSetVideoSize = true;
+    sp<AMessage> msg = new AMessage(kWhatSetVideoNativeWindow, id());
+    sp<SurfaceTextureClient> surfaceTextureClient(surfaceTexture != NULL ?
+                new SurfaceTextureClient(surfaceTexture) : NULL);
+    msg->setObject("native-window", new NativeWindowWrapper(surfaceTextureClient));
+    msg->post();
+}
+#endif
+
+void DashPlayer::setAudioSink(const sp<MediaPlayerBase::AudioSink> &sink) {
+    sp<AMessage> msg = new AMessage(kWhatSetAudioSink, id());
+    msg->setObject("sink", sink);
+    msg->post();
+}
+
+void DashPlayer::start() {
+    (new AMessage(kWhatStart, id()))->post();
+}
+
+void DashPlayer::pause() {
+    (new AMessage(kWhatPause, id()))->post();
+}
+
+void DashPlayer::resume() {
+    (new AMessage(kWhatResume, id()))->post();
+}
+
+void DashPlayer::resetAsync() {
+    (new AMessage(kWhatReset, id()))->post();
+}
+
+void DashPlayer::seekToAsync(int64_t seekTimeUs) {
+    sp<AMessage> msg = new AMessage(kWhatSeek, id());
+    msg->setInt64("seekTimeUs", seekTimeUs);
+    msg->post();
+}
+
+// static
+bool DashPlayer::IsFlushingState(FlushStatus state, bool *needShutdown) {
+    switch (state) {
+        case FLUSHING_DECODER:
+            if (needShutdown != NULL) {
+                *needShutdown = false;
+            }
+            return true;
+
+        case FLUSHING_DECODER_SHUTDOWN:
+        case SHUTTING_DOWN_DECODER:
+            if (needShutdown != NULL) {
+                *needShutdown = true;
+            }
+            return true;
+
+        default:
+            return false;
+    }
+}
+
+void DashPlayer::onMessageReceived(const sp<AMessage> &msg) {
+    switch (msg->what()) {
+        case kWhatSetDataSource:
+        {
+            ALOGV("kWhatSetDataSource");
+
+            CHECK(mSource == NULL);
+
+            sp<RefBase> obj;
+            CHECK(msg->findObject("source", &obj));
+
+            mSource = static_cast<Source *>(obj.get());
+            if (mSourceType == kHttpDashSource) {
+               prepareSource();
+            }
+            break;
+        }
+
+        case kWhatSetVideoNativeWindow:
+        {
+            ALOGV("kWhatSetVideoNativeWindow");
+
+            sp<RefBase> obj;
+            CHECK(msg->findObject("native-window", &obj));
+
+            mNativeWindow = static_cast<NativeWindowWrapper *>(obj.get());
+            break;
+        }
+
+        case kWhatSetAudioSink:
+        {
+            ALOGV("kWhatSetAudioSink");
+
+            sp<RefBase> obj;
+            CHECK(msg->findObject("sink", &obj));
+
+            mAudioSink = static_cast<MediaPlayerBase::AudioSink *>(obj.get());
+            break;
+        }
+
+        case kWhatStart:
+        {
+            ALOGV("kWhatStart");
+
+            mVideoIsAVC = false;
+            mAudioEOS = false;
+            mVideoEOS = false;
+            mSkipRenderingAudioUntilMediaTimeUs = -1;
+            mSkipRenderingVideoUntilMediaTimeUs = -1;
+            mVideoLateByUs = 0;
+            mNumFramesTotal = 0;
+            mNumFramesDropped = 0;
+            if (mSource != NULL)
+            {
+              mSource->start();
+            }
+
+            // for qualcomm statistics profiling
+            mStats = new DashPlayerStats();
+
+#ifdef QCOM_WFD_SINK
+            if (mSourceType == kWfdSource) {
+                ALOGV("creating WFDRenderer in NU player");
+                mRenderer = new WFDRenderer(
+                        mAudioSink,
+                        new AMessage(kWhatRendererNotify, id()));
+            }
+            else {
+#endif /* QCOM_WFD_SINK */
+                mRenderer = new Renderer(
+                        mAudioSink,
+                        new AMessage(kWhatRendererNotify, id()));
+#ifdef QCOM_WFD_SINK
+            }
+#endif /* QCOM_WFD_SINK */
+                mRenderer->registerStats(mStats);
+                looper()->registerHandler(mRenderer);
+
+            postScanSources();
+            break;
+        }
+
+        case kWhatScanSources:
+        {
+            if (!mPauseIndication) {
+                int32_t generation = 0;
+                CHECK(msg->findInt32("generation", &generation));
+                if (generation != mScanSourcesGeneration) {
+                    // Drop obsolete msg.
+                    break;
+                }
+
+                mScanSourcesPending = false;
+                if (mSourceType == kHttpDashSource) {
+                    ALOGV("scanning sources haveAudio=%d, haveVideo=%d haveText=%d",
+                         mAudioDecoder != NULL, mVideoDecoder != NULL, mTextDecoder!= NULL);
+                } else {
+                    ALOGV("scanning sources haveAudio=%d, haveVideo=%d",
+                         mAudioDecoder != NULL, mVideoDecoder != NULL);
+                }
+
+                if(mNativeWindow != NULL) {
+                    instantiateDecoder(kVideo, &mVideoDecoder);
+                }
+
+                if (mAudioSink != NULL) {
+                    instantiateDecoder(kAudio, &mAudioDecoder);
+                }
+                if (mSourceType == kHttpDashSource) {
+                    instantiateDecoder(kText, &mTextDecoder);
+                }
+
+                status_t err;
+                if ((err = mSource->feedMoreTSData()) != OK) {
+                    if (mAudioDecoder == NULL && mVideoDecoder == NULL) {
+                        // We're not currently decoding anything (no audio or
+                        // video tracks found) and we just ran out of input data.
+
+                        if (err == ERROR_END_OF_STREAM) {
+                            notifyListener(MEDIA_PLAYBACK_COMPLETE, 0, 0);
+                        } else {
+                            notifyListener(MEDIA_ERROR, MEDIA_ERROR_UNKNOWN, err);
+                        }
+                    }
+                    break;
+                }
+                if (mSourceType == kHttpDashSource) {
+                    if ((mAudioDecoder == NULL && mAudioSink != NULL)     ||
+                        (mVideoDecoder == NULL && mNativeWindow != NULL)  ||
+                        (mTextDecoder == NULL)) {
+                          msg->post(100000ll);
+                          mScanSourcesPending = true;
+                    }
+                } else {
+                    if ((mAudioDecoder == NULL && mAudioSink != NULL) ||
+                        (mVideoDecoder == NULL && mNativeWindow != NULL)) {
+                           msg->post(100000ll);
+                           mScanSourcesPending = true;
+                    }
+               }
+               if (mTimeDiscontinuityPending && mRenderer != NULL){
+                   mRenderer->signalTimeDiscontinuity();
+                   mTimeDiscontinuityPending = false;
+               }
+            }
+            break;
+        }
+
+        case kWhatVideoNotify:
+        case kWhatAudioNotify:
+        case kWhatTextNotify:
+        {
+            int track;
+            if (msg->what() == kWhatAudioNotify)
+                track = kAudio;
+            else if (msg->what() == kWhatVideoNotify)
+                track = kVideo;
+            else if (msg->what() == kWhatTextNotify)
+                track = kText;
+
+            getTrackName(track,mTrackName);
+
+            sp<AMessage> codecRequest;
+            CHECK(msg->findMessage("codec-request", &codecRequest));
+
+            int32_t what;
+            CHECK(codecRequest->findInt32("what", &what));
+
+            if (what == DashCodec::kWhatFillThisBuffer) {
+                ALOGV("@@@@:: Dashplayer :: MESSAGE FROM DASHCODEC +++++++++++++ (%s) kWhatFillThisBuffer",mTrackName);
+                if ( (track == kText) && (mTextDecoder == NULL)) {
+                    break; // no need to proceed further
+                }
+
+                //if Player is in pause state, for WFD use case ,store the fill Buffer events and return back
+                if((mSourceType == kWfdSource) && (mPauseIndication)) {
+                    QueueEntry entry;
+                    entry.mMessageToBeConsumed = msg;
+                    mDecoderMessageQueue.push_back(entry);
+                    break;
+                }
+
+                status_t err = feedDecoderInputData(
+                        track, codecRequest);
+
+                if (err == -EWOULDBLOCK) {
+                    if (mSource->feedMoreTSData() == OK) {
+                           msg->post(10000ll);
+                    }
+                }
+
+            } else if (what == DashCodec::kWhatEOS) {
+                ALOGV("@@@@:: Dashplayer :: MESSAGE FROM DASHCODEC +++++++++++++++++++++++++++++++ kWhatEOS");
+                int32_t err;
+                CHECK(codecRequest->findInt32("err", &err));
+
+                if (err == ERROR_END_OF_STREAM) {
+                    ALOGW("got %s decoder EOS", mTrackName);
+                } else {
+                    ALOGE("got %s decoder EOS w/ error %d",
+                         mTrackName,
+                         err);
+                }
+
+                if(mRenderer != NULL)
+                {
+                  if((track == kAudio && !IsFlushingState(mFlushingAudio)) || (track == kVideo && !IsFlushingState(mFlushingVideo))) {
+                    mRenderer->queueEOS(track, err);
+                  }
+                  else{
+                    ALOGE("FlushingState for %s. Decoder EOS not queued to renderer", mTrackName);
+                  }
+                }
+            } else if (what == DashCodec::kWhatFlushCompleted) {
+                ALOGV("@@@@:: Dashplayer :: MESSAGE FROM DASHCODEC +++++++++++++++++++++++++++++++ kWhatFlushCompleted");
+
+                Mutex::Autolock autoLock(mLock);
+                bool needShutdown;
+
+                if (track == kAudio) {
+                    CHECK(IsFlushingState(mFlushingAudio, &needShutdown));
+                    mFlushingAudio = FLUSHED;
+                } else if (track == kVideo){
+                    CHECK(IsFlushingState(mFlushingVideo, &needShutdown));
+                    mFlushingVideo = FLUSHED;
+
+                    mVideoLateByUs = 0;
+                }
+
+                ALOGV("decoder %s flush completed", mTrackName);
+
+                if (needShutdown) {
+                    ALOGV("initiating %s decoder shutdown",
+                           mTrackName);
+
+                    if (track == kAudio) {
+                        mAudioDecoder->initiateShutdown();
+                        mFlushingAudio = SHUTTING_DOWN_DECODER;
+                    } else if (track == kVideo) {
+                        mVideoDecoder->initiateShutdown();
+                        mFlushingVideo = SHUTTING_DOWN_DECODER;
+                    }
+                }
+
+                finishFlushIfPossible();
+            } else if (what == DashCodec::kWhatOutputFormatChanged) {
+                if (track == kAudio) {
+                    ALOGV("@@@@:: Dashplayer :: MESSAGE FROM DASHCODEC +++++++++++++++++++++++++++++++ kWhatOutputFormatChanged:: audio");
+                    int32_t numChannels;
+                    CHECK(codecRequest->findInt32("channel-count", &numChannels));
+
+                    int32_t sampleRate;
+                    CHECK(codecRequest->findInt32("sample-rate", &sampleRate));
+
+                    ALOGW("Audio output format changed to %d Hz, %d channels",
+                         sampleRate, numChannels);
+
+                    mAudioSink->close();
+
+                    audio_output_flags_t flags;
+                    int64_t durationUs;
+                    // FIXME: we should handle the case where the video decoder is created after
+                    // we receive the format change indication. Current code will just make that
+                    // we select deep buffer with video which should not be a problem as it should
+                    // not prevent from keeping A/V sync.
+                    if (mVideoDecoder == NULL &&
+                            mSource->getDuration(&durationUs) == OK &&
+                            durationUs > AUDIO_SINK_MIN_DEEP_BUFFER_DURATION_US) {
+                        flags = AUDIO_OUTPUT_FLAG_DEEP_BUFFER;
+                    } else {
+                        flags = AUDIO_OUTPUT_FLAG_NONE;
+                    }
+
+                    int32_t channelMask;
+                    if (!codecRequest->findInt32("channel-mask", &channelMask)) {
+                        channelMask = CHANNEL_MASK_USE_CHANNEL_ORDER;
+                    }
+
+                    CHECK_EQ(mAudioSink->open(
+                                sampleRate,
+                                numChannels,
+                                (audio_channel_mask_t)channelMask,
+                                AUDIO_FORMAT_PCM_16_BIT,
+                                8 /* bufferCount */,
+                                NULL,
+                                NULL,
+                                flags),
+                             (status_t)OK);
+                    mAudioSink->start();
+
+                    if(mRenderer != NULL) {
+                        mRenderer->signalAudioSinkChanged();
+                    }
+                } else if (track == kVideo) {
+                    // video
+                    ALOGV("@@@@:: Dashplayer :: MESSAGE FROM DASHCODEC +++++++++++++++++++++++++++++++ kWhatOutputFormatChanged:: video");
+                    // No need to notify JAVA layer the message of kWhatOutputFormatChanged which will cause a flicker while changing the resolution
+#if 0
+                        int32_t width, height;
+                        CHECK(codecRequest->findInt32("width", &width));
+                        CHECK(codecRequest->findInt32("height", &height));
+
+                        int32_t cropLeft, cropTop, cropRight, cropBottom;
+                        CHECK(codecRequest->findRect(
+                                    "crop",
+                                    &cropLeft, &cropTop, &cropRight, &cropBottom));
+
+                        ALOGW("Video output format changed to %d x %d "
+                             "(crop: %d x %d @ (%d, %d))",
+                             width, height,
+                             (cropRight - cropLeft + 1),
+                             (cropBottom - cropTop + 1),
+                             cropLeft, cropTop);
+
+                        notifyListener(
+                                MEDIA_SET_VIDEO_SIZE,
+                                cropRight - cropLeft + 1,
+                                cropBottom - cropTop + 1);
+#endif
+                }
+            } else if (what == DashCodec::kWhatShutdownCompleted) {
+                ALOGV("%s shutdown completed", mTrackName);
+                if (track == kAudio) {
+                    ALOGV("@@@@:: Dashplayer :: MESSAGE FROM DASHCODEC +++++++++++++++++++++++++++++++ kWhatShutdownCompleted:: audio");
+                    if (mAudioDecoder != NULL) {
+                        looper()->unregisterHandler(mAudioDecoder->id());
+                    }
+                    mAudioDecoder.clear();
+
+                    CHECK_EQ((int)mFlushingAudio, (int)SHUTTING_DOWN_DECODER);
+                    mFlushingAudio = SHUT_DOWN;
+                } else if (track == kVideo) {
+                    ALOGV("@@@@:: Dashplayer :: MESSAGE FROM DASHCODEC +++++++++++++++++++++++++++++++ kWhatShutdownCompleted:: Video");
+                    if (mVideoDecoder != NULL) {
+                        looper()->unregisterHandler(mVideoDecoder->id());
+                    }
+                    mVideoDecoder.clear();
+
+                    CHECK_EQ((int)mFlushingVideo, (int)SHUTTING_DOWN_DECODER);
+                    mFlushingVideo = SHUT_DOWN;
+                }
+
+                finishFlushIfPossible();
+            } else if (what == DashCodec::kWhatError) {
+                ALOGE("Received error from %s decoder, aborting playback.",
+                       mTrackName);
+                if(mRenderer != NULL)
+                {
+                  if((track == kAudio && !IsFlushingState(mFlushingAudio)) ||
+                     (track == kVideo && !IsFlushingState(mFlushingVideo)))
+                  {
+                    ALOGV("@@@@:: Dashplayer :: MESSAGE FROM DASHCODEC +++++++++++++++++++++++++++++++ DashCodec::kWhatError:: %s",track == kAudio ? "audio" : "video");
+                    mRenderer->queueEOS(track, UNKNOWN_ERROR);
+                }
+                  else{
+                    ALOGE("EOS not queued for %s track", track);
+                  }
+                }
+            } else if (what == DashCodec::kWhatDrainThisBuffer) {
+                if(track == kAudio || track == kVideo) {
+                   ALOGV("@@@@:: Dashplayer :: MESSAGE FROM DASHCODEC +++++++++++++++++++++++++++++++ DashCodec::kWhatRenderBuffer:: %s",track == kAudio ? "audio" : "video");
+                        renderBuffer(track, codecRequest);
+                    }
+            } else {
+                ALOGV("Unhandled codec notification %d.", what);
+            }
+
+            break;
+        }
+
+        case kWhatRendererNotify:
+        {
+            int32_t what;
+            CHECK(msg->findInt32("what", &what));
+
+            if (what == Renderer::kWhatEOS) {
+                int32_t audio;
+                CHECK(msg->findInt32("audio", &audio));
+
+                int32_t finalResult;
+                CHECK(msg->findInt32("finalResult", &finalResult));
+                ALOGV("@@@@:: Dashplayer :: MESSAGE FROM RENDERER ***************** kWhatRendererNotify:: %s",audio ? "audio" : "video");
+                if (audio) {
+                    mAudioEOS = true;
+                } else {
+                    mVideoEOS = true;
+                }
+
+                if (finalResult == ERROR_END_OF_STREAM) {
+                    ALOGW("reached %s EOS", audio ? "audio" : "video");
+                } else {
+                    ALOGE("%s track encountered an error (%d)",
+                         audio ? "audio" : "video", finalResult);
+
+                    notifyListener(
+                            MEDIA_ERROR, MEDIA_ERROR_UNKNOWN, finalResult);
+                }
+
+                if ((mAudioEOS || mAudioDecoder == NULL)
+                        && (mVideoEOS || mVideoDecoder == NULL)) {
+                     if ((mSourceType == kHttpDashSource) &&
+                         (finalResult == ERROR_END_OF_STREAM)) {
+                        notifyListener(MEDIA_PLAYBACK_COMPLETE, 0, 0);
+                     } else if (mSourceType != kHttpDashSource) {
+                       notifyListener(MEDIA_PLAYBACK_COMPLETE, 0, 0);
+                     }
+                }
+            } else if (what == Renderer::kWhatPosition) {
+                int64_t positionUs;
+                CHECK(msg->findInt64("positionUs", &positionUs));
+
+                CHECK(msg->findInt64("videoLateByUs", &mVideoLateByUs));
+                ALOGV("@@@@:: Dashplayer :: MESSAGE FROM RENDERER ***************** kWhatPosition:: position(%lld) VideoLateBy(%lld)",positionUs,mVideoLateByUs);
+
+                if (mDriver != NULL) {
+                    sp<DashPlayerDriver> driver = mDriver.promote();
+                    if (driver != NULL) {
+                        driver->notifyPosition(positionUs);
+                        //Notify rendering position used for HLS
+                        mSource->notifyRenderingPosition(positionUs);
+
+                        driver->notifyFrameStats(
+                                mNumFramesTotal, mNumFramesDropped);
+                    }
+                }
+            } else if (what == Renderer::kWhatFlushComplete) {
+                CHECK_EQ(what, (int32_t)Renderer::kWhatFlushComplete);
+
+                int32_t audio;
+                CHECK(msg->findInt32("audio", &audio));
+                ALOGV("@@@@:: Dashplayer :: MESSAGE FROM RENDERER ***************** kWhatFlushComplete:: %s",audio ? "audio" : "video");
+
+            }
+            break;
+        }
+
+        case kWhatMoreDataQueued:
+        {
+            break;
+        }
+
+        case kWhatReset:
+        {
+            ALOGV("kWhatReset");
+            Mutex::Autolock autoLock(mLock);
+
+            if (mRenderer != NULL) {
+                // There's an edge case where the renderer owns all output
+                // buffers and is paused, therefore the decoder will not read
+                // more input data and will never encounter the matching
+                // discontinuity. To avoid this, we resume the renderer.
+
+                if (mFlushingAudio == AWAITING_DISCONTINUITY
+                        || mFlushingVideo == AWAITING_DISCONTINUITY) {
+                    mRenderer->resume();
+                }
+            }
+            if ( (mAudioDecoder != NULL && IsFlushingState(mFlushingAudio)) ||
+                 (mVideoDecoder != NULL && IsFlushingState(mFlushingVideo)) ) {
+
+                // We're currently flushing, postpone the reset until that's
+                // completed.
+
+                ALOGV("postponing reset mFlushingAudio=%d, mFlushingVideo=%d",
+                      mFlushingAudio, mFlushingVideo);
+
+                mResetPostponed = true;
+                break;
+            }
+
+            if (mAudioDecoder == NULL && mVideoDecoder == NULL) {
+                finishReset();
+                break;
+            }
+
+            mTimeDiscontinuityPending = true;
+
+            if (mAudioDecoder != NULL) {
+                flushDecoder(true /* audio */, true /* needShutdown */);
+            }
+
+            if (mVideoDecoder != NULL) {
+                flushDecoder(false /* audio */, true /* needShutdown */);
+            }
+
+            mResetInProgress = true;
+            break;
+        }
+
+        case kWhatSeek:
+        {
+            if(mStats != NULL) {
+                mStats->notifySeek();
+            }
+
+            Mutex::Autolock autoLock(mLock);
+            int64_t seekTimeUs = -1, newSeekTime = -1;
+            status_t nRet = OK;
+            CHECK(msg->findInt64("seekTimeUs", &seekTimeUs));
+
+            ALOGW("kWhatSeek seekTimeUs=%lld us (%.2f secs)",
+                 seekTimeUs, seekTimeUs / 1E6);
+
+            nRet = mSource->seekTo(seekTimeUs);
+
+            if (mSourceType == kHttpLiveSource) {
+                mSource->getNewSeekTime(&newSeekTime);
+                ALOGV("newSeekTime %lld", newSeekTime);
+            }
+            else if (mSourceType == kHttpDashSource) {
+                mTimeDiscontinuityPending = true;
+                if (nRet == OK) { // if seek success then flush the audio,video decoder and renderer
+                  bool audPresence = false;
+                  bool vidPresence = false;
+                  bool textPresence = false;
+                  mSource->getMediaPresence(audPresence,vidPresence,textPresence);
+                  mRenderer->setMediaPresence(true,audPresence); // audio
+                  mRenderer->setMediaPresence(false,vidPresence); // video
+                  if( (mVideoDecoder != NULL) &&
+                      (mFlushingVideo == NONE || mFlushingVideo == AWAITING_DISCONTINUITY) ) {
+                      flushDecoder( false, true ); // flush video, shutdown
+                  }
+
+                 if( (mAudioDecoder != NULL) &&
+                     (mFlushingAudio == NONE|| mFlushingAudio == AWAITING_DISCONTINUITY) )
+                 {
+                     flushDecoder( true, true );  // flush audio,  shutdown
+                 }
+                 if( mAudioDecoder == NULL ) {
+                     ALOGV("Audio is not there, set it to shutdown");
+                     mFlushingAudio = SHUT_DOWN;
+                 }
+                 if( mVideoDecoder == NULL ) {
+                     ALOGV("Video is not there, set it to shutdown");
+                     mFlushingVideo = SHUT_DOWN;
+                 }
+               }
+               // get the new seeked position
+               newSeekTime = seekTimeUs;
+               ALOGV("newSeekTime %lld", newSeekTime);
+            }
+            if( (newSeekTime >= 0 ) && (mSourceType != kHttpDashSource)) {
+               mTimeDiscontinuityPending = true;
+               if( (mAudioDecoder != NULL) &&
+                   (mFlushingAudio == NONE || mFlushingAudio == AWAITING_DISCONTINUITY) ) {
+                  flushDecoder( true, true );
+               }
+               if( (mVideoDecoder != NULL) &&
+                   (mFlushingVideo == NONE || mFlushingVideo == AWAITING_DISCONTINUITY) ) {
+                  flushDecoder( false, true );
+               }
+               if( mAudioDecoder == NULL ) {
+                   ALOGV("Audio is not there, set it to shutdown");
+                   mFlushingAudio = SHUT_DOWN;
+
+               }
+               if( mVideoDecoder == NULL ) {
+                   ALOGV("Video is not there, set it to shutdown");
+                   mFlushingVideo = SHUT_DOWN;
+               }
+            }
+
+            if(mStats != NULL) {
+                mStats->logSeek(seekTimeUs);
+            }
+
+            if (mDriver != NULL) {
+                sp<DashPlayerDriver> driver = mDriver.promote();
+                if (driver != NULL) {
+                    if( newSeekTime >= 0 ) {
+                        mRenderer->notifySeekPosition(newSeekTime);
+                        driver->notifyPosition( newSeekTime );
+                        mSource->notifyRenderingPosition(newSeekTime);
+                        driver->notifySeekComplete();
+                     }
+                }
+            }
+
+            break;
+        }
+
+        case kWhatPause:
+        {
+#ifdef QCOM_WFD_SINK
+            if (mSourceType == kWfdSource) {
+                CHECK(mSource != NULL);
+                mSource->pause();
+            }
+#endif //QCOM_WFD_SINK
+                CHECK(mRenderer != NULL);
+                mRenderer->pause();
+
+            mPauseIndication = true;
+            if (mSourceType == kHttpDashSource) {
+                Mutex::Autolock autoLock(mLock);
+                if (mSource != NULL)
+                {
+                   mSource->pause();
+                }
+            }
+            break;
+        }
+
+        case kWhatResume:
+        {
+                CHECK(mRenderer != NULL);
+                mRenderer->resume();
+
+            mPauseIndication = false;
+
+            if (mSourceType == kHttpDashSource) {
+               Mutex::Autolock autoLock(mLock);
+               if (mSource != NULL) {
+                   mSource->resume();
+               }
+                if (mAudioDecoder == NULL || mVideoDecoder == NULL || mTextDecoder == NULL) {
+                    mScanSourcesPending = false;
+                    postScanSources();
+                }
+            }else if (mSourceType == kWfdSource) {
+                CHECK(mSource != NULL);
+                mSource->resume();
+                int count = 0;
+
+                //check if there are messages stored in the list, then repost them
+                while(!mDecoderMessageQueue.empty()) {
+                    (*mDecoderMessageQueue.begin()).mMessageToBeConsumed->post(); //self post
+                    mDecoderMessageQueue.erase(mDecoderMessageQueue.begin());
+                    ++count;
+                }
+                ALOGE("(%d) stored messages reposted ....",count);
+            }else {
+                if (mAudioDecoder == NULL || mVideoDecoder == NULL) {
+                    mScanSourcesPending = false;
+                    postScanSources();
+                }
+            }
+            break;
+        }
+
+        case kWhatPrepareAsync:
+            if (mSource == NULL)
+            {
+                ALOGE("Source is null in prepareAsync\n");
+                break;
+            }
+            mSource->prepareAsync();
+            postIsPrepareDone();
+            break;
+
+        case kWhatIsPrepareDone:
+            if (mSource == NULL)
+            {
+                ALOGE("Source is null when checking for prepare done\n");
+                break;
+            }
+            if (mSource->isPrepareDone()) {
+                int64_t durationUs;
+                if (mDriver != NULL && mSource->getDuration(&durationUs) == OK) {
+                    sp<DashPlayerDriver> driver = mDriver.promote();
+                    if (driver != NULL) {
+                        driver->notifyDuration(durationUs);
+                    }
+                }
+                notifyListener(MEDIA_PREPARED, 0, 0);
+            } else {
+                msg->post(100000ll);
+            }
+            break;
+        case kWhatSourceNotify:
+        {
+            Mutex::Autolock autoLock(mLock);
+            ALOGV("kWhatSourceNotify");
+
+            if(mSource != NULL) {
+                int64_t track;
+
+                sp<AMessage> sourceRequest;
+                ALOGD("kWhatSourceNotify - looking for source-request");
+
+                // attempt to find message by different names
+                bool msgFound = msg->findMessage("source-request", &sourceRequest);
+                int32_t handled;
+                if (!msgFound) {
+                    ALOGD("kWhatSourceNotify source-request not found, trying using sourceRequestID");
+                    char srName[] = "source-request00";
+                    srName[strlen("source-request")] += mSRid/10;
+                    srName[strlen("source-request")+sizeof(char)] += mSRid%10;
+                    msgFound = msg->findMessage(srName, &sourceRequest);
+                    if(msgFound)
+                        mSRid = (mSRid+1)%SRMax;
+                }
+
+                if(msgFound) {
+                    int32_t what;
+                    CHECK(sourceRequest->findInt32("what", &what));
+                    sourceRequest->findInt64("track", &track);
+                    getTrackName((int)track,mTrackName);
+
+                    if (what == kWhatBufferingStart) {
+                      ALOGE("Source Notified Buffering Start for %s ",mTrackName);
+                      if (mBufferingNotification == false) {
+                          if (track == kVideo && mNativeWindow == NULL)
+                          {
+                               ALOGE("video decoder not instantiated, no buffering for video",
+                                     mBufferingNotification);
+                          }
+                          else
+                          {
+                              mBufferingNotification = true;
+                              notifyListener(MEDIA_INFO, MEDIA_INFO_BUFFERING_START, 0);
+                          }
+                      }
+                      else {
+                         ALOGE("Buffering Start Event Already Notified mBufferingNotification(%d)",
+                               mBufferingNotification);
+                      }
+                    }
+                    else if(what == kWhatBufferingEnd) {
+                        if (mBufferingNotification) {
+                          ALOGE("Source Notified Buffering End for %s ",mTrackName);
+                                mBufferingNotification = false;
+                          notifyListener(MEDIA_INFO, MEDIA_INFO_BUFFERING_END, 0);
+                          if(mStats != NULL) {
+                            mStats->notifyBufferingEvent();
+                          }
+                        }
+                        else {
+                          ALOGE("No need to notify Buffering end as mBufferingNotification is (%d) "
+                                ,mBufferingNotification);
+                        }
+                    }
+                }
+            }
+            else {
+              ALOGE("kWhatSourceNotify - Source object does not exist anymore");
+            }
+            break;
+        }
+
+        default:
+            TRESPASS();
+            break;
+    }
+}
+
+void DashPlayer::finishFlushIfPossible() {
+    //If reset was postponed after one of the streams is flushed, complete it now
+    if (mResetPostponed) {
+        ALOGV("finishFlushIfPossible Handle reset postpone ");
+        if ((mAudioDecoder != NULL) &&
+            (mFlushingAudio == NONE || mFlushingAudio == AWAITING_DISCONTINUITY )) {
+           flushDecoder( true, true );
+        }
+        if ((mVideoDecoder != NULL) &&
+            (mFlushingVideo == NONE || mFlushingVideo == AWAITING_DISCONTINUITY )) {
+           flushDecoder( false, true );
+        }
+    }
+
+    //Check if both audio & video are flushed
+    if (mFlushingAudio != FLUSHED && mFlushingAudio != SHUT_DOWN) {
+        ALOGV("Dont finish flush, audio is in state %d ", mFlushingAudio);
+        return;
+    }
+
+    if (mFlushingVideo != FLUSHED && mFlushingVideo != SHUT_DOWN) {
+        ALOGV("Dont finish flush, video is in state %d ", mFlushingVideo);
+        return;
+    }
+
+    ALOGV("both audio and video are flushed now.");
+
+    if ((mRenderer != NULL) && (mTimeDiscontinuityPending)) {
+        mRenderer->signalTimeDiscontinuity();
+        mTimeDiscontinuityPending = false;
+    }
+
+    if (mAudioDecoder != NULL) {
+        ALOGV("Resume Audio after flush");
+        mAudioDecoder->signalResume();
+    }
+
+    if (mVideoDecoder != NULL) {
+        ALOGV("Resume Video after flush");
+        mVideoDecoder->signalResume();
+    }
+
+    mFlushingAudio = NONE;
+    mFlushingVideo = NONE;
+
+    if (mResetInProgress) {
+        ALOGV("reset completed");
+
+        mResetInProgress = false;
+        finishReset();
+    } else if (mResetPostponed) {
+        (new AMessage(kWhatReset, id()))->post();
+        mResetPostponed = false;
+        ALOGV("Handle reset postpone");
+    } else if (mAudioDecoder == NULL || mVideoDecoder == NULL) {
+        ALOGV("Start scanning for sources after shutdown");
+        if ( (mSourceType == kHttpDashSource) &&
+             (mTextDecoder != NULL) )
+        {
+          if (mSource != NULL) {
+           ALOGV("finishFlushIfPossible calling mSource->stop");
+           mSource->stop();
+          }
+          sp<AMessage> codecRequest;
+          mTextNotify->findMessage("codec-request", &codecRequest);
+          codecRequest = NULL;
+          mTextNotify = NULL;
+          looper()->unregisterHandler(mTextDecoder->id());
+          mTextDecoder.clear();
+        }
+        postScanSources();
+    }
+}
+
+void DashPlayer::finishReset() {
+    CHECK(mAudioDecoder == NULL);
+    CHECK(mVideoDecoder == NULL);
+
+    ++mScanSourcesGeneration;
+    mScanSourcesPending = false;
+
+    if (mRenderer != NULL) {
+        looper()->unregisterHandler(mRenderer->id());
+    }
+    if(mRenderer != NULL) {
+        mRenderer.clear();
+    }
+
+    if (mSource != NULL) {
+        ALOGV("finishReset calling mSource->stop");
+        mSource->stop();
+        mSource.clear();
+    }
+
+    if ( (mSourceType == kHttpDashSource) && (mTextDecoder != NULL) && (mTextNotify != NULL))
+    {
+      sp<AMessage> codecRequest;
+      mTextNotify->findMessage("codec-request", &codecRequest);
+      codecRequest = NULL;
+      mTextNotify = NULL;
+      looper()->unregisterHandler(mTextDecoder->id());
+      mTextDecoder.clear();
+      ALOGE("Text Dummy Decoder Deleted");
+    }
+    if (mSourceNotify != NULL)
+    {
+       sp<AMessage> sourceRequest;
+       mSourceNotify->findMessage("source-request", &sourceRequest);
+       sourceRequest = NULL;
+       for (int id = 0; id < SRMax; id++){
+           char srName[] = "source-request00";
+           srName[strlen("source-request")] += id/10;
+           srName[strlen("source-request")+sizeof(char)] += id%10;
+           mSourceNotify->findMessage(srName, &sourceRequest);
+           sourceRequest = NULL;
+       }
+       mSourceNotify = NULL;
+    }
+
+    if (mDriver != NULL) {
+        sp<DashPlayerDriver> driver = mDriver.promote();
+        if (driver != NULL) {
+            driver->notifyResetComplete();
+        }
+    }
+}
+
+void DashPlayer::postScanSources() {
+    if (mScanSourcesPending) {
+        return;
+    }
+
+    sp<AMessage> msg = new AMessage(kWhatScanSources, id());
+    msg->setInt32("generation", mScanSourcesGeneration);
+    msg->post();
+
+    mScanSourcesPending = true;
+}
+
+status_t DashPlayer::instantiateDecoder(int track, sp<Decoder> *decoder) {
+    ALOGV("@@@@:: instantiateDecoder Called ");
+    if (*decoder != NULL) {
+        return OK;
+    }
+
+    sp<MetaData> meta = mSource->getFormat(track);
+
+    if (meta == NULL) {
+        return -EWOULDBLOCK;
+    }
+
+    if (track == kVideo) {
+        const char *mime;
+        CHECK(meta->findCString(kKeyMIMEType, &mime));
+        mVideoIsAVC = !strcasecmp(MEDIA_MIMETYPE_VIDEO_AVC, mime);
+        if(mStats != NULL) {
+            mStats->setMime(mime);
+        }
+
+        //TO-DO:: Similarly set here for Decode order
+        if (mVideoIsAVC &&
+           ((mSourceType == kHttpLiveSource) || (mSourceType == kHttpDashSource) ||(mSourceType == kWfdSource))) {
+            ALOGV("Set Enable smooth streaming in meta data ");
+            meta->setInt32(kKeySmoothStreaming, 1);
+        }
+
+        int32_t isDRMSecBuf = 0;
+        meta->findInt32(kKeyRequiresSecureBuffers, &isDRMSecBuf);
+        if(isDRMSecBuf) {
+            mIsSecureInputBuffers = true;
+        }
+
+        if (mSetVideoSize) {
+            int32_t width = 0;
+            meta->findInt32(kKeyWidth, &width);
+            int32_t height = 0;
+            meta->findInt32(kKeyHeight, &height);
+            ALOGE("instantiate video decoder, send wxh = %dx%d",width,height);
+            notifyListener(MEDIA_SET_VIDEO_SIZE, width, height);
+            mSetVideoSize = false;
+        }
+    }
+
+    sp<AMessage> notify;
+    if (track == kAudio) {
+        notify = new AMessage(kWhatAudioNotify ,id());
+        ALOGV("Creating Audio Decoder ");
+        *decoder = new Decoder(notify);
+        ALOGV("@@@@:: setting Sink/Renderer pointer to decoder");
+        (*decoder)->setSink(mAudioSink, mRenderer);
+    } else if (track == kVideo) {
+        notify = new AMessage(kWhatVideoNotify ,id());
+        *decoder = new Decoder(notify, mNativeWindow);
+        ALOGV("Creating Video Decoder ");
+    } else if (track == kText) {
+        mTextNotify = new AMessage(kWhatTextNotify ,id());
+        *decoder = new Decoder(mTextNotify);
+        sp<AMessage> codecRequest = new AMessage;
+        codecRequest->setInt32("what", DashCodec::kWhatFillThisBuffer);
+        mTextNotify->setMessage("codec-request", codecRequest);
+        ALOGV("Creating Dummy Text Decoder ");
+        if ((mSource != NULL) && (mSourceType == kHttpDashSource)) {
+           mSource->setupSourceData(mTextNotify, track);
+        }
+    }
+
+    looper()->registerHandler(*decoder);
+
+    char value[PROPERTY_VALUE_MAX] = {0};
+    if (mSourceType == kHttpLiveSource || mSourceType == kHttpDashSource){
+        //Set flushing state to none
+        Mutex::Autolock autoLock(mLock);
+        if(track == kAudio) {
+            mFlushingAudio = NONE;
+        } else if (track == kVideo) {
+            mFlushingVideo = NONE;
+
+        }
+    }
+
+    if( track == kAudio || track == kVideo) {
+        (*decoder)->configure(meta);
+    }
+
+    int64_t durationUs;
+    if (mDriver != NULL && mSource->getDuration(&durationUs) == OK) {
+        sp<DashPlayerDriver> driver = mDriver.promote();
+        if (driver != NULL) {
+            driver->notifyDuration(durationUs);
+        }
+    }
+
+    return OK;
+}
+
+status_t DashPlayer::feedDecoderInputData(int track, const sp<AMessage> &msg) {
+    sp<AMessage> reply;
+
+    if ( (track != kText) && !(msg->findMessage("reply", &reply)))
+    {
+       CHECK(msg->findMessage("reply", &reply));
+    }
+
+    {
+        Mutex::Autolock autoLock(mLock);
+
+        if (((track == kAudio) && IsFlushingState(mFlushingAudio))
+            || ((track == kVideo) && IsFlushingState(mFlushingVideo))) {
+            reply->setInt32("err", INFO_DISCONTINUITY);
+            reply->post();
+            return OK;
+        }
+    }
+
+    getTrackName(track,mTrackName);
+
+    sp<ABuffer> accessUnit;
+
+    bool dropAccessUnit;
+    do {
+
+        status_t err = UNKNOWN_ERROR;
+
+        if (mIsSecureInputBuffers && track == kVideo) {
+            msg->findBuffer("buffer", &accessUnit);
+
+            if (accessUnit == NULL) {
+                ALOGE("Dashplayer NULL buffer in message");
+                return err;
+            } else {
+                ALOGV("Dashplayer buffer in message %d %d",
+                accessUnit->data(), accessUnit->capacity());
+            }
+        }
+
+        err = mSource->dequeueAccessUnit(track, &accessUnit);
+
+        if (err == -EWOULDBLOCK) {
+            return err;
+        } else if (err != OK) {
+            if (err == INFO_DISCONTINUITY) {
+                int32_t type;
+                CHECK(accessUnit->meta()->findInt32("discontinuity", &type));
+
+                bool formatChange =
+                    ((track == kAudio) &&
+                     (type & ATSParser::DISCONTINUITY_AUDIO_FORMAT))
+                    || ((track == kVideo) &&
+                            (type & ATSParser::DISCONTINUITY_VIDEO_FORMAT));
+
+                bool timeChange = (type & ATSParser::DISCONTINUITY_TIME) != 0;
+
+                ALOGW("%s discontinuity (formatChange=%d, time=%d)",
+                     mTrackName, formatChange, timeChange);
+
+                if (track == kAudio) {
+                    mSkipRenderingAudioUntilMediaTimeUs = -1;
+                } else if (track == kVideo) {
+                    mSkipRenderingVideoUntilMediaTimeUs = -1;
+                }
+
+                if (timeChange) {
+                    sp<AMessage> extra;
+                    if (accessUnit->meta()->findMessage("extra", &extra)
+                            && extra != NULL) {
+                        int64_t resumeAtMediaTimeUs;
+                        if (extra->findInt64(
+                                    "resume-at-mediatimeUs", &resumeAtMediaTimeUs)) {
+                            ALOGW("suppressing rendering of %s until %lld us",
+                                    mTrackName, resumeAtMediaTimeUs);
+
+                            if (track == kAudio) {
+                                mSkipRenderingAudioUntilMediaTimeUs =
+                                    resumeAtMediaTimeUs;
+                            } else if (track == kVideo) {
+                                mSkipRenderingVideoUntilMediaTimeUs =
+                                    resumeAtMediaTimeUs;
+                            }
+                        }
+                    }
+                }
+
+                mTimeDiscontinuityPending =
+                    mTimeDiscontinuityPending || timeChange;
+
+                if (formatChange || timeChange) {
+                    flushDecoder(track, formatChange);
+                } else {
+                    // This stream is unaffected by the discontinuity
+
+                    if (track == kAudio) {
+                        mFlushingAudio = FLUSHED;
+                    } else if (track == kVideo) {
+                        mFlushingVideo = FLUSHED;
+                    }
+
+                    finishFlushIfPossible();
+
+                    return -EWOULDBLOCK;
+                }
+            }
+
+            if ( (track == kAudio) ||
+                 (track == kVideo))
+            {
+               reply->setInt32("err", err);
+               reply->post();
+               return OK;
+            }
+            else if ((track == kText) &&
+                     (err == ERROR_END_OF_STREAM || err == (status_t)UNKNOWN_ERROR)) {
+               ALOGE("Text track has encountered error %d", err );
+               sendTextPacket(NULL, err);
+               return err;
+            }
+        }
+
+        dropAccessUnit = false;
+        if (track == kVideo) {
+            ++mNumFramesTotal;
+
+            if(mStats != NULL) {
+                mStats->incrementTotalFrames();
+            }
+
+            if (mVideoLateByUs > 100000ll
+                    && mVideoIsAVC
+                    && !mIsSecureInputBuffers
+                    && !IsAVCReferenceFrame(accessUnit)) {
+                dropAccessUnit = true;
+                ++mNumFramesDropped;
+                if(mStats != NULL) {
+                    mStats->incrementDroppedFrames();
+                }
+            }
+        }
+    } while (dropAccessUnit);
+
+    // ALOGV("returned a valid buffer of %s data", mTrackName);
+
+#if 0
+    int64_t mediaTimeUs;
+    CHECK(accessUnit->meta()->findInt64("timeUs", &mediaTimeUs));
+    ALOGV("feeding %s input buffer at media time %.2f secs",
+         mTrackName,
+         mediaTimeUs / 1E6);
+#endif
+    if (track == kVideo || track == kAudio) {
+        reply->setBuffer("buffer", accessUnit);
+        reply->post();
+    } else if (mSourceType == kHttpDashSource && track == kText) {
+        sendTextPacket(accessUnit,OK);
+        if (mSource != NULL) {
+          mSource->postNextTextSample(accessUnit,mTextNotify,track);
+        }
+    }
+    return OK;
+}
+
+void DashPlayer::renderBuffer(bool audio, const sp<AMessage> &msg) {
+    // ALOGV("renderBuffer %s", audio ? "audio" : "video");
+
+    sp<AMessage> reply;
+    CHECK(msg->findMessage("reply", &reply));
+
+    Mutex::Autolock autoLock(mLock);
+    if (IsFlushingState(audio ? mFlushingAudio : mFlushingVideo)) {
+        // We're currently attempting to flush the decoder, in order
+        // to complete this, the decoder wants all its buffers back,
+        // so we don't want any output buffers it sent us (from before
+        // we initiated the flush) to be stuck in the renderer's queue.
+
+        ALOGV("we're still flushing the %s decoder, sending its output buffer"
+             " right back.", audio ? "audio" : "video");
+
+        reply->post();
+        return;
+    }
+
+    sp<ABuffer> buffer;
+    CHECK(msg->findBuffer("buffer", &buffer));
+
+    int64_t &skipUntilMediaTimeUs =
+        audio
+            ? mSkipRenderingAudioUntilMediaTimeUs
+            : mSkipRenderingVideoUntilMediaTimeUs;
+
+    if (skipUntilMediaTimeUs >= 0) {
+        int64_t mediaTimeUs;
+        CHECK(buffer->meta()->findInt64("timeUs", &mediaTimeUs));
+
+        if (mediaTimeUs < skipUntilMediaTimeUs) {
+            ALOGV("dropping %s buffer at time %lld as requested.",
+                 audio ? "audio" : "video",
+                 mediaTimeUs);
+
+            reply->post();
+            return;
+        }
+
+        skipUntilMediaTimeUs = -1;
+    }
+
+    if(mRenderer != NULL) {
+        mRenderer->queueBuffer(audio, buffer, reply);
+    }
+}
+
+void DashPlayer::notifyListener(int msg, int ext1, int ext2, const Parcel *obj) {
+    if (mDriver == NULL) {
+        return;
+    }
+
+    sp<DashPlayerDriver> driver = mDriver.promote();
+
+    if (driver == NULL) {
+        return;
+    }
+
+        driver->notifyListener(msg, ext1, ext2, obj);
+}
+
+void DashPlayer::flushDecoder(bool audio, bool needShutdown) {
+    if ((audio && mAudioDecoder == NULL) || (!audio && mVideoDecoder == NULL)) {
+        ALOGI("flushDecoder %s without decoder present",
+             audio ? "audio" : "video");
+    }
+
+    // Make sure we don't continue to scan sources until we finish flushing.
+    ++mScanSourcesGeneration;
+    mScanSourcesPending = false;
+
+    (audio ? mAudioDecoder : mVideoDecoder)->signalFlush();
+
+    if(mRenderer != NULL) {
+        mRenderer->flush(audio);
+    }
+
+    FlushStatus newStatus =
+        needShutdown ? FLUSHING_DECODER_SHUTDOWN : FLUSHING_DECODER;
+
+    if (audio) {
+        CHECK(mFlushingAudio == NONE
+                || mFlushingAudio == AWAITING_DISCONTINUITY);
+
+        mFlushingAudio = newStatus;
+
+        if (mFlushingVideo == NONE) {
+            mFlushingVideo = (mVideoDecoder != NULL)
+                ? AWAITING_DISCONTINUITY
+                : FLUSHED;
+        }
+    } else {
+        CHECK(mFlushingVideo == NONE
+                || mFlushingVideo == AWAITING_DISCONTINUITY);
+
+        mFlushingVideo = newStatus;
+
+        if (mFlushingAudio == NONE) {
+            mFlushingAudio = (mAudioDecoder != NULL)
+                ? AWAITING_DISCONTINUITY
+                : FLUSHED;
+        }
+    }
+}
+
+sp<DashPlayer::Source>
+    DashPlayer::LoadCreateSource(const char * uri, const KeyedVector<String8,String8> *headers,
+                               bool uidValid, uid_t uid, NuSourceType srcTyp)
+{
+   const char* STREAMING_SOURCE_LIB = "libmmipstreamaal.so";
+   const char* DASH_HTTP_LIVE_CREATE_SOURCE = "CreateDashHttpLiveSource";
+   const char* WFD_CREATE_SOURCE = "CreateWFDSource";
+   void* pStreamingSourceLib = NULL;
+
+   typedef DashPlayer::Source* (*SourceFactory)(const char * uri, const KeyedVector<String8, String8> *headers, bool uidValid, uid_t uid);
+
+   /* Open librery */
+   pStreamingSourceLib = ::dlopen(STREAMING_SOURCE_LIB, RTLD_LAZY);
+
+   if (pStreamingSourceLib == NULL) {
+       ALOGV("@@@@:: STREAMING  Source Library (libmmipstreamaal.so) Load Failed  Error : %s ",::dlerror());
+       return NULL;
+   }
+
+   SourceFactory StreamingSourcePtr;
+
+   if(srcTyp == kHttpDashSource) {
+
+       /* Get the entry level symbol which gets us the pointer to DASH HTTP Live Source object */
+       StreamingSourcePtr = (SourceFactory) dlsym(pStreamingSourceLib, DASH_HTTP_LIVE_CREATE_SOURCE);
+   } else if (srcTyp == kWfdSource){
+
+       /* Get the entry level symbol which gets us the pointer to WFD Source object */
+       StreamingSourcePtr = (SourceFactory) dlsym(pStreamingSourceLib, WFD_CREATE_SOURCE);
+
+   }
+
+   if (StreamingSourcePtr == NULL) {
+       ALOGV("@@@@:: CreateDashHttpLiveSource symbol not found in libmmipstreamaal.so, return NULL ");
+       return NULL;
+   }
+
+    /*Get the Streaming (DASH\WFD) Source object, which will be used to communicate with Source (DASH\WFD) */
+    sp<DashPlayer::Source> StreamingSource = StreamingSourcePtr(uri, headers, uidValid, uid);
+
+    if(StreamingSource==NULL) {
+        ALOGV("@@@@:: StreamingSource failed to instantiate Source ");
+        return NULL;
+    }
+
+
+    return StreamingSource;
+}
+
+status_t DashPlayer::prepareAsync() // only for DASH
+{
+    if (mSourceType == kHttpDashSource) {
+        sp<AMessage> msg = new AMessage(kWhatPrepareAsync, id());
+        if (msg == NULL)
+        {
+            ALOGE("Out of memory, AMessage is null for kWhatPrepareAsync\n");
+            return NO_MEMORY;
+        }
+        msg->post();
+        return -EWOULDBLOCK;
+    }
+    return OK;
+}
+
+status_t DashPlayer::getParameter(int key, Parcel *reply)
+{
+    void * data_8;
+    void * data_16;
+    size_t data_8_Size;
+    size_t data_16_Size;
+
+    status_t err = OK;
+
+    if (mSource == NULL)
+    {
+      ALOGE("Source is NULL in getParameter\n");
+      return UNKNOWN_ERROR;
+    }
+    err = mSource->getParameter(key, &data_8, &data_8_Size);
+    if (err != OK)
+    {
+      ALOGE("source getParameter returned error: %d\n",err);
+      return err;
+    }
+
+    data_16_Size = data_8_Size * sizeof(char16_t);
+    data_16 = malloc(data_16_Size);
+    if (data_16 == NULL)
+    {
+      ALOGE("Out of memory in getParameter\n");
+      return NO_MEMORY;
+    }
+
+    utf8_to_utf16_no_null_terminator((uint8_t *)data_8, data_8_Size, (char16_t *) data_16);
+    err = reply->writeString16((char16_t *)data_16, data_8_Size);
+    free(data_16);
+    return err;
+}
+
+status_t DashPlayer::setParameter(int key, const Parcel &request)
+{
+    status_t err = OK;
+    if (key == 8004) {
+
+        size_t len = 0;
+        const char16_t* str = request.readString16Inplace(&len);
+        void * data = malloc(len + 1);
+        if (data == NULL)
+        {
+            ALOGE("Out of memory in setParameter\n");
+            return NO_MEMORY;
+        }
+
+        utf16_to_utf8(str, len, (char*) data);
+        err = mSource->setParameter(key, data, len);
+        free(data);
+    }
+    return err;
+}
+
+void DashPlayer::postIsPrepareDone()
+{
+    sp<AMessage> msg = new AMessage(kWhatIsPrepareDone, id());
+    if (msg == NULL)
+    {
+        ALOGE("Out of memory, AMessage is null for kWhatIsPrepareDone\n");
+        return;
+    }
+    msg->post();
+}
+void DashPlayer::sendTextPacket(sp<ABuffer> accessUnit,status_t err)
+{
+    Parcel parcel;
+    int mFrameType = TIMED_TEXT_FLAG_FRAME;
+
+    //Local setting
+    parcel.writeInt32(KEY_LOCAL_SETTING);
+    if (err == ERROR_END_OF_STREAM ||
+        err == (status_t)UNKNOWN_ERROR)
+    {
+       parcel.writeInt32(KEY_TEXT_EOS);
+       // write size of sample
+       ALOGE("Error End Of Stream EOS");
+       mFrameType = TIMED_TEXT_FLAG_EOS;
+       notifyListener(MEDIA_TIMED_TEXT, 0, mFrameType, &parcel);
+       return;
+    }
+   // time stamp
+    int64_t mediaTimeUs = 0;
+    CHECK(accessUnit->meta()->findInt64("timeUs", &mediaTimeUs));
+    parcel.writeInt32(KEY_START_TIME);
+    parcel.writeInt32((int32_t)(mediaTimeUs / 1000));  // convert micro sec to milli sec
+
+    ALOGE("sendTextPacket Text Track Timestamp (%0.2f) sec",mediaTimeUs / 1E6);
+
+    // Text Sample
+    parcel.writeInt32(KEY_STRUCT_TEXT);
+
+    int32_t tCodecConfig;
+    accessUnit->meta()->findInt32("conf", &tCodecConfig);
+    if (tCodecConfig)
+    {
+       ALOGE("Timed text codec config frame");
+       parcel.writeInt32(TIMED_TEXT_FLAG_CODEC_CONFIG_FRAME);
+       mFrameType = TIMED_TEXT_FLAG_CODEC_CONFIG_FRAME;
+    }
+    else
+    {
+       parcel.writeInt32(TIMED_TEXT_FLAG_FRAME);
+       mFrameType = TIMED_TEXT_FLAG_FRAME;
+    }
+
+    // write size of sample
+    parcel.writeInt32(accessUnit->size());
+    parcel.writeInt32(accessUnit->size());
+    // write sample payload
+    parcel.write((const uint8_t *)accessUnit->data(), accessUnit->size());
+
+    int32_t height = 0;
+    if (accessUnit->meta()->findInt32("height", &height)) {
+        ALOGE("sendTextPacket Height (%d)",height);
+        parcel.writeInt32(KEY_HEIGHT);
+        parcel.writeInt32(height);
+    }
+
+    // width
+    int32_t width = 0;
+    if (accessUnit->meta()->findInt32("width", &width)) {
+        ALOGE("sendTextPacket width (%d)",width);
+        parcel.writeInt32(KEY_WIDTH);
+        parcel.writeInt32(width);
+    }
+
+    // Duration
+    int32_t duration = 0;
+    if (accessUnit->meta()->findInt32("duration", &duration)) {
+        ALOGE("sendTextPacket duration (%d)",duration);
+        parcel.writeInt32(KEY_DURATION);
+        parcel.writeInt32(duration);
+    }
+
+    // start offset
+    int32_t startOffset = 0;
+    if (accessUnit->meta()->findInt32("startoffset", &startOffset)) {
+        ALOGE("sendTextPacket startOffset (%d)",startOffset);
+        parcel.writeInt32(KEY_START_OFFSET);
+        parcel.writeInt32(startOffset);
+    }
+
+    // SubInfoSize
+    int32_t subInfoSize = 0;
+    if (accessUnit->meta()->findInt32("subSz", &subInfoSize)) {
+        ALOGE("sendTextPacket subInfoSize (%d)",subInfoSize);
+    }
+
+    // SubInfo
+    AString subInfo;
+    if (accessUnit->meta()->findString("subSi", &subInfo)) {
+        parcel.writeInt32(KEY_SUB_ATOM);
+        parcel.writeInt32(subInfoSize);
+        parcel.writeInt32(subInfoSize);
+        parcel.write((const uint8_t *)subInfo.c_str(), subInfoSize);
+    }
+
+    notifyListener(MEDIA_TIMED_TEXT, 0, mFrameType, &parcel);
+}
+
+void DashPlayer::getTrackName(int track, char* name)
+{
+    if( track == kAudio)
+    {
+      memset(name,0x00,6);
+      strlcpy(name, "audio",6);
+    }
+    else if( track == kVideo)
+    {
+      memset(name,0x00,6);
+      strlcpy(name, "video",6);
+    }
+    else if( track == kText)
+    {
+      memset(name,0x00,6);
+      strlcpy(name, "text",5);
+    }
+    else if (track == kTrackAll)
+    {
+      memset(name,0x00,6);
+      strlcpy(name, "all",4);
+    }
+}
+
+void DashPlayer::prepareSource()
+{
+    if (mSourceType = kHttpDashSource)
+    {
+       mSourceNotify = new AMessage(kWhatSourceNotify ,id());
+       if (mSource != NULL)
+       {
+         mSource->setupSourceData(mSourceNotify,kTrackAll);
+       }
+    }
+}
+
+status_t DashPlayer::dump(int fd, const Vector<String16> &args)
+{
+    if(mStats != NULL) {
+      mStats->setFileDescAndOutputStream(fd);
+    }
+
+    return OK;
+}
+
+}  // namespace android
diff --git a/dashplayer/DashPlayer.h b/dashplayer/DashPlayer.h
new file mode 100644
index 0000000..5efca7c
--- /dev/null
+++ b/dashplayer/DashPlayer.h
@@ -0,0 +1,269 @@
+/*
+ * Copyright (C) 2010 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef DASH_PLAYER_H_
+
+#define DASH_PLAYER_H_
+
+#include <media/MediaPlayerInterface.h>
+#include <media/stagefright/foundation/AHandler.h>
+#include <media/stagefright/NativeWindowWrapper.h>
+#include "DashPlayerStats.h"
+#include <media/stagefright/foundation/ABuffer.h>
+#define KEY_DASH_ADAPTION_PROPERTIES 8002 // used for Get Adaotionset property
+#define KEY_DASH_MPD_QUERY           8003
+#define KEY_DASH_SET_ADAPTION_PROPERTIES 8004 // used for Set Adaotionset property
+
+namespace android {
+
+struct DashCodec;
+struct MetaData;
+struct DashPlayerDriver;
+
+struct DashPlayer : public AHandler {
+    DashPlayer();
+
+    void setUID(uid_t uid);
+
+    void setDriver(const wp<DashPlayerDriver> &driver);
+
+    void setDataSource(const sp<IStreamSource> &source);
+
+    status_t  setDataSource(
+            const char *url, const KeyedVector<String8, String8> *headers);
+
+    void setDataSource(int fd, int64_t offset, int64_t length);
+
+#ifdef ANDROID_JB_MR2
+    void setVideoSurfaceTexture(const sp<IGraphicBufferProducer> &bufferProducer);
+#else
+    void setVideoSurfaceTexture(const sp<ISurfaceTexture> &surfaceTexture);
+#endif
+
+    void setAudioSink(const sp<MediaPlayerBase::AudioSink> &sink);
+    void start();
+
+    void pause();
+    void resume();
+
+    // Will notify the driver through "notifyResetComplete" once finished.
+    void resetAsync();
+
+    // Will notify the driver through "notifySeekComplete" once finished.
+    void seekToAsync(int64_t seekTimeUs);
+
+    status_t prepareAsync();
+    status_t getParameter(int key, Parcel *reply);
+    status_t setParameter(int key, const Parcel &request);
+    status_t dump(int fd, const Vector<String16> &args);
+
+public:
+    struct DASHHTTPLiveSource;
+    struct WFDSource;
+
+protected:
+    virtual ~DashPlayer();
+
+    virtual void onMessageReceived(const sp<AMessage> &msg);
+
+private:
+    struct Decoder;
+    struct Renderer;
+    struct Source;
+
+    enum {
+          // These keys must be in sync with the keys in QCTimedText.java
+          KEY_DISPLAY_FLAGS                 = 1, // int
+          KEY_STYLE_FLAGS                   = 2, // int
+          KEY_BACKGROUND_COLOR_RGBA         = 3, // int
+          KEY_HIGHLIGHT_COLOR_RGBA          = 4, // int
+          KEY_SCROLL_DELAY                  = 5, // int
+          KEY_WRAP_TEXT                     = 6, // int
+          KEY_START_TIME                    = 7, // int
+          KEY_STRUCT_BLINKING_TEXT_LIST     = 8, // List<CharPos>
+          KEY_STRUCT_FONT_LIST              = 9, // List<Font>
+          KEY_STRUCT_HIGHLIGHT_LIST         = 10,// List<CharPos>
+          KEY_STRUCT_HYPER_TEXT_LIST        = 11,// List<HyperText>
+          KEY_STRUCT_KARAOKE_LIST           = 12,// List<Karaoke>
+          KEY_STRUCT_STYLE_LIST             = 13,// List<Style>
+          KEY_STRUCT_TEXT_POS               = 14,// TextPos
+          KEY_STRUCT_JUSTIFICATION          = 15,// Justification
+          KEY_STRUCT_TEXT                   = 16,// Text
+          KEY_HEIGHT                        = 17,
+          KEY_WIDTH                         = 18,
+          KEY_DURATION                      = 19,
+          KEY_START_OFFSET                  = 20,
+          KEY_SUB_ATOM                      = 21,
+          KEY_GLOBAL_SETTING                = 101,
+          KEY_LOCAL_SETTING                 = 102,
+          KEY_START_CHAR                    = 103,
+          KEY_END_CHAR                      = 104,
+          KEY_FONT_ID                       = 105,
+          KEY_FONT_SIZE                     = 106,
+          KEY_TEXT_COLOR_RGBA               = 107,
+          KEY_TEXT_EOS                      = 108,
+    };
+
+    enum {
+        kWhatSetDataSource              = '=DaS',
+        kWhatSetVideoNativeWindow       = '=NaW',
+        kWhatSetAudioSink               = '=AuS',
+        kWhatMoreDataQueued             = 'more',
+        kWhatStart                      = 'strt',
+        kWhatScanSources                = 'scan',
+        kWhatVideoNotify                = 'vidN',
+        kWhatAudioNotify                = 'audN',
+        kWhatTextNotify                 = 'texN',
+        kWhatRendererNotify             = 'renN',
+        kWhatReset                      = 'rset',
+        kWhatSeek                       = 'seek',
+        kWhatPause                      = 'paus',
+        kWhatResume                     = 'rsme',
+        kWhatPrepareAsync               = 'pras',
+        kWhatIsPrepareDone              = 'prdn',
+        kWhatSourceNotify               = 'snfy',
+        kKeySmoothStreaming             = 'ESmS',  //bool (int32_t)
+        kKeyEnableDecodeOrder           = 'EDeO',  //bool (int32_t)
+    };
+
+    enum {
+        kWhatBufferingStart             = 'bfst',
+        kWhatBufferingEnd               = 'bfen',
+    };
+
+    wp<DashPlayerDriver> mDriver;
+    bool mUIDValid;
+    uid_t mUID;
+    sp<Source> mSource;
+    sp<NativeWindowWrapper> mNativeWindow;
+    sp<MediaPlayerBase::AudioSink> mAudioSink;
+    sp<Decoder> mVideoDecoder;
+    bool mVideoIsAVC;
+    sp<Decoder> mAudioDecoder;
+    sp<Decoder> mTextDecoder;
+    sp<Renderer> mRenderer;
+
+    bool mAudioEOS;
+    bool mVideoEOS;
+
+    bool mScanSourcesPending;
+    int32_t mScanSourcesGeneration;
+    bool mBufferingNotification;
+
+    enum TrackName {
+        kVideo = 0,
+        kAudio,
+        kText,
+        kTrackAll,
+    };
+
+    enum FlushStatus {
+        NONE,
+        AWAITING_DISCONTINUITY,
+        FLUSHING_DECODER,
+        FLUSHING_DECODER_SHUTDOWN,
+        SHUTTING_DOWN_DECODER,
+        FLUSHED,
+        SHUT_DOWN,
+    };
+
+    enum FrameFlags {
+         TIMED_TEXT_FLAG_FRAME = 0x00,
+         TIMED_TEXT_FLAG_CODEC_CONFIG_FRAME,
+         TIMED_TEXT_FLAG_EOS,
+         TIMED_TEXT_FLAG_END = TIMED_TEXT_FLAG_EOS,
+    };
+
+    // Once the current flush is complete this indicates whether the
+    // notion of time has changed.
+    bool mTimeDiscontinuityPending;
+
+    FlushStatus mFlushingAudio;
+    FlushStatus mFlushingVideo;
+    bool mResetInProgress;
+    bool mResetPostponed;
+    bool mSetVideoSize;
+
+    int64_t mSkipRenderingAudioUntilMediaTimeUs;
+    int64_t mSkipRenderingVideoUntilMediaTimeUs;
+
+    int64_t mVideoLateByUs;
+    int64_t mNumFramesTotal, mNumFramesDropped;
+
+    bool mPauseIndication;
+
+    Mutex mLock;
+
+    char *mTrackName;
+    sp<AMessage> mTextNotify;
+    sp<AMessage> mSourceNotify;
+
+    enum NuSourceType {
+        kHttpLiveSource = 0,
+        kHttpDashSource,
+        kRtspSource,
+        kStreamingSource,
+        kWfdSource,
+        kGenericSource,
+        kDefaultSource
+    };
+    NuSourceType mSourceType;
+
+    bool mIsSecureInputBuffers;
+
+    int32_t mSRid;
+
+    status_t instantiateDecoder(int track, sp<Decoder> *decoder);
+
+    status_t feedDecoderInputData(int track, const sp<AMessage> &msg);
+    void renderBuffer(bool audio, const sp<AMessage> &msg);
+
+    void notifyListener(int msg, int ext1, int ext2, const Parcel *obj=NULL);
+
+    void finishFlushIfPossible();
+
+    void flushDecoder(bool audio, bool needShutdown);
+
+    static bool IsFlushingState(FlushStatus state, bool *needShutdown = NULL);
+
+    void finishReset();
+    void postScanSources();
+
+    sp<Source> LoadCreateSource(const char * uri, const KeyedVector<String8,
+                                 String8> *headers, bool uidValid, uid_t uid, NuSourceType srcTyp);
+
+    void postIsPrepareDone();
+
+    // for qualcomm statistics profiling
+    sp<DashPlayerStats> mStats;
+
+    void sendTextPacket(sp<ABuffer> accessUnit, status_t err);
+    void getTrackName(int track, char* name);
+    void prepareSource();
+
+    struct QueueEntry {
+        sp<AMessage>  mMessageToBeConsumed;
+    };
+
+    List<QueueEntry> mDecoderMessageQueue;
+
+
+    DISALLOW_EVIL_CONSTRUCTORS(DashPlayer);
+};
+
+}  // namespace android
+
+#endif  // DASH_PLAYER_H_
diff --git a/dashplayer/DashPlayerDecoder.cpp b/dashplayer/DashPlayerDecoder.cpp
new file mode 100644
index 0000000..1439560
--- /dev/null
+++ b/dashplayer/DashPlayerDecoder.cpp
@@ -0,0 +1,237 @@
+/*
+ * Copyright (C) 2010 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+//#define LOG_NDEBUG 0
+#define LOG_TAG "DashPlayerDecoder"
+#include <utils/Log.h>
+
+#include "DashPlayerDecoder.h"
+#include "DashCodec.h"
+#include "ESDS.h"
+#include "QCMediaDefs.h"
+#include "QCMetaData.h"
+#include <media/stagefright/foundation/ABuffer.h>
+#include <media/stagefright/foundation/ADebug.h>
+#include <media/stagefright/foundation/AMessage.h>
+#include <media/stagefright/MediaDefs.h>
+#include <media/stagefright/MetaData.h>
+#include <media/stagefright/Utils.h>
+
+namespace android {
+
+DashPlayer::Decoder::Decoder(
+        const sp<AMessage> &notify,
+        const sp<NativeWindowWrapper> &nativeWindow)
+    : mNotify(notify),
+      mNativeWindow(nativeWindow) {
+      mAudioSink = NULL;
+}
+
+DashPlayer::Decoder::~Decoder() {
+    ALooper::handler_id id = 0;
+    if (mCodec != NULL) {
+        id = mCodec->id();
+    }
+    if (id != 0) {
+        if (mCodecLooper != NULL) {
+            mCodecLooper->stop();
+            mCodecLooper->unregisterHandler(id);
+        }
+        looper()->unregisterHandler(id);
+    }
+}
+
+void DashPlayer::Decoder::configure(const sp<MetaData> &meta) {
+    CHECK(mCodec == NULL);
+
+    const char *mime;
+    CHECK(meta->findCString(kKeyMIMEType, &mime));
+
+    ALOGV("@@@@:: Decoder::configure :: mime is --- %s ---",mime);
+
+    sp<AMessage> notifyMsg =
+        new AMessage(kWhatCodecNotify, id());
+
+    sp<AMessage> format = makeFormat(meta);
+
+    if (mNativeWindow != NULL) {
+        format->setObject("native-window", mNativeWindow);
+    }
+
+    // Current video decoders do not return from OMX_FillThisBuffer
+    // quickly, violating the OpenMAX specs, until that is remedied
+    // we need to invest in an extra looper to free the main event
+    // queue.
+    bool isVideo = !strncasecmp(mime, "video/", 6);
+
+    if(!isVideo) {
+        const char *mime;
+        CHECK(meta->findCString(kKeyMIMEType, &mime));
+    }
+
+    ALOGV("@@@@:: DashCodec created ");
+    mCodec = new DashCodec;
+
+    bool needDedicatedLooper = false;
+
+    if (isVideo){
+        needDedicatedLooper = true;
+        if(mCodecLooper == NULL) {
+            ALOGV("@@@@:: Creating Looper for %s",(isVideo?"Video":"Audio"));
+            mCodecLooper = new ALooper;
+            mCodecLooper->setName("DashPlayerDecoder");
+            mCodecLooper->start(false, false, ANDROID_PRIORITY_AUDIO);
+        }
+    }
+
+    (needDedicatedLooper ? mCodecLooper : looper())->registerHandler(mCodec);
+     mCodec->setNotificationMessage(notifyMsg);
+     mCodec->initiateSetup(format);
+
+}
+
+void DashPlayer::Decoder::onMessageReceived(const sp<AMessage> &msg) {
+    switch (msg->what()) {
+        case kWhatCodecNotify:
+        {
+            int32_t what;
+            CHECK(msg->findInt32("what", &what));
+
+            if (what == DashCodec::kWhatFillThisBuffer) {
+                onFillThisBuffer(msg);
+            }else {
+                sp<AMessage> notify = mNotify->dup();
+                notify->setMessage("codec-request", msg);
+                notify->post();
+            }
+            break;
+        }
+
+        default:
+            TRESPASS();
+            break;
+    }
+}
+
+void DashPlayer::Decoder::setSink(const sp<MediaPlayerBase::AudioSink> &sink, sp<Renderer> Renderer) {
+    mAudioSink = sink;
+    mRenderer  = Renderer;
+}
+
+
+sp<AMessage> DashPlayer::Decoder::makeFormat(const sp<MetaData> &meta) {
+    CHECK(mCSD.isEmpty());
+
+    sp<AMessage> msg;
+    uint32_t type;
+    const void *data;
+    size_t size;
+
+    CHECK_EQ(convertMetaDataToMessage(meta, &msg), (status_t)OK);
+
+    int32_t value;
+    if (meta->findInt32(kKeySmoothStreaming, &value)) {
+        msg->setInt32("smooth-streaming", value);
+    }
+
+    if (meta->findInt32(kKeyIsDRM, &value)) {
+        msg->setInt32("secure-op", 1);
+    }
+
+    if (meta->findInt32(kKeyRequiresSecureBuffers, &value)) {
+        msg->setInt32("requires-secure-buffers", 1);
+    }
+
+    if (meta->findInt32(kKeyEnableDecodeOrder, &value)) {
+        msg->setInt32("decodeOrderEnable", value);
+    }
+    if (meta->findData(kKeyAacCodecSpecificData, &type, &data, &size)) {
+          if (size > 0 && data != NULL) {
+              sp<ABuffer> buffer = new ABuffer(size);
+              if (buffer != NULL) {
+                memcpy(buffer->data(), data, size);
+                buffer->meta()->setInt32("csd", true);
+                buffer->meta()->setInt64("timeUs", 0);
+                msg->setBuffer("csd-0", buffer);
+              }
+              else {
+                ALOGE("kKeyAacCodecSpecificData ABuffer Allocation failed");
+              }
+          }
+          else {
+              ALOGE("Not a valid data pointer or size == 0");
+          }
+    }
+
+
+    mCSDIndex = 0;
+    for (size_t i = 0;; ++i) {
+        sp<ABuffer> csd;
+        if (!msg->findBuffer(StringPrintf("csd-%d", i).c_str(), &csd)) {
+            break;
+        }
+
+        mCSD.push(csd);
+    }
+
+    return msg;
+}
+
+void DashPlayer::Decoder::onFillThisBuffer(const sp<AMessage> &msg) {
+    sp<AMessage> reply;
+    CHECK(msg->findMessage("reply", &reply));
+
+#if 0
+    sp<ABuffer> outBuffer;
+    CHECK(msg->findBuffer("buffer", &outBuffer));
+#else
+    sp<ABuffer> outBuffer;
+#endif
+
+    if (mCSDIndex < mCSD.size()) {
+        outBuffer = mCSD.editItemAt(mCSDIndex++);
+        outBuffer->meta()->setInt64("timeUs", 0);
+
+        reply->setBuffer("buffer", outBuffer);
+        reply->post();
+        return;
+    }
+
+    sp<AMessage> notify = mNotify->dup();
+    notify->setMessage("codec-request", msg);
+    notify->post();
+}
+
+void DashPlayer::Decoder::signalFlush() {
+    if (mCodec != NULL) {
+        mCodec->signalFlush();
+    }
+}
+
+void DashPlayer::Decoder::signalResume() {
+    if(mCodec != NULL) {
+        mCodec->signalResume();
+    }
+}
+
+void DashPlayer::Decoder::initiateShutdown() {
+    if (mCodec != NULL) {
+        mCodec->initiateShutdown();
+   }
+}
+
+}  // namespace android
+
diff --git a/dashplayer/DashPlayerDecoder.h b/dashplayer/DashPlayerDecoder.h
new file mode 100644
index 0000000..adf7544
--- /dev/null
+++ b/dashplayer/DashPlayerDecoder.h
@@ -0,0 +1,70 @@
+/*
+ * Copyright (C) 2010 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef DASHPLAYER_DECODER_H_
+
+#define DASHPLAYER_DECODER_H_
+
+#include "DashPlayerRenderer.h"
+#include "DashPlayer.h"
+#include <media/stagefright/foundation/AHandler.h>
+
+namespace android {
+
+struct ABuffer;
+
+struct DashPlayer::Decoder : public AHandler {
+    Decoder(const sp<AMessage> &notify,
+            const sp<NativeWindowWrapper> &nativeWindow = NULL);
+
+    void configure(const sp<MetaData> &meta);
+
+    void signalFlush();
+    void signalResume();
+    void initiateShutdown();
+    void setSink(const sp<MediaPlayerBase::AudioSink> &sink, sp<Renderer> Renderer);
+
+protected:
+    virtual ~Decoder();
+
+    virtual void onMessageReceived(const sp<AMessage> &msg);
+
+private:
+    enum {
+        kWhatCodecNotify        = 'cdcN',
+    };
+
+    sp<AMessage> mNotify;
+    sp<NativeWindowWrapper> mNativeWindow;
+
+    sp<DashCodec> mCodec;
+    sp<ALooper> mCodecLooper;
+    sp<MediaPlayerBase::AudioSink> mAudioSink;
+    sp<Renderer> mRenderer;
+
+    Vector<sp<ABuffer> > mCSD;
+    size_t mCSDIndex;
+
+    sp<AMessage> makeFormat(const sp<MetaData> &meta);
+
+    void onFillThisBuffer(const sp<AMessage> &msg);
+
+    DISALLOW_EVIL_CONSTRUCTORS(Decoder);
+};
+
+}  // namespace android
+
+#endif  // DASHPLAYER_DECODER_H_
diff --git a/dashplayer/DashPlayerDriver.cpp b/dashplayer/DashPlayerDriver.cpp
new file mode 100644
index 0000000..91840fc
--- /dev/null
+++ b/dashplayer/DashPlayerDriver.cpp
@@ -0,0 +1,392 @@
+/*
+ * Copyright (C) 2010 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+//#define LOG_NDEBUG 0
+#define LOG_TAG "DashPlayerDriver"
+#include <utils/Log.h>
+
+#include "DashPlayerDriver.h"
+
+#include "DashPlayer.h"
+
+#include <media/stagefright/foundation/ADebug.h>
+#include <media/stagefright/foundation/ALooper.h>
+
+namespace android {
+
+DashPlayerDriver::DashPlayerDriver()
+    : mResetInProgress(false),
+      mDurationUs(-1),
+      mPositionUs(-1),
+      mNumFramesTotal(0),
+      mNumFramesDropped(0),
+      mLooper(new ALooper),
+      mState(UNINITIALIZED),
+      mAtEOS(false),
+      mStartupSeekTimeUs(-1) {
+    mLooper->setName("DashPlayerDriver Looper");
+
+    mLooper->start(
+            false, /* runOnCallingThread */
+            true,  /* canCallJava */
+            PRIORITY_AUDIO);
+
+    mPlayer = new DashPlayer;
+    mLooper->registerHandler(mPlayer);
+
+    mPlayer->setDriver(this);
+}
+
+DashPlayerDriver::~DashPlayerDriver() {
+    mLooper->stop();
+    mLooper->unregisterHandler(mPlayer->id());
+}
+
+status_t DashPlayerDriver::initCheck() {
+    return OK;
+}
+
+status_t DashPlayerDriver::setUID(uid_t uid) {
+    mPlayer->setUID(uid);
+
+    return OK;
+}
+
+status_t DashPlayerDriver::setDataSource(
+        const char *url, const KeyedVector<String8, String8> *headers) {
+    CHECK_EQ((int)mState, (int)UNINITIALIZED);
+
+    status_t ret = mPlayer->setDataSource(url, headers);
+
+    mState = STOPPED;
+
+    return ret;
+}
+
+status_t DashPlayerDriver::setDataSource(int fd, int64_t offset, int64_t length) {
+    CHECK_EQ((int)mState, (int)UNINITIALIZED);
+
+    mPlayer->setDataSource(fd, offset, length);
+
+    mState = STOPPED;
+
+    return OK;
+}
+
+status_t DashPlayerDriver::setDataSource(const sp<IStreamSource> &source) {
+    CHECK_EQ((int)mState, (int)UNINITIALIZED);
+
+    mPlayer->setDataSource(source);
+
+    mState = STOPPED;
+
+    return OK;
+}
+
+#ifdef ANDROID_JB_MR2
+status_t DashPlayerDriver::setVideoSurfaceTexture(
+        const sp<IGraphicBufferProducer> &bufferProducer) {
+    mPlayer->setVideoSurfaceTexture(bufferProducer);
+
+    return OK;
+}
+#else
+status_t DashPlayerDriver::setVideoSurfaceTexture(
+        const sp<ISurfaceTexture> &surfaceTexture) {
+    mPlayer->setVideoSurfaceTexture(surfaceTexture);
+
+    return OK;
+}
+#endif
+
+status_t DashPlayerDriver::prepare() {
+    sendEvent(MEDIA_SET_VIDEO_SIZE, 0, 0);
+    return OK;
+}
+
+status_t DashPlayerDriver::prepareAsync() {
+    status_t err = UNKNOWN_ERROR;
+    if (mPlayer != NULL) {
+        err = mPlayer->prepareAsync();
+    }
+
+    if (err == OK) {
+        err = prepare();
+        notifyListener(MEDIA_PREPARED);
+    } else if (err == -EWOULDBLOCK) {
+        // this case only happens for DASH
+        return OK;
+    }
+    return err;
+}
+
+status_t DashPlayerDriver::start() {
+    switch (mState) {
+        case UNINITIALIZED:
+            return INVALID_OPERATION;
+        case STOPPED:
+        {
+            mAtEOS = false;
+            mPlayer->start();
+
+            if (mStartupSeekTimeUs >= 0) {
+                if (mStartupSeekTimeUs == 0) {
+                    notifySeekComplete();
+                } else {
+                    mPlayer->seekToAsync(mStartupSeekTimeUs);
+                }
+
+                mStartupSeekTimeUs = -1;
+            }
+
+            break;
+        }
+        case PLAYING:
+            return OK;
+        default:
+        {
+            CHECK_EQ((int)mState, (int)PAUSED);
+            if (mAtEOS){
+                seekTo(0);
+            }
+            mPlayer->resume();
+            break;
+        }
+    }
+
+    mState = PLAYING;
+
+    return OK;
+}
+
+status_t DashPlayerDriver::stop() {
+    return pause();
+}
+
+status_t DashPlayerDriver::pause() {
+    switch (mState) {
+        case UNINITIALIZED:
+            return INVALID_OPERATION;
+        case STOPPED:
+            return OK;
+        case PLAYING:
+            mPlayer->pause();
+            break;
+        default:
+        {
+            CHECK_EQ((int)mState, (int)PAUSED);
+            return OK;
+        }
+    }
+
+    mState = PAUSED;
+
+    return OK;
+}
+
+bool DashPlayerDriver::isPlaying() {
+    return mState == PLAYING && !mAtEOS;
+}
+
+status_t DashPlayerDriver::seekTo(int msec) {
+    int64_t seekTimeUs = msec * 1000ll;
+
+    switch (mState) {
+        case UNINITIALIZED:
+            return INVALID_OPERATION;
+        case STOPPED:
+        {
+            mStartupSeekTimeUs = seekTimeUs;
+            break;
+        }
+        case PLAYING:
+        case PAUSED:
+        {
+            mAtEOS = false;
+            mPlayer->seekToAsync(seekTimeUs);
+            break;
+        }
+
+        default:
+            TRESPASS();
+            break;
+    }
+
+    return OK;
+}
+
+status_t DashPlayerDriver::getCurrentPosition(int *msec) {
+    Mutex::Autolock autoLock(mLock);
+
+    if (mPositionUs < 0) {
+        *msec = 0;
+    } else {
+        *msec = (mPositionUs + 500ll) / 1000;
+    }
+
+    return OK;
+}
+
+status_t DashPlayerDriver::getDuration(int *msec) {
+    Mutex::Autolock autoLock(mLock);
+
+    if (mDurationUs < 0) {
+        *msec = 0;
+    } else {
+        *msec = (mDurationUs + 500ll) / 1000;
+    }
+
+    return OK;
+}
+
+status_t DashPlayerDriver::reset() {
+    Mutex::Autolock autoLock(mLock);
+    mResetInProgress = true;
+
+    mPlayer->resetAsync();
+
+    while (mResetInProgress) {
+        mCondition.wait(mLock);
+    }
+
+    mDurationUs = -1;
+    mPositionUs = -1;
+    mState = UNINITIALIZED;
+    mStartupSeekTimeUs = -1;
+
+    return OK;
+}
+
+status_t DashPlayerDriver::setLooping(int loop) {
+    return INVALID_OPERATION;
+}
+
+player_type DashPlayerDriver::playerType() {
+    return NU_PLAYER;
+}
+
+status_t DashPlayerDriver::invoke(const Parcel &request, Parcel *reply) {
+    status_t ret = INVALID_OPERATION;
+    int32_t methodId;
+    ret = request.readInt32(&methodId);
+    if (ret != OK) {
+          ALOGE("Failed to retrieve the requested method to invoke");
+          return ret;
+    }
+
+    switch (methodId) {
+        case KEY_DASH_ADAPTION_PROPERTIES:
+          {
+            ALOGE("calling KEY_DASH_GET_ADAPTION_PROPERTIES");
+            ret = getParameter(methodId,reply);
+           break;
+          }
+        case KEY_DASH_SET_ADAPTION_PROPERTIES:
+          {
+            ALOGE("calling KEY_DASH_SET_ADAPTION_PROPERTIES");
+            int32_t val = 0;
+            ret = setParameter(methodId,request);
+            val = (ret == OK)? 1:0;
+            reply->setDataPosition(0);
+            reply->writeInt32(val);
+            break;
+         }
+        default:
+          {
+            ALOGE("Invoke:unHandled requested method%d",methodId);
+            ret = OK;
+            break;
+          }
+      }
+      return ret;
+}
+
+void DashPlayerDriver::setAudioSink(const sp<AudioSink> &audioSink) {
+    mPlayer->setAudioSink(audioSink);
+}
+
+status_t DashPlayerDriver::setParameter(int key, const Parcel &request) {
+
+    status_t err = UNKNOWN_ERROR;
+    if (mPlayer != NULL)
+    {
+        err = mPlayer->setParameter(key, request);
+    }
+    return err;
+}
+
+status_t DashPlayerDriver::getParameter(int key, Parcel *reply) {
+
+    status_t err = UNKNOWN_ERROR;
+    if (mPlayer != NULL)
+    {
+        err = mPlayer->getParameter(key, reply);
+    }
+    return err;
+}
+
+status_t DashPlayerDriver::getMetadata(
+        const media::Metadata::Filter& ids, Parcel *records) {
+    return INVALID_OPERATION;
+}
+
+void DashPlayerDriver::notifyResetComplete() {
+    Mutex::Autolock autoLock(mLock);
+    CHECK(mResetInProgress);
+    mResetInProgress = false;
+    mCondition.broadcast();
+}
+
+void DashPlayerDriver::notifyDuration(int64_t durationUs) {
+    Mutex::Autolock autoLock(mLock);
+    mDurationUs = durationUs;
+}
+
+void DashPlayerDriver::notifyPosition(int64_t positionUs) {
+    Mutex::Autolock autoLock(mLock);
+    mPositionUs = positionUs;
+}
+
+void DashPlayerDriver::notifySeekComplete() {
+    notifyListener(MEDIA_SEEK_COMPLETE);
+}
+
+void DashPlayerDriver::notifyFrameStats(
+        int64_t numFramesTotal, int64_t numFramesDropped) {
+    Mutex::Autolock autoLock(mLock);
+    mNumFramesTotal = numFramesTotal;
+    mNumFramesDropped = numFramesDropped;
+}
+
+status_t DashPlayerDriver::dump(int fd, const Vector<String16> &args) const {
+    if(mPlayer != NULL) {
+      mPlayer->dump(fd, args);
+    }
+    return OK;
+}
+
+void DashPlayerDriver::notifyListener(int msg, int ext1, int ext2, const Parcel *obj) {
+    if (msg == MEDIA_PLAYBACK_COMPLETE || msg == MEDIA_ERROR) {
+        mAtEOS = true;
+        if(msg == MEDIA_PLAYBACK_COMPLETE){
+            pause();
+        }
+    }
+
+    sendEvent(msg, ext1, ext2, obj);
+}
+
+}  // namespace android
diff --git a/dashplayer/DashPlayerDriver.h b/dashplayer/DashPlayerDriver.h
new file mode 100644
index 0000000..fd10b39
--- /dev/null
+++ b/dashplayer/DashPlayerDriver.h
@@ -0,0 +1,112 @@
+/*
+ * Copyright (C) 2010 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include <media/MediaPlayerInterface.h>
+
+#include <media/stagefright/foundation/ABase.h>
+
+namespace android {
+
+struct ALooper;
+struct DashPlayer;
+
+struct DashPlayerDriver : public MediaPlayerInterface {
+    DashPlayerDriver();
+
+    virtual status_t initCheck();
+
+    virtual status_t setUID(uid_t uid);
+
+    virtual status_t setDataSource(
+            const char *url, const KeyedVector<String8, String8> *headers);
+
+    virtual status_t setDataSource(int fd, int64_t offset, int64_t length);
+
+    virtual status_t setDataSource(const sp<IStreamSource> &source);
+
+#ifdef ANDROID_JB_MR2
+    virtual status_t setVideoSurfaceTexture(
+            const sp<IGraphicBufferProducer> &bufferProducer);
+#else
+    virtual status_t setVideoSurfaceTexture(
+            const sp<ISurfaceTexture> &surfaceTexture);
+#endif
+    virtual status_t prepare();
+    virtual status_t prepareAsync();
+    virtual status_t start();
+    virtual status_t stop();
+    virtual status_t pause();
+    virtual bool isPlaying();
+    virtual status_t seekTo(int msec);
+    virtual status_t getCurrentPosition(int *msec);
+    virtual status_t getDuration(int *msec);
+    virtual status_t reset();
+    virtual status_t setLooping(int loop);
+    virtual player_type playerType();
+    virtual status_t invoke(const Parcel &request, Parcel *reply);
+    virtual void setAudioSink(const sp<AudioSink> &audioSink);
+    virtual status_t setParameter(int key, const Parcel &request);
+    virtual status_t getParameter(int key, Parcel *reply);
+
+    virtual status_t getMetadata(
+            const media::Metadata::Filter& ids, Parcel *records);
+
+    virtual status_t dump(int fd, const Vector<String16> &args) const;
+
+    void notifyResetComplete();
+    void notifyDuration(int64_t durationUs);
+    void notifyPosition(int64_t positionUs);
+    void notifySeekComplete();
+    void notifyFrameStats(int64_t numFramesTotal, int64_t numFramesDropped);
+    void notifyListener(int msg, int ext1 = 0, int ext2 = 0, const Parcel *obj=NULL);
+
+protected:
+    virtual ~DashPlayerDriver();
+
+private:
+    mutable Mutex mLock;
+    Condition mCondition;
+
+    // The following are protected through "mLock"
+    // >>>
+    bool mResetInProgress;
+    int64_t mDurationUs;
+    int64_t mPositionUs;
+    int64_t mNumFramesTotal;
+    int64_t mNumFramesDropped;
+    // <<<
+
+    sp<ALooper> mLooper;
+    sp<DashPlayer> mPlayer;
+
+    enum State {
+        UNINITIALIZED,
+        STOPPED,
+        PLAYING,
+        PAUSED
+    };
+
+    State mState;
+    bool mAtEOS;
+
+    int64_t mStartupSeekTimeUs;
+
+    DISALLOW_EVIL_CONSTRUCTORS(DashPlayerDriver);
+};
+
+}  // namespace android
+
+
diff --git a/dashplayer/DashPlayerRenderer.cpp b/dashplayer/DashPlayerRenderer.cpp
new file mode 100644
index 0000000..35b8fab
--- /dev/null
+++ b/dashplayer/DashPlayerRenderer.cpp
@@ -0,0 +1,744 @@
+/*
+ * Copyright (C) 2010 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+//#define LOG_NDEBUG 0
+#define LOG_TAG "DashPlayerRenderer"
+#include <utils/Log.h>
+
+#include "DashPlayerRenderer.h"
+
+#include <media/stagefright/foundation/ABuffer.h>
+#include <media/stagefright/foundation/ADebug.h>
+#include <media/stagefright/foundation/AMessage.h>
+
+namespace android {
+
+// static
+const int64_t DashPlayer::Renderer::kMinPositionUpdateDelayUs = 100000ll;
+
+DashPlayer::Renderer::Renderer(
+        const sp<MediaPlayerBase::AudioSink> &sink,
+        const sp<AMessage> &notify)
+    : mAudioSink(sink),
+      mNotify(notify),
+      mNumFramesWritten(0),
+      mDrainAudioQueuePending(false),
+      mDrainVideoQueuePending(false),
+      mAudioQueueGeneration(0),
+      mVideoQueueGeneration(0),
+      mAnchorTimeMediaUs(-1),
+      mAnchorTimeRealUs(-1),
+      mFlushingAudio(false),
+      mFlushingVideo(false),
+      mHasAudio(false),
+      mHasVideo(false),
+      mSyncQueues(false),
+      mPaused(false),
+      mWasPaused(false),
+      mLastPositionUpdateUs(-1ll),
+      mVideoLateByUs(0ll),
+      mStats(NULL),
+      mSeekTimeUs(0){
+}
+
+DashPlayer::Renderer::~Renderer() {
+    if(mStats != NULL) {
+        mStats->logStatistics();
+        mStats->logSyncLoss();
+        mStats = NULL;
+    }
+}
+
+void DashPlayer::Renderer::queueBuffer(
+        bool audio,
+        const sp<ABuffer> &buffer,
+        const sp<AMessage> &notifyConsumed) {
+    sp<AMessage> msg = new AMessage(kWhatQueueBuffer, id());
+    msg->setInt32("audio", static_cast<int32_t>(audio));
+    msg->setBuffer("buffer", buffer);
+    msg->setMessage("notifyConsumed", notifyConsumed);
+    msg->post();
+}
+
+void DashPlayer::Renderer::queueEOS(bool audio, status_t finalResult) {
+    CHECK_NE(finalResult, (status_t)OK);
+
+    if(mSyncQueues)
+      syncQueuesDone();
+
+    sp<AMessage> msg = new AMessage(kWhatQueueEOS, id());
+    msg->setInt32("audio", static_cast<int32_t>(audio));
+    msg->setInt32("finalResult", finalResult);
+    msg->post();
+}
+
+void DashPlayer::Renderer::flush(bool audio) {
+    {
+        Mutex::Autolock autoLock(mFlushLock);
+        if (audio) {
+            CHECK(!mFlushingAudio);
+            mFlushingAudio = true;
+        } else {
+            CHECK(!mFlushingVideo);
+            mFlushingVideo = true;
+        }
+    }
+
+    sp<AMessage> msg = new AMessage(kWhatFlush, id());
+    msg->setInt32("audio", static_cast<int32_t>(audio));
+    msg->post();
+}
+
+void DashPlayer::Renderer::signalTimeDiscontinuity() {
+    CHECK(mAudioQueue.empty());
+    CHECK(mVideoQueue.empty());
+    mAnchorTimeMediaUs = -1;
+    mAnchorTimeRealUs = -1;
+    mWasPaused = false;
+    mSeekTimeUs = 0;
+    mSyncQueues = mHasAudio && mHasVideo;
+    ALOGI("signalTimeDiscontinuity mHasAudio %d mHasVideo %d mSyncQueues %d",mHasAudio,mHasVideo,mSyncQueues);
+}
+
+void DashPlayer::Renderer::pause() {
+    (new AMessage(kWhatPause, id()))->post();
+}
+
+void DashPlayer::Renderer::resume() {
+    (new AMessage(kWhatResume, id()))->post();
+}
+
+void DashPlayer::Renderer::onMessageReceived(const sp<AMessage> &msg) {
+    switch (msg->what()) {
+        case kWhatDrainAudioQueue:
+        {
+            int32_t generation;
+            CHECK(msg->findInt32("generation", &generation));
+            if (generation != mAudioQueueGeneration) {
+                break;
+            }
+
+            mDrainAudioQueuePending = false;
+
+            if (onDrainAudioQueue()) {
+                uint32_t numFramesPlayed;
+                CHECK_EQ(mAudioSink->getPosition(&numFramesPlayed),
+                         (status_t)OK);
+
+                uint32_t numFramesPendingPlayout =
+                    mNumFramesWritten - numFramesPlayed;
+
+                // This is how long the audio sink will have data to
+                // play back.
+                int64_t delayUs =
+                    mAudioSink->msecsPerFrame()
+                        * numFramesPendingPlayout * 1000ll;
+
+                // Let's give it more data after about half that time
+                // has elapsed.
+                postDrainAudioQueue(delayUs / 2);
+            }
+            break;
+        }
+
+        case kWhatDrainVideoQueue:
+        {
+            int32_t generation;
+            CHECK(msg->findInt32("generation", &generation));
+            if (generation != mVideoQueueGeneration) {
+                break;
+            }
+
+            mDrainVideoQueuePending = false;
+
+            onDrainVideoQueue();
+
+            postDrainVideoQueue();
+            break;
+        }
+
+        case kWhatQueueBuffer:
+        {
+            onQueueBuffer(msg);
+            break;
+        }
+
+        case kWhatQueueEOS:
+        {
+            onQueueEOS(msg);
+            break;
+        }
+
+        case kWhatFlush:
+        {
+            onFlush(msg);
+            break;
+        }
+
+        case kWhatAudioSinkChanged:
+        {
+            onAudioSinkChanged();
+            break;
+        }
+
+        case kWhatPause:
+        {
+            onPause();
+            break;
+        }
+
+        case kWhatResume:
+        {
+            onResume();
+            break;
+        }
+
+        default:
+            TRESPASS();
+            break;
+    }
+}
+
+void DashPlayer::Renderer::postDrainAudioQueue(int64_t delayUs) {
+    if (mDrainAudioQueuePending || mSyncQueues || mPaused) {
+        return;
+    }
+
+    if (mAudioQueue.empty()) {
+        return;
+    }
+
+    mDrainAudioQueuePending = true;
+    sp<AMessage> msg = new AMessage(kWhatDrainAudioQueue, id());
+    msg->setInt32("generation", mAudioQueueGeneration);
+    msg->post(delayUs);
+}
+
+void DashPlayer::Renderer::signalAudioSinkChanged() {
+    (new AMessage(kWhatAudioSinkChanged, id()))->post();
+}
+
+bool DashPlayer::Renderer::onDrainAudioQueue() {
+    uint32_t numFramesPlayed;
+    if (mAudioSink->getPosition(&numFramesPlayed) != OK) {
+        return false;
+    }
+
+    ssize_t numFramesAvailableToWrite =
+        mAudioSink->frameCount() - (mNumFramesWritten - numFramesPlayed);
+
+#if 0
+    if (numFramesAvailableToWrite == mAudioSink->frameCount()) {
+        ALOGI("audio sink underrun");
+    } else {
+        ALOGV("audio queue has %d frames left to play",
+             mAudioSink->frameCount() - numFramesAvailableToWrite);
+    }
+#endif
+
+    size_t numBytesAvailableToWrite =
+        numFramesAvailableToWrite * mAudioSink->frameSize();
+
+    while (numBytesAvailableToWrite > 0 && !mAudioQueue.empty()) {
+        QueueEntry *entry = &*mAudioQueue.begin();
+
+        if (entry->mBuffer == NULL) {
+            // EOS
+
+            notifyEOS(true /* audio */, entry->mFinalResult);
+
+            mAudioQueue.erase(mAudioQueue.begin());
+            entry = NULL;
+            return false;
+        }
+
+        if (entry->mOffset == 0) {
+            int64_t mediaTimeUs;
+            CHECK(entry->mBuffer->meta()->findInt64("timeUs", &mediaTimeUs));
+
+            ALOGV("rendering audio at media time %.2f secs", mediaTimeUs / 1E6);
+
+            mAnchorTimeMediaUs = mediaTimeUs;
+
+            uint32_t numFramesPlayed;
+            CHECK_EQ(mAudioSink->getPosition(&numFramesPlayed), (status_t)OK);
+
+            uint32_t numFramesPendingPlayout =
+                mNumFramesWritten - numFramesPlayed;
+
+            int64_t realTimeOffsetUs =
+                (mAudioSink->latency() / 2  /* XXX */
+                    + numFramesPendingPlayout
+                        * mAudioSink->msecsPerFrame()) * 1000ll;
+
+            // ALOGI("realTimeOffsetUs = %lld us", realTimeOffsetUs);
+
+            mAnchorTimeRealUs =
+                ALooper::GetNowUs() + realTimeOffsetUs;
+        }
+
+        size_t copy = entry->mBuffer->size() - entry->mOffset;
+        if (copy > numBytesAvailableToWrite) {
+            copy = numBytesAvailableToWrite;
+        }
+
+        CHECK_EQ(mAudioSink->write(
+                    entry->mBuffer->data() + entry->mOffset, copy),
+                 (ssize_t)copy);
+
+        entry->mOffset += copy;
+        if (entry->mOffset == entry->mBuffer->size()) {
+            entry->mNotifyConsumed->post();
+            mAudioQueue.erase(mAudioQueue.begin());
+
+            entry = NULL;
+        }
+
+        numBytesAvailableToWrite -= copy;
+        size_t copiedFrames = copy / mAudioSink->frameSize();
+        mNumFramesWritten += copiedFrames;
+    }
+
+    notifyPosition();
+
+    return !mAudioQueue.empty();
+}
+
+void DashPlayer::Renderer::postDrainVideoQueue() {
+    if (mDrainVideoQueuePending || mSyncQueues || mPaused) {
+        return;
+    }
+
+    if (mVideoQueue.empty()) {
+        return;
+    }
+
+    QueueEntry &entry = *mVideoQueue.begin();
+
+    sp<AMessage> msg = new AMessage(kWhatDrainVideoQueue, id());
+    msg->setInt32("generation", mVideoQueueGeneration);
+
+    int64_t delayUs;
+
+    if (entry.mBuffer == NULL) {
+        // EOS doesn't carry a timestamp.
+        delayUs = 0;
+    } else {
+        int64_t mediaTimeUs;
+        CHECK(entry.mBuffer->meta()->findInt64("timeUs", &mediaTimeUs));
+
+        if (mAnchorTimeMediaUs < 0) {
+            delayUs = 0;
+
+            if (!mHasAudio) {
+                mAnchorTimeMediaUs = mediaTimeUs;
+                mAnchorTimeRealUs = ALooper::GetNowUs();
+            }
+        } else {
+            if ( (!mHasAudio && mHasVideo) && (mWasPaused == true))
+            {
+               mAnchorTimeMediaUs = mediaTimeUs;
+               mAnchorTimeRealUs = ALooper::GetNowUs();
+               mWasPaused = false;
+            }
+
+            int64_t realTimeUs =
+                (mediaTimeUs - mAnchorTimeMediaUs) + mAnchorTimeRealUs;
+
+            delayUs = realTimeUs - ALooper::GetNowUs();
+        }
+    }
+
+    msg->post(delayUs);
+
+    mDrainVideoQueuePending = true;
+}
+
+void DashPlayer::Renderer::onDrainVideoQueue() {
+    if (mVideoQueue.empty()) {
+        return;
+    }
+
+    QueueEntry *entry = &*mVideoQueue.begin();
+
+    if (entry->mBuffer == NULL) {
+        // EOS
+
+        notifyPosition(true);
+
+        notifyEOS(false /* audio */, entry->mFinalResult);
+
+        mVideoQueue.erase(mVideoQueue.begin());
+        entry = NULL;
+
+        mVideoLateByUs = 0ll;
+
+        return;
+    }
+
+    int64_t mediaTimeUs;
+    CHECK(entry->mBuffer->meta()->findInt64("timeUs", &mediaTimeUs));
+
+    int64_t realTimeUs = mediaTimeUs - mAnchorTimeMediaUs + mAnchorTimeRealUs;
+    int64_t nowUs = ALooper::GetNowUs();
+    mVideoLateByUs = nowUs - realTimeUs;
+
+    bool tooLate = (mVideoLateByUs > 40000);
+
+    if (tooLate) {
+        ALOGV("video late by %lld us (%.2f secs)",
+             mVideoLateByUs, mVideoLateByUs / 1E6);
+        if(mStats != NULL) {
+            mStats->recordLate(realTimeUs,nowUs,mVideoLateByUs,mAnchorTimeRealUs);
+        }
+    } else {
+        ALOGV("rendering video at media time %.2f secs", mediaTimeUs / 1E6);
+        if(mStats != NULL) {
+            mStats->recordOnTime(realTimeUs,nowUs,mVideoLateByUs);
+            mStats->incrementTotalRenderingFrames();
+            mStats->logFps();
+        }
+    }
+
+    entry->mNotifyConsumed->setInt32("render", !tooLate);
+    entry->mNotifyConsumed->post();
+    mVideoQueue.erase(mVideoQueue.begin());
+    entry = NULL;
+
+    notifyPosition();
+}
+
+void DashPlayer::Renderer::notifyEOS(bool audio, status_t finalResult) {
+    sp<AMessage> notify = mNotify->dup();
+    notify->setInt32("what", kWhatEOS);
+    notify->setInt32("audio", static_cast<int32_t>(audio));
+    notify->setInt32("finalResult", finalResult);
+    notify->post();
+}
+
+void DashPlayer::Renderer::onQueueBuffer(const sp<AMessage> &msg) {
+    int32_t audio;
+    CHECK(msg->findInt32("audio", &audio));
+
+    if (audio) {
+        mHasAudio = true;
+    } else {
+        mHasVideo = true;
+    }
+
+    if (dropBufferWhileFlushing(audio, msg)) {
+        return;
+    }
+
+    sp<ABuffer> buffer;
+    CHECK(msg->findBuffer("buffer", &buffer));
+
+    sp<AMessage> notifyConsumed;
+    CHECK(msg->findMessage("notifyConsumed", &notifyConsumed));
+
+    QueueEntry entry;
+    entry.mBuffer = buffer;
+    entry.mNotifyConsumed = notifyConsumed;
+    entry.mOffset = 0;
+    entry.mFinalResult = OK;
+
+    if (audio) {
+        mAudioQueue.push_back(entry);
+        postDrainAudioQueue();
+    } else {
+        mVideoQueue.push_back(entry);
+        postDrainVideoQueue();
+    }
+
+    if (!mSyncQueues || mAudioQueue.empty() || mVideoQueue.empty()) {
+        return;
+    }
+
+    sp<ABuffer> firstAudioBuffer = (*mAudioQueue.begin()).mBuffer;
+    sp<ABuffer> firstVideoBuffer = (*mVideoQueue.begin()).mBuffer;
+
+    if (firstAudioBuffer == NULL || firstVideoBuffer == NULL) {
+        // EOS signalled on either queue.
+        syncQueuesDone();
+        return;
+    }
+
+    int64_t firstAudioTimeUs;
+    int64_t firstVideoTimeUs;
+    CHECK(firstAudioBuffer->meta()
+            ->findInt64("timeUs", &firstAudioTimeUs));
+    CHECK(firstVideoBuffer->meta()
+            ->findInt64("timeUs", &firstVideoTimeUs));
+
+    int64_t diff = firstVideoTimeUs - firstAudioTimeUs;
+
+    ALOGV("queueDiff = %.2f secs", diff / 1E6);
+
+    if (diff > 100000ll) {
+        // Audio data starts More than 0.1 secs before video.
+        // Drop some audio.
+
+        (*mAudioQueue.begin()).mNotifyConsumed->post();
+        mAudioQueue.erase(mAudioQueue.begin());
+        return;
+    }
+
+    syncQueuesDone();
+}
+
+void DashPlayer::Renderer::syncQueuesDone() {
+    if (!mSyncQueues) {
+        return;
+    }
+
+    mSyncQueues = false;
+
+    if (!mAudioQueue.empty()) {
+        postDrainAudioQueue();
+    }
+
+    if (!mVideoQueue.empty()) {
+        postDrainVideoQueue();
+    }
+}
+
+void DashPlayer::Renderer::onQueueEOS(const sp<AMessage> &msg) {
+    int32_t audio;
+    CHECK(msg->findInt32("audio", &audio));
+
+    if (dropBufferWhileFlushing(audio, msg)) {
+        return;
+    }
+
+    int32_t finalResult;
+    CHECK(msg->findInt32("finalResult", &finalResult));
+
+    QueueEntry entry;
+    entry.mOffset = 0;
+    entry.mFinalResult = finalResult;
+
+    if (audio) {
+        mAudioQueue.push_back(entry);
+        postDrainAudioQueue();
+    } else {
+        mVideoQueue.push_back(entry);
+        postDrainVideoQueue();
+    }
+}
+
+void DashPlayer::Renderer::onFlush(const sp<AMessage> &msg) {
+    int32_t audio;
+    CHECK(msg->findInt32("audio", &audio));
+
+    // If we're currently syncing the queues, i.e. dropping audio while
+    // aligning the first audio/video buffer times and only one of the
+    // two queues has data, we may starve that queue by not requesting
+    // more buffers from the decoder. If the other source then encounters
+    // a discontinuity that leads to flushing, we'll never find the
+    // corresponding discontinuity on the other queue.
+    // Therefore we'll stop syncing the queues if at least one of them
+    // is flushed.
+    syncQueuesDone();
+
+    if (audio) {
+        flushQueue(&mAudioQueue);
+
+        Mutex::Autolock autoLock(mFlushLock);
+        mFlushingAudio = false;
+
+        mDrainAudioQueuePending = false;
+        ++mAudioQueueGeneration;
+    } else {
+        flushQueue(&mVideoQueue);
+
+        Mutex::Autolock autoLock(mFlushLock);
+        mFlushingVideo = false;
+
+        mDrainVideoQueuePending = false;
+        ++mVideoQueueGeneration;
+        if(mStats != NULL) {
+            mStats->setVeryFirstFrame(true);
+        }
+    }
+
+    notifyFlushComplete(audio);
+}
+
+void DashPlayer::Renderer::flushQueue(List<QueueEntry> *queue) {
+    while (!queue->empty()) {
+        QueueEntry *entry = &*queue->begin();
+
+        if (entry->mBuffer != NULL) {
+            entry->mNotifyConsumed->post();
+        }
+
+        queue->erase(queue->begin());
+        entry = NULL;
+    }
+}
+
+void DashPlayer::Renderer::notifyFlushComplete(bool audio) {
+    sp<AMessage> notify = mNotify->dup();
+    notify->setInt32("what", kWhatFlushComplete);
+    notify->setInt32("audio", static_cast<int32_t>(audio));
+    notify->post();
+}
+
+bool DashPlayer::Renderer::dropBufferWhileFlushing(
+        bool audio, const sp<AMessage> &msg) {
+    bool flushing = false;
+
+    {
+        Mutex::Autolock autoLock(mFlushLock);
+        if (audio) {
+            flushing = mFlushingAudio;
+        } else {
+            flushing = mFlushingVideo;
+        }
+    }
+
+    if (!flushing) {
+        return false;
+    }
+
+    sp<AMessage> notifyConsumed;
+    if (msg->findMessage("notifyConsumed", &notifyConsumed)) {
+        notifyConsumed->post();
+    }
+
+    return true;
+}
+
+void DashPlayer::Renderer::onAudioSinkChanged() {
+    CHECK(!mDrainAudioQueuePending);
+    mNumFramesWritten = 0;
+    uint32_t written;
+    if (mAudioSink->getFramesWritten(&written) == OK) {
+        mNumFramesWritten = written;
+    }
+}
+
+void DashPlayer::Renderer::notifyPosition(bool isEOS) {
+    if (mAnchorTimeRealUs < 0 || mAnchorTimeMediaUs < 0) {
+        return;
+    }
+
+    int64_t nowUs = ALooper::GetNowUs();
+
+    if ((!isEOS) && (mLastPositionUpdateUs >= 0
+            && nowUs < mLastPositionUpdateUs + kMinPositionUpdateDelayUs)) {
+        return;
+    }
+    mLastPositionUpdateUs = nowUs;
+
+    int64_t positionUs = (mSeekTimeUs != 0) ? mSeekTimeUs : ((nowUs - mAnchorTimeRealUs) + mAnchorTimeMediaUs);
+
+    sp<AMessage> notify = mNotify->dup();
+    notify->setInt32("what", kWhatPosition);
+    notify->setInt64("positionUs", positionUs);
+    notify->setInt64("videoLateByUs", mVideoLateByUs);
+    notify->post();
+}
+
+void DashPlayer::Renderer::notifySeekPosition(int64_t seekTime){
+  mSeekTimeUs = seekTime;
+  int64_t nowUs = ALooper::GetNowUs();
+  mLastPositionUpdateUs = nowUs;
+  sp<AMessage> notify = mNotify->dup();
+  notify->setInt32("what", kWhatPosition);
+  notify->setInt64("positionUs", seekTime);
+  notify->setInt64("videoLateByUs", mVideoLateByUs);
+  notify->post();
+
+}
+
+
+void DashPlayer::Renderer::onPause() {
+    CHECK(!mPaused);
+
+    mDrainAudioQueuePending = false;
+    ++mAudioQueueGeneration;
+
+    mDrainVideoQueuePending = false;
+    ++mVideoQueueGeneration;
+
+    if (mHasAudio) {
+        mAudioSink->pause();
+    }
+
+    ALOGV("now paused audio queue has %d entries, video has %d entries",
+          mAudioQueue.size(), mVideoQueue.size());
+
+    mPaused = true;
+    mWasPaused = true;
+
+    if(mStats != NULL) {
+        int64_t positionUs;
+        if(mAnchorTimeRealUs < 0 || mAnchorTimeMediaUs < 0) {
+            positionUs = -1000;
+        } else {
+            int64_t nowUs = ALooper::GetNowUs();
+            positionUs = (nowUs - mAnchorTimeRealUs) + mAnchorTimeMediaUs;
+        }
+
+        mStats->logPause(positionUs);
+    }
+}
+
+void DashPlayer::Renderer::onResume() {
+    if (!mPaused) {
+        return;
+    }
+
+    if (mHasAudio) {
+        mAudioSink->start();
+    }
+
+    mPaused = false;
+
+    if (!mAudioQueue.empty()) {
+        postDrainAudioQueue();
+    }
+
+    if (!mVideoQueue.empty()) {
+        postDrainVideoQueue();
+    }
+}
+
+void DashPlayer::Renderer::registerStats(sp<DashPlayerStats> stats) {
+    if(mStats != NULL) {
+        mStats = NULL;
+    }
+    mStats = stats;
+}
+
+status_t DashPlayer::Renderer::setMediaPresence(bool audio, bool bValue)
+{
+   if (audio)
+   {
+      ALOGV("mHasAudio set to %d from %d",bValue,mHasAudio);
+      mHasAudio = bValue;
+   }
+   else
+   {
+     ALOGV("mHasVideo set to %d from %d",bValue,mHasVideo);
+     mHasVideo = bValue;
+   }
+   return OK;
+}
+
+}  // namespace android
+
diff --git a/dashplayer/DashPlayerRenderer.h b/dashplayer/DashPlayerRenderer.h
new file mode 100644
index 0000000..b71f460
--- /dev/null
+++ b/dashplayer/DashPlayerRenderer.h
@@ -0,0 +1,163 @@
+/*
+ * Copyright (C) 2010 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef DASHPLAYER_RENDERER_H_
+
+#define DASHPLAYER_RENDERER_H_
+
+#include "DashPlayer.h"
+
+namespace android {
+
+struct ABuffer;
+
+struct DashPlayer::Renderer : public AHandler {
+    Renderer(const sp<MediaPlayerBase::AudioSink> &sink,
+             const sp<AMessage> &notify);
+
+    void queueBuffer(
+            bool audio,
+            const sp<ABuffer> &buffer,
+            const sp<AMessage> &notifyConsumed);
+#ifdef QCOM_WFD_SINK
+    virtual void queueEOS(bool audio, status_t finalResult);
+
+    virtual void flush(bool audio);
+
+    virtual void signalTimeDiscontinuity();
+
+    virtual void signalAudioSinkChanged();
+
+    virtual void pause();
+    virtual void resume();
+#else
+
+    void queueEOS(bool audio, status_t finalResult);
+
+    void flush(bool audio);
+
+    void signalTimeDiscontinuity();
+
+    void signalAudioSinkChanged();
+
+    void pause();
+    void resume();
+    void notifySeekPosition(int64_t seekTime);
+#endif /* QCOM_WFD_SINK */
+    enum {
+        kWhatEOS                = 'eos ',
+        kWhatFlushComplete      = 'fluC',
+        kWhatPosition           = 'posi',
+    };
+
+protected:
+    virtual ~Renderer();
+
+    virtual void onMessageReceived(const sp<AMessage> &msg);
+
+private:
+    enum {
+        kWhatDrainAudioQueue    = 'draA',
+        kWhatDrainVideoQueue    = 'draV',
+        kWhatQueueBuffer        = 'queB',
+        kWhatQueueEOS           = 'qEOS',
+        kWhatFlush              = 'flus',
+        kWhatAudioSinkChanged   = 'auSC',
+        kWhatPause              = 'paus',
+        kWhatResume             = 'resm',
+    };
+
+    struct QueueEntry {
+        sp<ABuffer> mBuffer;
+        sp<AMessage> mNotifyConsumed;
+        size_t mOffset;
+        status_t mFinalResult;
+    };
+
+    static const int64_t kMinPositionUpdateDelayUs;
+
+    sp<MediaPlayerBase::AudioSink> mAudioSink;
+    sp<AMessage> mNotify;
+    List<QueueEntry> mAudioQueue;
+    List<QueueEntry> mVideoQueue;
+    uint32_t mNumFramesWritten;
+
+    bool mDrainAudioQueuePending;
+    bool mDrainVideoQueuePending;
+    int32_t mAudioQueueGeneration;
+    int32_t mVideoQueueGeneration;
+
+    int64_t mAnchorTimeMediaUs;
+    int64_t mAnchorTimeRealUs;
+    int64_t mSeekTimeUs;
+
+    Mutex mFlushLock;  // protects the following 2 member vars.
+    bool mFlushingAudio;
+    bool mFlushingVideo;
+
+    bool mHasAudio;
+    bool mHasVideo;
+    bool mSyncQueues;
+
+    bool mPaused;
+    bool mWasPaused; // if paused then store the info
+
+    int64_t mLastPositionUpdateUs;
+    int64_t mVideoLateByUs;
+
+    bool onDrainAudioQueue();
+    void postDrainAudioQueue(int64_t delayUs = 0);
+
+    void onDrainVideoQueue();
+    void postDrainVideoQueue();
+#ifdef QCOM_WFD_SINK
+    virtual void onQueueBuffer(const sp<AMessage> &msg);
+#else
+    void onQueueBuffer(const sp<AMessage> &msg);
+#endif /* QCOM_WFD_SINK */
+    void onQueueEOS(const sp<AMessage> &msg);
+    void onFlush(const sp<AMessage> &msg);
+    void onAudioSinkChanged();
+    void onPause();
+    void onResume();
+
+    void notifyEOS(bool audio, status_t finalResult);
+    void notifyFlushComplete(bool audio);
+    void notifyPosition(bool isEOS = false);
+    void notifyVideoLateBy(int64_t lateByUs);
+
+    void flushQueue(List<QueueEntry> *queue);
+    bool dropBufferWhileFlushing(bool audio, const sp<AMessage> &msg);
+    void syncQueuesDone();
+
+    // for qualcomm statistics profiling
+  public:
+#ifdef QCOM_WFD_SINK
+    virtual void registerStats(sp<DashPlayerStats> stats);
+    virtual status_t setMediaPresence(bool audio, bool bValue);
+#else
+    void registerStats(sp<DashPlayerStats> stats);
+    status_t setMediaPresence(bool audio, bool bValue);
+#endif /* QCOM_WFD_SINK */
+  private:
+    sp<DashPlayerStats> mStats;
+
+    DISALLOW_EVIL_CONSTRUCTORS(Renderer);
+};
+
+}  // namespace android
+
+#endif  // DASHPLAYER_RENDERER_H_
diff --git a/dashplayer/DashPlayerSource.h b/dashplayer/DashPlayerSource.h
new file mode 100644
index 0000000..9f968b2
--- /dev/null
+++ b/dashplayer/DashPlayerSource.h
@@ -0,0 +1,107 @@
+/*
+ * Copyright (C) 2010 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef DASHPLAYER_SOURCE_H_
+
+#define DASHPLAYER_SOURCE_H_
+
+#include "DashPlayer.h"
+//#include <media/stagefright/MediaDebug.h>
+
+namespace android {
+
+struct ABuffer;
+
+struct DashPlayer::Source : public RefBase {
+    Source() {}
+
+    virtual void start() = 0;
+    virtual void stop() {}
+
+    // Returns OK iff more data was available,
+    // an error or ERROR_END_OF_STREAM if not.
+    virtual status_t feedMoreTSData() = 0;
+
+    virtual sp<MetaData> getFormat(int audio) = 0;
+
+    virtual status_t dequeueAccessUnit(
+            int track, sp<ABuffer> *accessUnit) = 0;
+
+    virtual status_t getDuration(int64_t *durationUs) {
+        return INVALID_OPERATION;
+    }
+
+    virtual status_t seekTo(int64_t seekTimeUs) {
+        return INVALID_OPERATION;
+    }
+
+    virtual bool isSeekable() {
+        return false;
+    }
+
+    virtual status_t getNewSeekTime(int64_t* newSeek) {
+        return INVALID_OPERATION;
+    }
+
+    virtual status_t prepareAsync() {
+        return INVALID_OPERATION;
+    }
+
+    virtual bool isPrepareDone() {
+        return INVALID_OPERATION;
+    }
+
+    virtual status_t getParameter(int key, void **data, size_t *size) {
+        return INVALID_OPERATION;
+    }
+
+    virtual status_t setParameter(int key, void *data, size_t size) {
+        return INVALID_OPERATION;
+    }
+    virtual void notifyRenderingPosition(int64_t nRenderingTS){}
+
+    virtual status_t setupSourceData(const sp<AMessage> &msg, int iTrack){
+        return INVALID_OPERATION;
+    }
+    virtual status_t postNextTextSample(sp<ABuffer> accessUnit,const sp<AMessage> &msg,int iTrack) {
+        return INVALID_OPERATION;
+    }
+
+    virtual status_t getMediaPresence(bool &audio, bool &video, bool &text) {
+       return INVALID_OPERATION;
+    }
+
+    virtual void pause() {
+        ALOGE("Pause called on Wrong DataSource.. Please check !!!");
+        //CHECK(false);
+    }
+
+    virtual void resume() {
+        ALOGE("Resume called on Wrong DataSource.. Please check !!!");
+        //CHECK(false);
+    }
+
+protected:
+    virtual ~Source() {}
+
+private:
+    DISALLOW_EVIL_CONSTRUCTORS(Source);
+};
+
+}  // namespace android
+
+#endif  // DASHPLAYER_SOURCE_H_
+
diff --git a/dashplayer/DashPlayerStats.cpp b/dashplayer/DashPlayerStats.cpp
new file mode 100644
index 0000000..247b62d
--- /dev/null
+++ b/dashplayer/DashPlayerStats.cpp
@@ -0,0 +1,289 @@
+/*
+ * Copyright (c) 2013, The Linux Foundation. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are
+ * met:
+ *     * Redistributions of source code must retain the above copyright
+ *      notice, this list of conditions and the following disclaimer.
+ *     * Redistributions in binary form must reproduce the above
+ *       copyright notice, this list of conditions and the following
+ *       disclaimer in the documentation and/or other materials provided
+ *      with the distribution.
+ *     * Neither the name of The Linux Foundation nor the names of its
+ *      contributors may be used to endorse or promote products derived
+ *       from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED "AS IS" AND ANY EXPRESS OR IMPLIED
+ * WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT
+ * ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS
+ * BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+ * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+ * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
+ * BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,
+ * WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE
+ * OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN
+ * IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#include <utils/Log.h>
+#include "DashPlayerStats.h"
+
+#define NO_MIMETYPE_AVAILABLE "N/A"
+
+namespace android {
+
+DashPlayerStats::DashPlayerStats() {
+      Mutex::Autolock autoLock(mStatsLock);
+      mMIME = new char[strlen(NO_MIMETYPE_AVAILABLE)+1];
+      strcpy(mMIME,NO_MIMETYPE_AVAILABLE);
+      mNumVideoFramesDecoded = 0;
+      mNumVideoFramesDropped = 0;
+      mConsecutiveFramesDropped = 0;
+      mCatchupTimeStart = 0;
+      mNumTimesSyncLoss = 0;
+      mMaxEarlyDelta = 0;
+      mMaxLateDelta = 0;
+      mMaxTimeSyncLoss = 0;
+      mTotalFrames = 0;
+      mFirstFrameLatencyStartUs = getTimeOfDayUs();
+      mLastFrame = 0;
+      mLastFrameUs = 0;
+      mStatisticsFrames = 0;
+      mFPSSumUs = 0;
+      mVeryFirstFrame = true;
+      mSeekPerformed = false;
+      mTotalTime = 0;
+      mFirstFrameTime = 0;
+      mTotalRenderingFrames = 0;
+      mBufferingEvent = false;
+      mFd = -1;
+      mFileOut = NULL;
+}
+
+DashPlayerStats::~DashPlayerStats() {
+    Mutex::Autolock autoLock(mStatsLock);
+    if(mFileOut){
+      fclose(mFileOut);
+      mFileOut = NULL;
+    }
+    if(mMIME) {
+        delete[] mMIME;
+    }
+}
+
+void DashPlayerStats::setFileDescAndOutputStream(int fd) {
+    Mutex::Autolock autoLock(mStatsLock);
+    mFd = fd;
+    if(mFileOut){
+      fclose(mFileOut);
+      mFileOut = NULL;
+    }
+    mFileOut = fdopen(dup(fd), "w");
+}
+
+void DashPlayerStats::setMime(const char* mime) {
+    Mutex::Autolock autoLock(mStatsLock);
+    if(mime != NULL) {
+        int mimeLen = strlen(mime);
+        if(mMIME) {
+            delete[] mMIME;
+        }
+
+        mMIME = new char[mimeLen+1];
+        strcpy(mMIME,mime);
+    }
+}
+
+void DashPlayerStats::setVeryFirstFrame(bool vff) {
+    Mutex::Autolock autoLock(mStatsLock);
+    mVeryFirstFrame = true;
+}
+
+void DashPlayerStats::notifySeek() {
+    Mutex::Autolock autoLock(mStatsLock);
+    mFirstFrameLatencyStartUs = getTimeOfDayUs();
+    mSeekPerformed = true;
+}
+
+void DashPlayerStats::notifyBufferingEvent() {
+    Mutex::Autolock autoLock(mStatsLock);
+    mBufferingEvent = true;
+}
+
+void DashPlayerStats::incrementTotalFrames() {
+    Mutex::Autolock autoLock(mStatsLock);
+    mTotalFrames++;
+}
+
+void DashPlayerStats::incrementTotalRenderingFrames() {
+    Mutex::Autolock autoLock(mStatsLock);
+    mTotalRenderingFrames++;
+}
+
+void DashPlayerStats::incrementDroppedFrames() {
+    Mutex::Autolock autoLock(mStatsLock);
+    mNumVideoFramesDropped++;
+}
+
+void DashPlayerStats::logStatistics() {
+    if(mFileOut) {
+        Mutex::Autolock autoLock(mStatsLock);
+        fprintf(mFileOut, "=====================================================\n");
+        fprintf(mFileOut, "Mime Type: %s\n",mMIME);
+        fprintf(mFileOut, "Number of total frames: %llu\n",mTotalFrames);
+        fprintf(mFileOut, "Number of frames dropped: %lld\n",mNumVideoFramesDropped);
+        fprintf(mFileOut, "Number of frames rendered: %llu\n",mTotalRenderingFrames);
+        fprintf(mFileOut, "Percentage dropped: %.2f\n",
+                           mTotalFrames == 0 ? 0.0 : (double)mNumVideoFramesDropped / mTotalFrames);
+        fprintf(mFileOut, "=====================================================\n");
+    }
+}
+
+void DashPlayerStats::logPause(int64_t positionUs) {
+    if(mFileOut) {
+        fprintf(mFileOut, "=====================================================\n");
+        fprintf(mFileOut, "Pause position: %lld ms\n",positionUs/1000);
+        fprintf(mFileOut, "=====================================================\n");
+    }
+}
+
+void DashPlayerStats::logSeek(int64_t seekTimeUs) {
+    if(mFileOut) {
+        Mutex::Autolock autoLock(mStatsLock);
+        fprintf(mFileOut, "=====================================================\n");
+        fprintf(mFileOut, "Seek position: %lld ms\n",seekTimeUs/1000);
+        fprintf(mFileOut, "Seek latency: %lld ms\n",(getTimeOfDayUs() - mFirstFrameLatencyStartUs)/1000);
+        fprintf(mFileOut, "=====================================================\n");
+    }
+}
+
+void DashPlayerStats::recordLate(int64_t ts, int64_t clock, int64_t delta, int64_t anchorTime) {
+    Mutex::Autolock autoLock(mStatsLock);
+    mNumVideoFramesDropped++;
+    mConsecutiveFramesDropped++;
+    if (mConsecutiveFramesDropped == 1){
+      mCatchupTimeStart = anchorTime;
+    }
+
+    logLate(ts,clock,delta);
+}
+
+void DashPlayerStats::recordOnTime(int64_t ts, int64_t clock, int64_t delta) {
+    Mutex::Autolock autoLock(mStatsLock);
+    mNumVideoFramesDecoded++;
+    mConsecutiveFramesDropped = 0;
+    logOnTime(ts,clock,delta);
+}
+
+void DashPlayerStats::logSyncLoss() {
+    if(mFileOut) {
+        Mutex::Autolock autoLock(mStatsLock);
+        fprintf(mFileOut, "=====================================================\n");
+        fprintf(mFileOut, "Number of times AV Sync Losses = %u\n", mNumTimesSyncLoss);
+        fprintf(mFileOut, "Max Video Ahead time delta = %u\n", -mMaxEarlyDelta/1000);
+        fprintf(mFileOut, "Max Video Behind time delta = %u\n", mMaxLateDelta/1000);
+        fprintf(mFileOut, "Max Time sync loss = %u\n",mMaxTimeSyncLoss/1000);
+        fprintf(mFileOut, "=====================================================\n");
+    }
+}
+
+void DashPlayerStats::logFps() {
+    if (mFileOut) {
+        Mutex::Autolock autoLock(mStatsLock);
+        int64_t now = getTimeOfDayUs();
+
+        if(mTotalRenderingFrames < 2){
+           mLastFrameUs = now;
+           mFirstFrameTime = now;
+        }
+
+        mTotalTime = now - mFirstFrameTime;
+        int64_t diff = now - mLastFrameUs;
+        if (diff > 250000 && !mVeryFirstFrame && !mBufferingEvent) {
+             double fps =((mTotalRenderingFrames - mLastFrame) * 1E6)/diff;
+             if (mStatisticsFrames == 0) {
+                 fps =((mTotalRenderingFrames - mLastFrame - 1) * 1E6)/diff;
+             }
+             fprintf(mFileOut, "Frames per second: %.4f, Duration of measurement: %lld\n", fps,diff);
+             mFPSSumUs += fps;
+             ++mStatisticsFrames;
+             mLastFrameUs = now;
+             mLastFrame = mTotalRenderingFrames;
+         }
+
+        if(mSeekPerformed) {
+            mVeryFirstFrame = false;
+            mSeekPerformed = false;
+        } else if(mVeryFirstFrame) {
+            logFirstFrame();
+            fprintf(mFileOut, "setting first frame time\n");
+            mLastFrameUs = now;
+        } else if(mBufferingEvent) {
+            mLastFrameUs = now;
+            mLastFrame = mTotalRenderingFrames;
+        }
+        mBufferingEvent = false;
+    }
+}
+
+void DashPlayerStats::logFpsSummary() {
+    if (mFileOut) {
+        logStatistics();
+        logSyncLoss();
+        {
+            Mutex::Autolock autoLock(mStatsLock);
+            fprintf(mFileOut, "=========================================================\n");
+            fprintf(mFileOut, "Average Frames Per Second: %.4f\n", mFPSSumUs/((double)mStatisticsFrames));
+            fprintf(mFileOut, "Total Frames (rendered) / Total Time: %.4f\n", ((double)(mTotalRenderingFrames-1)*1E6)/((double)mTotalTime));
+            fprintf(mFileOut, "========================================================\n");
+        }
+    }
+}
+
+int64_t DashPlayerStats::getTimeOfDayUs() {
+    struct timeval tv;
+    gettimeofday(&tv, NULL);
+    return (int64_t)tv.tv_sec * 1000000 + tv.tv_usec;
+}
+
+// WARNING: Most private functions are only thread-safe within mStatsLock
+inline void DashPlayerStats::logFirstFrame() {
+    fprintf(mFileOut, "=====================================================\n");
+    fprintf(mFileOut, "First frame latency: %lld ms\n",(getTimeOfDayUs()-mFirstFrameLatencyStartUs)/1000);
+    fprintf(mFileOut, "=====================================================\n");
+    mVeryFirstFrame = false;
+}
+
+inline void DashPlayerStats::logCatchUp(int64_t ts, int64_t clock, int64_t delta) {
+    if (mConsecutiveFramesDropped > 0) {
+        mNumTimesSyncLoss++;
+        if (mMaxTimeSyncLoss < (clock - mCatchupTimeStart) && clock > 0 && ts > 0) {
+            mMaxTimeSyncLoss = clock - mCatchupTimeStart;
+        }
+    }
+}
+
+inline void DashPlayerStats::logLate(int64_t ts, int64_t clock, int64_t delta) {
+    if (mMaxLateDelta < delta && clock > 0 && ts > 0) {
+        mMaxLateDelta = delta;
+    }
+}
+
+inline void DashPlayerStats::logOnTime(int64_t ts, int64_t clock, int64_t delta) {
+    bool needLogLate = false;
+    logCatchUp(ts, clock, delta);
+    if (delta <= 0) {
+        if ((-delta) > (-mMaxEarlyDelta) && clock > 0 && ts > 0) {
+            mMaxEarlyDelta = delta;
+        }
+    }
+    else {
+        needLogLate = true;
+    }
+
+    if(needLogLate) logLate(ts, clock, delta);
+}
+
+} // namespace android
diff --git a/dashplayer/DashPlayerStats.h b/dashplayer/DashPlayerStats.h
new file mode 100644
index 0000000..9dcb423
--- /dev/null
+++ b/dashplayer/DashPlayerStats.h
@@ -0,0 +1,97 @@
+/*
+ * Copyright (c) 2013, The Linux Foundation. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are
+ * met:
+ *     * Redistributions of source code must retain the above copyright
+ *      notice, this list of conditions and the following disclaimer.
+ *     * Redistributions in binary form must reproduce the above
+ *       copyright notice, this list of conditions and the following
+ *       disclaimer in the documentation and/or other materials provided
+ *      with the distribution.
+ *     * Neither the name of The Linux Foundation nor the names of its
+ *      contributors may be used to endorse or promote products derived
+ *       from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED "AS IS" AND ANY EXPRESS OR IMPLIED
+ * WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT
+ * ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS
+ * BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+ * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+ * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
+ * BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,
+ * WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE
+ * OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN
+ * IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#ifndef DASHPLAYER_STATS_H_
+
+#define DASHPLAYER_STATS_H_
+
+#include <utils/RefBase.h>
+#include <utils/threads.h>
+
+namespace android {
+
+class DashPlayerStats : public RefBase {
+  public:
+    DashPlayerStats();
+    ~DashPlayerStats();
+
+    void setMime(const char* mime);
+    void setVeryFirstFrame(bool vff);
+    void notifySeek();
+    void incrementTotalFrames();
+    void incrementDroppedFrames();
+    void logStatistics();
+    void logPause(int64_t positionUs);
+    void logSeek(int64_t seekTimeUs);
+    void recordLate(int64_t ts, int64_t clock, int64_t delta, int64_t anchorTime);
+    void recordOnTime(int64_t ts, int64_t clock, int64_t delta);
+    void logSyncLoss();
+    void logFps();
+    void logFpsSummary();
+    static int64_t getTimeOfDayUs();
+    void incrementTotalRenderingFrames();
+    void notifyBufferingEvent();
+    void setFileDescAndOutputStream(int fd);
+
+  private:
+    void logFirstFrame();
+    void logCatchUp(int64_t ts, int64_t clock, int64_t delta);
+    void logLate(int64_t ts, int64_t clock, int64_t delta);
+    void logOnTime(int64_t ts, int64_t clock, int64_t delta);
+
+    mutable Mutex mStatsLock;
+    bool mStatistics;
+    char* mMIME;
+    int64_t mNumVideoFramesDecoded;
+    int64_t mNumVideoFramesDropped;
+    int64_t mConsecutiveFramesDropped;
+    uint32_t mCatchupTimeStart;
+    uint32_t mNumTimesSyncLoss;
+    uint32_t mMaxEarlyDelta;
+    uint32_t mMaxLateDelta;
+    uint32_t mMaxTimeSyncLoss;
+    uint64_t mTotalFrames;
+    int64_t mFirstFrameLatencyStartUs;
+    int64_t mLastFrame;
+    int64_t mLastFrameUs;
+    double mFPSSumUs;
+    int64_t mStatisticsFrames;
+    bool mVeryFirstFrame;
+    bool mSeekPerformed;
+    int64_t mTotalTime;
+    int64_t mFirstFrameTime;
+    uint64_t mTotalRenderingFrames;
+    bool mBufferingEvent;
+    int mFd;
+    FILE *mFileOut;
+};
+
+} // namespace android
+
+#endif // DASHPLAYER_STATS_H_
